[["index.html", "Statistisk prosesskontroll Introduksjon Versjoner", " Statistisk prosesskontroll Siste endring 24 januar, 2022 Introduksjon Denne boka gir en introduksjon til statistisk prosesskontroll (SPC) som element i kontinuerlig kvalitetsarbeid. Innholdet er under utvikling og oppdateres jevnlig om enn noe uregelmessig. Tilbakemeldinger og innspill bes gitt til Nils Kvilvang Bilde: Colourbox.com Boka er laget i R Markdown ved hjelp av en rekke programmer og pakker til R, ikke minst bookdown. Versjoner Dato Endring 16.nov 2021 Grunnversjon 09.jan 2022 Oppdatert forside med versjonstabell. Lagt til nytt delkapittel 7.1 om mønstre for kontrolldiagram. Oppdatert vedlegg 4 11.jan 2022 Oppdatert bibliografi med R-pakker som er brukt 12.jan 2022 Rettet opp feil i vedlegg 1 (koder) 13.jan 2022 Oppdatert kap 7 med nytt delkapittel om tolkning av kontrolldiagrammer 14.jan 2022 Mindre endringer i kap 1. Ny innledning kap 2. 15.jan 2022 Oppdatering i kap 2.1. Endringer i kap 3. Mindre endringer i kap 6. Mindre endringer i kap 7. Nytt vedlegg 9. Nytt vedlegg 10. 16.jan 2022 Oppdatert kap 8.Oppdatert vedlegg 10 med flere formler. 19.januar Oppdatert kap 6 med videoeksempel på utarbeidelse av seriediagram i Excel. "],["hvorfor-denne-boka.html", "1 Hvorfor denne boka? 1.1 Programvare", " 1 Hvorfor denne boka? Tanken på å lage denne boka oppsto gjennom forberedelser til innføring av et nytt emne i Kvalitetsledelse på Høgskolen i Innlandet, og gjennom erfaringer fra liknende kurs i helsesektoren rundt om i Kommune-Norge. Kvalitetsarbeid er et sentralt element i svært mange virksomheter. I mange virksomheter, som i helsesektoren, finnes det også lovpålegg som omhandler kvalitet. Det finnes et utall metodikker, tilbydere, bøker og artikler om temaet. Likevel følte vi at akkurat denne boka manglet. Vi savnet en kobling mellom mye av det som blir beskrevet i bøker om kvalitet og kvalitetsledelse, og en grundigere behandling av grunnlaget (= datagrunnlaget) for mye av dette kvalitetsarbeidet. Denne koblingen var fundamental i utviklingen av kvalitetsarbeid gjennom frontfigurer som Walter A. Shewhart og W. Edwards Deming, men har etter vår mening til en viss grad havnet litt i bakleksa. Det grunnleggende premisset bak denne boka og vår tilnærming til kvalitetsarbeid er: Uten en god forståelse av datagrunnlag og analyse av prosesser er sjansene for å lykkes med kvalitetsarbeid små og tilfeldige. I beste fall har man kastet bort ressurser. I verste fall har man kastet bort ressurser, økt frustrasjonen blant ansatte og fått dårligere kvalitet. Derfor mener vi at statistisk prosesskontroll må ha en helt sentral plass i kvalitetsarbeid. Denne boka har til hensikt å drøfte kvalitetsarbeid. Vi ønsker a dekke et gap. For det første er det skrevet på norsk. Mye av litteraturen er skrevet på engelsk og kan for mange være vanskelig tilgjengelig av den grunn. Videre er det overraskende lite om statistisk prosesskontroll som verktøy i kvalitetsarbeid, langt mindre på norsk. Der det er et tema, er det i liten grad koblet inn i en større kvalitetssammenheng. Til slutt ønsker vi også å gi leseren en praktisk introduksjon gjennom å vise konkret anvendelse av statistisk prosesskontroll ved å bruke ulike dataverktøy. Til syvende og sist gjelder postulatet «godt gjort er bedre enn godt sagt». Det er vårt klare håp at denne boka kan være både en kilde til forståelse og et praktisk oppslagsverk. 1.1 Programvare Det kan synes unødvendig eller overflødig å vise bruk av flere dataverktøy, men hensikten er å gjøre dette lettere tilgjengelig og mer anvendbart for praktikere som har tilgang til ulike dataverktøy. Excel (Microsoft 2021) og R (R Core Team 2021)1 er fritt tilgjengelig (dvs Excel er for så vidt ikke fritt tilgjengelig, men så utbredt at det er naturlig å ta det med2). Det finnes veldig gode tilleggsprogrammer til Excel som integrerer seg sømløst med Excel3 og gjør at arbeidet med statistisk prosesskontroll blir veldig enkelt i et kjent grensesnitt. I forbindelse med arbeidet med denne boka har vi testet ut Analyse-It, SPC for Excel og QIMacros som gir Excel veldig god funksjonalitet 4 5 6. Analyse-it kan fremstå som dyrt, men sammenliknet med ekte statistikkprogram som SPSS eller Stata er kostnaden relativt lav. Imidlertid finnes det veldig gode alternativer rettet spesielt mot statistisk prosesskontroll og kvalitetsarbeid. De to vi har testet ut er SPC for Excel og QIMacros. Begge integrerer seg sømløst med Excel, har all funksjonalitet man med veldig stor sannsynlighet vil trenge i denne sammenheng og er enkle i bruk. Men alle tilleggene utover standard Excel koster noe. Skal man jobbe en del med statistisk prosesskontroll med Excel som er det imidlertid vel verdt pengene mener vi  og i organisasjoner kan man få volumrabatter o.l. Selv om vi har laget videoer som forklarer framgangsmåte i Excel for flere av analysene og man fint kan lage ulike diagrammer selv, er det uten tvil mer krøkkete. Det er enormt tidsbesparende å ha en plug-in i Excel om man skal jobbe med statistisk prosesskontroll. Om man velger å skaffe seg et av tilleggene til Excel blir et spørsmål om hvor ofte man har behov for å gjøre dette. R (R Core Team 2021) er en velkjent programvare innenfor statistikk, dataanalyse, datamodellering osv. R har noen store fordeler; det er gratis, det kjører på alle operativsystemer, og det har et svært stort bruker- og utviklermiljø som i all hovedsak deler alt gratis. Det er også enkelt å finne løsninger på det meste gjennom veiledninger og brukerforum på nett. Selve R er et programmeringsspråk og utviklermiljø for statistikk som gir en kjernefunksjonalitet innenfor datahåndtering, kalkulasjoner, dataanalyse, datamodellering, grafisk framstilling av data o.l. Brukerne av R utvikler imidlertid pakker som man bruker i R, det finnes p.t. over 18000 ulike pakker som bygger på kjernen i R. Alle pakkene tilbyr ulike tilrettelagte løsninger  det finnes f.eks. flere pakker som spesifikt handler om statistisk prosesskontroll som qicharts2 og qcc. Den største ulempen med R er at brukergrensesnittet er veldig ulikt hva vi kjenner fra Microsoft Office-typen brukergrensesnitt, så det vil ta litt tid å bli kjent med programmet. I tillegg er brukergrensesnittet kodebasert og ikke menybasert, og kan (dessverre) virke avskrekkende. Likevel, det er et utrolig kraftig verktøy hvis man tar seg tid til å lære seg det grunnleggende. Et spesielt interessant gratis alternativ er statistikkprogrammet jamovi. Dette er en grafisk tiltalende og funksjonsrik statistikkpakke som kjører med R i bakgrunnen (alle analyser i jamovi bruker R), og som også kan inkludere R kode direkte. Det gjør at man kan utnytte alle pakkene skrevet for R direkte i jamovis grafiske brukergrensesnitt. Jamovi er et ypperlig gratis program for statistiske analyser, men har ingen innebygd funksjonalitet ennå for statistisk prosesskontroll (men man kan som sagt kjøre R-pakker for dette i programmet). Et annet ypperlig og gratis program er JASP som også kjører analyser gjennom R i et grafisk brukergrensesnitt, og som har den samme muligheten til direkte R integrasjon som jamovi  foreløpig i betaversjon. JASP er i tillegg i ferd med å utvikle en integrert modul for kvalitetskontroll/statistisk prosesskontroll. Det er forventet lansert i løpet av høsten 2021 og vil kunne bli den absolutt foretrukne plattformen siden den da vil kjøre både avanserte statistikkfunksjoner basert på R og SPC-funksjoner i et intuitivt og flott grensesnitt, og er gratis. Leseren står selvsagt fritt til å hoppe elegant over alle verktøy som ikke er interessante. Det er klare fordeler og ulemper med alle, men forhåpentligvis vil de fleste finne et verktøy de kan bruke i utvalget vi har tatt med. Der det er naturlig, som ved bruk av R og RStudio (Team 2021), er kodingen inkludert slik at eksempler skal kunne replikeres av leseren, men vi går ikke inn på R utover dette (og en veldig kort introduksjon til hvordan man laster ned og installerer R og RStudio). Kodingen er gjengitt i vedlegg. Vi har brukt R/RStudio og rmarkdown (Allaire et al. 2021)  en såkalt pakke til R  i produksjonen av dette notatet. R baserer seg som sagt på bruk av ulike pakker som er utviklet av forskjellige utviklere og som er fritt tilgjengelig. Mange av disse har også datasett inkludert slik at det er enkelt å replikere eksempler. Så langt det er mulig har vi basert oss på at det vi viser som eksempler skal være replikerbare for leseren. Når det gjelder pakker for statistisk prosess kontroll har vi brukt pakkene qicharts2 (Anhøj 2021a) og qcc (Scrucca, Snow, and Bloomfield 2017). Vi har lite fokus på matematikk og formler i den forstand at vi ikke utleder i dybden forklaring på ulike formler. Vi tror det er fullt mulig å ha en praktisk forståelse og bruk av statistisk prosesskontroll uten å ha dyptgående kjennskap til de matematiske eller statistiske forklaringene  og det har vært vårt kjerneanliggende med denne boka. Likevel har vi inkludert noe bakgrunnskunnskap for å skape en ramme rundt kjernen i notatet der vi tenker det kan være interessant for de som ønsker å fordype seg noe mer. I vedleggene har vi også gjengitt formler og tabeller som kan være interessante. "],["kvalitet-kvalitetsarbeid-og-statistisk-prosesskontroll.html", "2 Kvalitet, kvalitetsarbeid og statistisk prosesskontroll 2.1 Hva er statistisk prosesskontroll? 2.2 Hvorfor er tid viktig? 2.3 Hva er utgangspunktet vi skal korrigere fra?", " 2 Kvalitet, kvalitetsarbeid og statistisk prosesskontroll En bok om kvalitet og kvalitetsarbeid bør selvsagt tidlig slå fast hva man mener med nettopp begrepene kvalitet og kvalitetsarbeid. Begrepet kvalitet kan gis mange definisjoner og bety ulike ting i ulike kontekster. På et veldig overordnet nivå kan man si at kvalitet er alle egenskaper og karakteristikker en tjeneste eller produkt har som bidrar til å dekke et definert behov (Alemi, Rom, and Eisenstein 1996). Antony, Balbontin, and Taner (2000) peker på at en tjenestes/et produkts kvalitet er evnen til å oppfylle eller overgå en brukers spesifikke behov eller forventninger. Kvalitet er derfor nært knyttet til en oppfattelse av måloppnåelse (Mainz et al. 2018), noe som understreker at kvalitet har både en objektiv og en subjektiv dimensjon. Hvis vi leverer en tjeneste eller et produkt må vi ha antakelser om mottakers forventninger og/eller forholde oss til bestemte forhåndsdefinerte objektive standarder (Elwyn et al. 2007; Wallander, Schmitt, and Koot 2001). Kvalitet kan derfor utrykkes som et forhold mellom resultat og forventninger. Noen elementer av kvalitet kan vi kanskje måle relativt objektivt, mens andre elementer er av mer subjektiv eller skjønnsmessig karakter. Norsk Standard (2000) definerer kvalitet som i hvilken grad en samling av iboende egenskaper oppfyller krav. Disse egenskapene kan være f.eks. kvalitative eller kvantitative, fysiske, sensoriske, atferdsmessige, tidsmessige, ergonomiske og/eller funksjonelle.Men uansett er kvalitet et umulig begrep å forholde seg til uten at man har en eller annen form for sammenlikning med noe annet. Et siste poeng vi vil nevne her er at kvalitet og kvalitesarbeid i en organisasjon må være knyttet til hva organisasjonen har en rimelig grad av kontroll over (Chin and Muramatsu 2003). 2.1 Hva er statistisk prosesskontroll? I følge Benneyan (1998a) er SPC grafisk og statistisk analyse av prosessdata i den hensikt å forstå, monitorere og forbedre prosessytelse. Kort fortalt handler SPC om å samle inn data fra en prosess, sette disse dataene i et tidsperspektiv, analysere og vurdere om prosessen har en normal eller unormal variasjon, og dermed legge grunnlaget for forbedringsarbeid. I tillegg kan SPC overvåke prosesser for å fange opp endringer i resultater på et tidlig tidspunkt. Selv om SPC som regel spores tilbake til Walter A. Shewghart og 1930-tallet, og ikke minst til W. Edward Deming etter 2.verdenskrig, viser Benneyan (1998a) til Frank Gilberths arbeid med prosessanalyser i sykehus så tidlig som i 1916. SPC, og Demings arbeid i Japan, tilskrives mye av æren for den japanske bilindustriens eventyrlige vekst. I følge Leavengood and Reeb (1999) er det rikelig med dokumentasjon på at SPC kan redusere kostnader, øke produktiviteten, øke kundelojalitet, øke kundegrunnlaget og virke positivt inn på ansattes motivasjon. Dessuten, SPC hviler på et solid og robust teoretisk og statistisk grunnlag (Thor et al. 2007). Vi vil likevel advare mot å tro at SPC er en quick fix som nærmest magisk forbedrer prosesser. SPC krever innsikt i prosessene man jobber med, og kan, som alle andre verktøy, produsere absolutt ingenting av verdi eller i verste fall negativ verdi om det brukes på feil måte. Rungtusanatham (2001) viser at som regel skyldes manglende effekt av SPC i organisasjoner ikke SPC i seg selv, men ineffektivitet og naivitet i implenteringen av teknikkene 7 (jfr. f.eks. Lightburn and G Dale 1992). Et annet aspekt verdt å merke seg er at diagrammene og analysene fra SPC gjennomgående beskrives som lette å tolke, skal man være observant på at de kan kontrueres feil (Thor et al. 2007). Et av målene for denne boka er naturligvis å redusere akkurat den muligheten.8 Selv om opprinnelsen til SPC gjennom Shwehart og Deming kan sies å være knyttet til industrielle produksjonsprosesser kan teknikkene anvendes på en hvilken som helst prosess (Benneyan, Lloyd, and Plsek 2003). I en noe forenklet språkdrakt kan SPC sies å være et virkemiddel for å (basert på Benneyan 1998b): Forstå den nåværende prosessens ytelse og karakteristikker Oppnå en konsistent prosesskvalitet og -ytelse Monitorere prosesser for å fange opp begynnende forringelse Redusere prosessvariasjonen Sentralt i SPC er altså (blant annet) å forstå prosessene og variasjonen i prosessene som ligger til grunn for et eller annet produkt eller tjeneste, som utgangspunkt for forbedringsarbeid. Alemi and Sullivan (2001) påpeker at beslutningstakere ofte feilaktig tilegner positive resultater med (deres) intervensjoner og tiltak, og negative resultater med tilfeldigheter eller eksterne hendelser. Gjennom SPC kan beslutningstakere få en forståelse av hvordan prosessene varierer, og om et dårlig resultat påvirkes av tilfeldige/unormale hendelser (som vanskelig kan kontrolleres eller påvirkes) eller er et utslag av systemet i seg selv (som kan kontrolleres eller påvirkes). De tre viktigste verktøyene i SPC er seriediagram, kontrolldiagram og analyse av prosesskapabilitet. Disse tre behandles i egne kapitler. Kort fortalt er seriediagram en sekvensiell plotting av data fra en prosess uten utregning av kontrollgrenser eller hensyn til hva slags data (måledata eller attributtdata - se senere kapitler) vi har. Et seriediagram bør være det første diagrammet man utarbeider og vil si oss noe om variasjonen og om vi kan gå videre med kontrolldiagram. Et kontrolldiagram viser også prosessdata over tid plottet i et diagram, men her regner man ut kontrollgrenser basert på dataene slik at man kan få mer nyanserte analyser. I motsetning til seriediagrammet har vi ulike kontrolldiagram ut fra hvilken type data man har. Til slutt har vi kapabilitetsanalyser. Disse utfører vi for å vurdere om en prosess er i stand til å møte forventninger, og vi kan sammenlikne resultatet fra en prosess med gitte grenser for hva man anser som akseptable grenser. Ofte deles SPC-arbeid inn i to faser (Sachlas, Bersimis, and Psarakis 2019). Den første fasen omfatter innsamling av data og retrospektive analyser for å undersøke om prosessen er under kontroll (altså om variasjonen man observerer er normal eller unormal - se kapittel om variasjon). Den andre fasen brukes SPC til å monitorere prosessen fortløpende for å fange opp endringer i prosessen tidlig. I tillegg vil vi legge til en tredje fase som er forbedringsarbeidet - strengt tatt vil vi ikke definere dette som en distinkt fase da forbedringsarbeidet bør være en kontinuerlig prosess. Vi må også fastslå at SPC er et bredt felt, og det er utenfor rekkevidden av denne boka å omfatte alle tekniske og metodiske aspekter ved SPC. 2.2 Hvorfor er tid viktig? La oss anta at et sykehus har en prosess der man har registrert antall avvik gjennom året. I 2019 hadde man 30 avvik i snitt pr måned. Ledelsen mente mot slutten av 2019 at dette var for høyt og bestemte at man skulle innføre en ny prosedyre fra årsskiftet. Ved overgangen til 2021 så man at man gjennom 2020 hadde ca. 24 avvik pr måned i snitt 9 10: Download prepost_eksempel_long.xlsx Figure 2.1: Eksempel på prosess over 2 år Når man så nærmere på tallene kunne man også se at variasjonen mellom månedene var blitt mindre: Figure 2.2: Prosess over 2 år - spredning Dette er nok en kjent tilnærming og konklusjon for mange som har jobbet med eller i organisasjoner som gjør tiltak for å heve kvaliteten. Dessverre er det en tilnærming som i beste fall er unøyaktig, men som i verste fall tåkelegger hva som faktisk skjer og som over tid kan gi dårligere kvalitet. Problemet er at man ikke har sett dataene i et tidsperspektiv. Siden man har data for avvik hver eneste måned vil tidsperspektivet kunne gi helt andre innsikter og konklusjoner. Figure 2.3: Prosess over 2 år i et tidsperspektiv I diagrammet over har vi plottet inn hver enkelt måned slik at vi får en blå linje som viser utvikling fra måned til måned. Den oransje horisontale streken angir snittet for året (tilsvarende histogrammet lenger opp). Den røde vertikale streken angir årsskiftet og tidspunktet for endring av rutinen. Rent visuelt vil vi nå ha problemer med å konkludere med at endringen av rutinen var en suksess. Vi vil heller tenke at utviklingen gjennom 2019 var veldig positiv, men at endringen ved årsskiftet 2019-2020 har gjort at trenden nå er klart negativ ift at avvikene øker jevnt og trutt igjen. Så kan man spekulere i at det kanskje er innføring av ny rutine som gjør at man igjen får flere avvik og at på litt lengre sikt vil man ha en positiv effekt. Kanskje, det vil vi ikke se før tallene for 2021 begynner å tikke inn. Men det er grunn til å si at dersom man kunne se denne trenden etter 1.kvartal i 2020 hadde man kanskje vurdert tiltak for å endre trenden (eller i det minste gjort en grundig analyse av rutiner og tiltak). Eksempelet ovenfor er konstruert. Likevel er det grunn til å tro at det ikke er spesielt uvanlig. Mange vil nok kunne kjenne seg igjen i at det jobbes mye med kvalitet i ulike organisasjoner, men at man kanskje ikke har spesielt god kontroll på hva endringer gjør med prosesser, eller at man ikke klarer å fange opp tidsnok at utviklingen går i feil retning. Kanskje har man egentlig lite kontroll på selve prosessen før man starter en endringsprosess? Tidsaspektet er med andre ord et viktig aspekt å ha med seg, og helt essensielt i statistisk prosesskontroll som vi hevder bør ha en sentral plass i kvalitetsarbeid. 2.3 Hva er utgangspunktet vi skal korrigere fra? Det kan kanskje virke selvsagt, men en forbedringsprosess vil ha små og tilfeldige sjanser for å lykkes hvis vi ikke kjenner utgangspunktet. Vi vil påstå at mange slike prosesser likevel starter opp med et noe svakt kjennskap til hva startstedet egentlig er. Kvalitetsarbeid  forbedringsprosesser  startes som regel fordi man har en oppfatning av at det man leverer ikke er like godt som det man mener man kan og bør levere. Men hva er egentlig problemet? Er det treffsikkerheten (treffer vi målet, det vi sikter mot) eller konsistensen (klarer vi å repetere hendelsen gang etter gang), eller begge deler?11 Figure 2.4: Kjenne til utgangspunktet før vi gjør endringer Det er ganske innlysende at vi vil ha langt større sannsynlighet for å lykkes med en forbedringsprosess om vi har kontroll på hva startsituasjonen er. Her kommer statistisk prosesskontroll inn og kan være et viktig verktøy. Med unntak av den nedre høyre illustrasjonen, der både treffsikkerhet og konsistens er bra, viser alle målskivene en variasjon i hvordan treffene er. Variasjon er et essensielt begrep i statistisk prosesskontroll, og forståelse av variasjon vil følgelig være et viktig tema før vi gir oss i kast med selve analysene. Uten forståelse av prosess og variasjon er det fare for at man forsøker å justere en prosess på feil grunnlag, og i verste fall ville vi kommet bedre ut av endringsprosessen ved å ikke gjøre noe som helst. "],["variasjon.html", "3 Variasjon 3.1 Simulering av trakteksperimentet i R 3.2 Normal og unormal variasjon", " 3 Variasjon Vi skal tilnærme oss begrepet variasjon gjennom å vise til et velkjent eksperiment  «The Funnel Experiment», eller trakteksperimentet som vi kan kalle det på norsk. Hensikten med trakteksperimentet var å vise at dersom vi ikke forstår variasjon, og introduserer korrigerende tiltak i prosesser som ikke trenger det, står vi i fare for å forverre resultatet (og ofte ha brukt mye tid og ressurser på å justere prosessen i den tro at resultatet vil bli bedre). Eksperimentet illustrerer at mange tiltak i organisasjoner for å «rette på feil» eller «forbedre kvaliteten» ender opp med å ha motsatt virkning. Trakteksperimentet - oppsett Trakteksperimentet ble popularisert av Deming (1986) for å beskrive de negative effektene prosessendringer kan ha hvis man ikke forstår årsakene til variasjonen i resultatene (Deming krediterer selv Lloyd Nelson for å ha designiet ekseperimentet, og enkelte kilder omtaler derfor dette som the Deming-Nelson funnel experiment (Georgantzas and Orsini 2003) . I trakteksperimentet lar vi en klinkekule falle gjennom en trakt vi har sentrert rett over et mål. Der kula treffer arket setter vi et merke. Kula vil aldri treffe nøyaktig på målet og aldri nøyaktig på samme sted fra gang til gang. La oss si at vi slipper kula gjennom trakta første gang. Trakta er plassert slik at senterlinja gjennom trakta treffer nøyaktig midt i målet. Så slipper vi kula og registerer treffpunktet. Trakteksperimentet - oppsett Deretter bruker vi 1 av 4 regler for korreksjon for å justere prosessen for å forsøke å få kula til å treffe nærmere målet (se f.eks. (Sparks and Field 2000). Regel 1 Ingen justering. Selv om kula ikke treffer målet fortsetter vi med neste forsøk uten å gjøre noen justeringer. Vi holder trakta på nøyaktig samme sted. Regel 2 Trakta justeres etter forrige treffpunkt (treff 1). Hvis kula treffer i z avstand fra målets senterpunkt vil trakta justeres med -z før neste forsøk. Trakteksperimentet - treff etter første forsøk Så gjentar vi prosessen og korrigerer trakta fra traktas forrige posisjon etter hvert treffpunkt ut fra kulas avstand fra det nye treffpunktet til målets senterpunkt. Justering av trakta skjer etter følgende metode: Plassering av trakta starter i målsenteret (0,0) og justeres deretter slik at ny plassering blir målsenteret blir minus offset (retning og avstand) for forrige kule fra treffpunkt til målsenteret. Sparks and Field (2000) beskriver regelen slik: At drop i (i = 1,2,3, .) the marble will come to rest at point yi, measured from the target. (In other words, yi is the error at drop i.) Move the funnel the distance -yi from its last position to aim for the next drop. Deming (1986) gir noen eksempler på bruk av regel 2: feedback-mekanismer som reagerer på enkelttilfeller, endring av en policy, rutine e.l. på bakgrunn av (kun) siste kundeundersøkelse, bruke variasjon/avvik til å lage budsjetter og vurdering av en aksje basert på forrige måneds underskudd. Regel 3 Her registrerer vi treff 1 som i regel 2. Vi flytter trakta til et punkt nøyaktig motsatt av det punktet kula fikk. Vi beregner offset for kula på samme måte som i regel 2  retning og avstand fra målsenteret til kulas treffpunkt. Før vi justerer flytter vi imidlertid trakta tilbake til (0,0) og justerer derfra (i motsetning til regel 2 da vi ikke flyttet trakta til (0,0) før vi begynte korreksjonen, men i stedet foretok justeringen fra det punktet trakta befant seg da kula ble sluppet). Her eksemplifiserer Deming (1986) ved å vise til hvordan mer effektiv narkotikabekjempelse fører til høyere priser på narkotika som stimulerer til smugling av mer narkotika, eller en gambler som høyner innsatsen for å dekke forrige tap. Sparks and Field (2000) beskriver regelen slik: At drop i the marble comes to rest at point yi from the target, then for the next drop aim the funnel over the point -yi from the target. Regel 4 Her flytter vi trakta hele tiden til siste treffpunkt og slipper ny kule der. Her viser Deming (1986) til eksempler som den kjente «hviskeleken» der et antall personer sitter i en ring og gjenforteller en historie ved å hviske den til neste person, som igjen hvisker den til neste osv til den kommer til siste person som forteller historien vedkommende nettopp hørte. Historien som til slutt blir fortalt er som regel ganske annerledes enn den opprinnelige. Et annet eksempel kan være produksjon av en gjenstand basert på forrige produserte gjenstands mål. Sparks and Field (2000) beskriver regelen slik: At drop i the marble comes to rest at point yi from the target, then for the next drop aim the funnel over the spot yi where the marble last came to rest. En kort og instruktiv video (Crostic 2015) om gjennomføringen av trakteksperimentet vises kan dere se her. 3.1 Simulering av trakteksperimentet i R Vi kan kjøre en simulasjon som viser at resultatet blir suksessivt dårligere etter hvert som vi implementerer reglene. Best resultat kommer fra ingen justering. Dernest gir regel 2 nest best resultat, regel 3 nest dårligst, og til slutt regel 4 det dårligste resultatet. Ved en simulering av 100 repetisjoner kan vi grafisk se hvilket resultat vi får gjennom å anvende de fire ulike reglene. For å kjøre R-koden (jfr vedlegg) må du laste ned disse Excel-filene: Download Funnel_blankedata_regel3.xlsxDownload Funnel_blankedata_regel4.xlsx Figure 3.1: Simulering av trakteksperimentet Det vi kan se er at resultatet etter regel 1 og 2 er sentrert rundt målet, men at regel 2 gir større spredning. Simuleringer viser at regel to gir 40-41 % større areal i plottet  eller dobbelt så stor varians (Prevette 2008; SPC for Excel 2006) 12. Regel 3 vil gi et økende oscillerende mønster. Med en start i nærheten av målet (0,0) vil treffpunktene flytte seg fra side til side stadig lengre vekk fra målet. Mønsteret vil variere, men treffpunktene vil stadig flytte seg lenger unna målet. Hvis vi har et annet førstetreff, vil dette påvirke hvordan mønsteret utvikler seg. For å kjøre R-koden for alternativt førstetreffpunkt må du laste ned denne Excel-fila: Download Funnel_blankedata_regel3_2.xlsx Figure 3.2: Regel 3 - annet førstetreff Regel 4 vil alltid medføre at treffpunktet vil bevege seg lenger og lenger unna målet. Med et annet førstetreff vil mønsteret se annerledes ut. For å kjøre R-koden for alternativt førstetreffpunkt må du laste ned denne Excel-fila: Download Funnel_blankedata_regel4_2.xlsx Figure 3.3: Regel 4 - annet førstetreff Eksperimentet, som altså som regel refereres til som Demings trakteksperiment (Funnel experiment), men som også omtales som Nelsons trakteksperiment (se f.eks. Alwan (1991)) illustrerer en viktig erkjennelse i alt kvalitetsarbeid: hvis man ikke vet hva man driver med kan man i beste hensikt fort ende opp med å korrigere en prosess ut i evigheten vekk fra målet. Dessverre er det grunn til å tro at mange forbedringsprosesser ender opp på denne måten. Eksperimentet illustrerer videre en viktig observasjon: alle prosesser har variasjon. Hvis vi tenker over det, vil vi lett finne eksempler fra dagliglivet. Vi sover et antall timer og minutter sammenhengende søvn hver natt som ikke vil være det samme fra natt til natt, men som regel ligge innenfor et visst intervall. Vi har en hvilepuls når vi våkner om morgenen. Måler vi den vil vi se variasjon. Vi kjører til jobben, og tidsbruken vil variere fra dag til dag. Vi tar en treningstur på kvelden. Selv om vi løper samme runde med samme utstyr vil tiden vi bruker variere. Eller strømregningen vi betaler hver måned. Hva med kostnader for en sykehusavdeling? Antall overtidstimer i en organisasjon? Mengde materialer i en bestemt produksjonslinje? Alle de ovennevnte er prosesser som har en variasjon. 3.2 Normal og unormal variasjon Et sentralt poeng i organisasjonsutvikling og beslutningstaking er om den variasjonen man ser i resultatene er et tegn på endring eller bare tilfeldig variasjon. For beslutningstakere er det åpenbart avgjørende å kunne skille mellom de to (Nolan and Provost 1990). Variasjon kan være normal eller unormal. Med normal variasjon mener vi variasjon som ikke kan tilskrives en spesiell årsak (ofte omtalt som common cause variation, opprinnelig av Shewhart som assignable cause og av f.eks. Benneyan (1998a) som systemic variation). Tilsvarende kan unormal variasjon tilskrives en eller flere spesifikke årsaker (special cause variation, av Shewhart benevnt som chance cause). Normal variasjon skyldes fenomen som alltid er til stede i en prosess (Plsek 23AD), og kan dermed ikke endres uten at man endrer selve prosessen. Det betyr også at normal variasjon er det som gjør prosesser forutsigbare i større eller mindre grad. Unormal variasjon på sin side skyldes en (eller flere) ikke-tilfeldige påvirkninger som ikke vanligvis er til stede i prosessen. Dette gjør prosessen uforutsigbar. Problemene oppstår når man ikke skiller mellom de to typene variasjon, og jager etter spesielle årsaker til variasjon når det i realiteten kun er normal variasjon man observerer. Da jager man etter å løse problemer uten å forstå årsakene. La oss se på dataene fra trakteksperimentet igjen, og denne gangen skal vi plotte datapunktene på en måte som gjør at vi ser hvordan treffpunktene varierer ved at vi plotter på en tidsakse (første forsøk til venstre, siste til høyre på x-aksen). Vi kan først se på treffpunkter for x- og y-verdi for hhv regel 1 og 2. Figure 3.4: x- og y-verdier for regel 1 Figure 3.5: x- og y-verdier for regel 2 Det vi kan se er: * Mønstrene likner på hverandre i hvordan de varierer * De varierer like mer eller mindre like mye over og under x = 0 og y = 0. En absolutt perfekt prosess ville gitt null avvik fra 0,0 for hvert forsøk. Dette tyder på at variasjonen er sentrert rundt målpunktet. * Vi kan se at avviket er noe større for regel 2, spesielt på x-verdiene. Dette er iht forventning siden vi vet at variansen er dobbelt så stor for regel 2 som for regel 1. * Vi ser også at gjennomsnittet (markert med horisontal linje) er nærme 0 for både x- og y-verdi for regel 1, mens den er noe mer avvikende for begge verdiene for regel 2. Hvis vi ser på x- og y-verdiene for regel 3 får vi et helt annet bilde. Figure 3.6: x- og y-verdier for regel 3 Vi ser at vi får en økende oscillerende trend. Samtidig ser vi at treffene er sentrert rundt 0, men at treffpunktene i stadig økende grad fjerner seg fra 0. Mønsteret er også veldig likt for x-verdi og y-verdi. Til slutt kan vi se på regel 4. Figure 3.7: x- og y-verdier for regel 4 Det vi kan legge merke til er at begge verdiene starter nærme 0, men at de  som forventet  etter hvert fjerner seg i en trend vekk fra 0. Hadde man kjørt 1000 eller 10000 forsøk ville denne trenden vært enda tydeligere. Dette leder oss til to begrep som er vesentlige i kvalitetsarbeid. Er prosessen kontrollert («in control») eller er den ukontrollert («out of control»)? Prosesser med kun normal variasjon er kontrollerte prosesser, mens prosesser med unormal variasjon er ukontrollerte prosesser. I en kontrollert, stabil prosess er årsakene til variasjon i ytelse/resultater konstant over tid. Dette betyr altså ikke at det ikke er variasjon i ytelse/resultater/kvalitet, at variasjonen er liten eller at kvaliteten er god nok. Under har vi simulert to team som jobber parallelt med å produsere samme produkt, samme maskiner, med samme råmaterialer. Vi skal ikke gå nærmere inn på variasjon o.l., men kan kort konstatere at begge prosessene er i kontroll. Vi kommer tilbake til kontrollgrenser om kort tid, men kort fortalt må alle punkter ligge innenfor kontrollgrensene for at prosessen skal være i kontroll. For å kjøre R-koden må du laste ned følgende fil: Download toteam.xlsx Figure 3.8: To teams kontrolldiagrammer Imidlertid ser vi at Team 1s prosess har større variasjon enn team 2s (selv om de ser like ut må vi ta hensyn til at y-aksene er ulike (legg merke til verdiene 1,2 og 0,4 som viser den øvre kontrollgrensen. Vi ser også at gjennomsnittet ligger på hhv 0.5 og 0.1 for team 1 og 2. Dersom vi arrangerer plottene med samme skala på y-aksen ser vi en klar forskjell mellom de to teamene: Figure 3.9: To teams - like prosesser - ulik variasjon Vi trenger altså ikke være fornøyde med en stabil og kontrollert prosess. Det betyr bare at variasjonen er forutsigbar innenfor statistisk etablerte grenser (Nolan and Provost 1990), og at ytelsen fra prosessen ikke vil endre seg vesentlig med mindre man endrer selve prosessen.Begge prosessene over er kontrollerte, men det kan virke åpenbart at man vil se nærmere på hvorfor det ene teamet skiller seg veldig fra det andre. Arbeidet med statistisk prosesskontroll handler i hovedsak om dette: Forstå prosessen og forstå variasjonen. Trakteksperimentet viser oss også at korreksjon av prosesser kan lede oss lenger og lenger fra målet om vi ikke forstår variasjon og kontrollerte vs. ukontrollerte prosesser. Deming omtaler dette som «tampering with the process» - tukling med prosessen («If it aint broken, dont fix it»). I jakten på små forbedringer er det fristende å gjøre små justeringer ofte. Det kan være en smart strategi, men det kan også gi motsatt effekt: variasjonen i resultatene blir bare større og større (i takt med desperasjonen etter ønskede forbedringer). Dette vil vi kalle for over-kontrollering av prosesser. Erkjennelsen av variasjon i prosesser og om prosesser i kontrollert eller ukontrollert har klare ledelsesmessige utfordringer og konsekvenser. Nolan and Provost (1990:s.3, figur 1) illustrerer to ulike tilnærminger til variasjon: Områder Tradisjonell SPC Som indikator på god eller dårlig ytelse Som resultat av normal eller unormal variasjon Fokus Resultat av prosessen (produkt, tjeneste) Årsaker til variasjon i prosessen Mål Klassifisere resultat som akseptabelt eller ikke Gi grunnlag for endring av prosess Grunnlag Hva kunden ønsker eller trenger Hva prosessen faktisk gir Metoder Spesifikasjoner, budsjetter, prognoser, numeriske mål, verktøy for å måle ytelse Kontrolldiagram En klar svakhet ved den første tilnærmingen  som indikator på god eller dårlig ytelse  er at det tilbyr lite informasjon og grunnlag for forbedring. Likevel, mange vil nok kjenne seg igjen i fokus, mål, grunnlag og metoder i denne tilnærmingen. En kjerne i ledelse i organisasjoner må derfor være å kunne avgjøre om variasjonen fra ulike prosesser er normal eller unormal, og om svingninger indikerer en trend eller en tilfeldig variasjon som følger mønstre vi har sett tidligere. Nolan and Provost (1990) peker på mulige konsekvenser i organisasjoner av å trekke feilslutninger om variasjon: Skylden for problemer legges på ansatte som er utenfor deres kontroll, kostnader til nytt utstyr som ikke er nødvendig, bortkastet tidsbruk for å lete etter forklaringer på en antatt trend når ingenting egentlig har endret seg og gjennomføre tiltak når det ville ha vært bedre å ikke gjøre noe. Avslutningsvis i dette kapittelet er det på sin plass å presisere at selv om en prosess kun har naturlig variasjon og således er kontrollert betyr ikke det at verken variasjonen eller resultatet er akseptabelt (Benneyan et al. 2003; Fasting and Gisvold 2003; Leavengood and Reeb 1999). En kontrollert prosess innebærer kun at variasjonen er forutsigbar etter statistisk etablerte grenser (Nolan and Provost 1990). Vi kan dermed forutsi prosessens resultater inntil det skjer en fundamental endring i prosessen. Det vi også kan si er at dersom man ikke er tilfreds med variasjon og resultat fra en prosess kan man gjøre noe med dette (=forbedre prosessen) dersom prosessen er kontrollert (Mohammed et al. 2001). Deming (1986) peker på at det store rommet for forbedring (94 %) ligger i endring av prosessen  altså i å jobbe med den normale variasjonen (gitt at prosessen er stabil). Kun 6 % av potensialet ligger i å fikse spesielle ting  unormal variasjon  som skjer. Her ser vi en veldig klar kobling til ledelsesaspektet og ledelsesansvaret som ligger i å realisere potensialet for forbedringer. Det er imidlertid viktig å alltid huske tre sannheter om kvalitetsarbeid (Plsek 23AD): Variasjon i resultat er naturlig i alle prosesser. Tilstedeværelse av variasjon er derfor ikke nok grunnlag for å konkludere med at prosessen er ute av kontroll eller trenger endringer. Hvis vi gjennomfører endringer uten å kjenne til hva slags variasjon vi har kan vi ende opp med å øke variasjonen. Variasjon er med andre ord ikke synonymt med varierende kvalitet For beslutningstakere kan vi derfor sette opp tre handlingsmønstre: Hvis prosessen viser unormal variasjon må vi forsøke å finne og eliminere den unormale variasjonen. Hvis prosessen viser normal variasjon og vi er tilfredse med resultetene er det best å ikke gjøre noe med prosessen ut over å monitorere variasjonen. Hvis prosessen viser normal variasjon og vi ikke er tilfredse med resultatene må vi jobbe med selve prosessen for å redusere variasjonen. "],["datatyper-og-datafordelinger.html", "4 Datatyper og datafordelinger 4.1 Normalfordeling 4.2 Binomialfordeling 4.3 Poissonfordeling 4.4 Geometrisk fordeling 4.5 Eksponensiell fordeling", " 4 Datatyper og datafordelinger Ift statistisk prosesskontroll er det formålstjenlig å snakke om tre hovedtyper data: måledata, telledata og sjeldne hendelser. Måledata er kontinuerlige data  det vil si de kan måles på en skala som høyde, vekt og tid. Her kan en observasjon/et datapunkt innta en hvilken som helst verdi innenfor et gitt spenn. Høyden på en person kan være 178,34227809 cm eller 178,34227808 cm. Telledata et kategoriske (også ofte omtalt som diskrete) data  det vil si et datapunkt (en observasjon) kan puttes inn i en klar kategori, som f.eks. antall avvik, antall hendelser, ja/nei, terningkast. Diskrete data har et begrenset antall mulige verdier som er gjensidig utelukkende. Et terningkast med en vanlig terning kan ikke både være 3 og 4 samtidig, en lysbryter kan ikke være av og på samtidig. Et terningkast kan heller ikke være 1,43. Med tanke på datafordeling er både binomial-, Poissonfordeling og geomterisk fordeling diskrete fordelinger, mens normalfordeling og eksponensiell fordeling vil være kontinuerlig (se f.eks. Ugarte, Militino, and Arnholt (2016)). Når det gjelder sjeldne hendelser kan de være både telledata og måledata. For eksempel vil antall dager mellom en hendelse være en diskret data, mens tid kan måles og vil være kontinuerlige data. Det er spesielle utfordringer med det vi kaller sjeldne hendelser finnes det også egne måter å håndtere dette på i statistisk prosesskontroll, noe vi vil komme tilbake til. For sjeldne henselser vil både geometrisk og eksponensiell fordeling være relevant. Det finnes en god del flere fordelinger enn disse som nå er nevnt, men som Benneyan (1998a) viser er normal-, binomial- og Poissonfordeling de tre vesentligste. For en god oversikt over flere fordelinger, se f.eks. Mun (2008). Hvorfor fokus på fordelinger? Fordelingene  normalfordeling, binomialfordeling, Poissionfordeling, geometrisk fordeling og eksponensiell fordeling  beskriver ulike fordelinger ut fra hvordan dataene ser ut. Vi bruker forventningene/sannsynlighetene for ulike verdier i statistisk prosesskontroll til å vurdere om en verdi av en observasjon eller måling er innenfor eller utenfor det vi vil kalle normal variasjon (jfr kapittelet om variasjon). Siden dataene kan være av ulik type  diskret eller kontinuerlig, binomial/ikke binomial osv  bruker vi ulike utregningsmetoder og diagrammer i statistisk prosesskontroll for å få et riktig resultat. Det finnes et antall ulike diagrammer å velge mellom i statistisk prosesskontroll. For å gjøre valget sikrere og lettere kan man bruke følgende flytskjema for å orientere seg. Siden lesbarheten er litt dårlig for flytskjemaet under kan følgende også brukes: Download Flytdiagram_valg.html Flytdiagram for valg av analyse Senere kommer vi tilbake til de ulike diagrammene gjennom praktiske eksempler. Før vi kommer dit vil vi gå gjennom de sentrale datafordelingstypene. 4.1 Normalfordeling Når vi snakker om distribusjonen av et datasett tenker vi på hvordan dataene vi har samlet inn fordeler seg i forhold til hverandre etter gitte egenskaper. Vi kan for eksempel ha målt høyden på 100 mennesker. Disse dataene utgjør da en observert fordeling som vi kan sette inn i et diagram for å visualisere hvordan datasettet ser ut. Figure 4.1: Høydefordeling for 100 tilfeldige menn, genererte data Hvis vi samler inn høydedata for 100 andre tilfeldig menn kan fordelingen se slik ut: Figure 4.2: Høydefordeling for 100 andre tilfeldige menn, genererte data Hver gang vi måler høyden på 100 tilfeldig utvalgte menn vil fordelingen se ulik ut siden de er observerte fordelinger i et utvalg av populasjonen (alle) «norske menn». Hvis vi imidlertid økte antallet i utvalget vi målte til 1000 eller 10000 vil vi med større sikkerhet kunne si at vi faktisk viser populasjonens fordeling (mulighetene for at vi tilfeldigvis måler 10000 veldig lave eller veldig høye menn er svært liten). Vi kan derfor, gitt visse forutsetninger om utvalget, si noe om hele populasjonen ut fra utvalget. Hittil har vi snakket om observerte fordelinger. Ut fra dette kan vi si at vi kan ha visse forventninger til hvordan fordelingen av ulike populasjoner vil se ut, og vi kan snakke om teoretiske fordelinger  eller sannsynlighetsfordelinger med andre ord. Hvor sannsynlig er det at en tilfeldig x-verdi dukker opp i dataene? For høyde kan vi ha visse forventninger til hvilke sannsynligheter det er for at en tilfeldig person har en gitt høyde, eller hvor mange prosent av den mannlige befolkningen som har en høyde innenfor et gitt intervall. Det vil si at fordelingen har en viss form med visse karakteristika. Vi forventer at flest observasjoner befinner seg i nærheten av gjennomsnittet, og at vi vil se færre og færre observasjoner jo lenger unna gjennomsnittet vi beveger oss. Vi forventer å finne flere norske menn over 20 år på rundt 180 cm enn 160 cm eller 210 cm. For fordelingen av høydedata vil vi si at dette er data som er normalfordelte. En normalfordeling er en sannsynlighetsfunksjon der flesteparten av verdiene fra funksjonen samler seg om en sentral tendens, og der tettheten (hyppigheten) av verdier avtar jevnt jo lenger unna den sentrale tendensen man kommer. Grafisk framstilt får fordelingskurven en klokkeform, og normalfordeling omtales også som bell shaped. Overraskende mange fenomener viser seg å være nærme en normalfordeling, og den er derfor en helt sentral teoretisk sannsynlighetsfordeling i mange sammenhenger (også i statistisk prosesskontroll som vi kommer tilbake til senere). Vi bruker dermed normalfordelingen som en modell for observerte data. I en såkalt standard normalfordeling har vi en symmetrisk fordeling der den sentrale tendensen (forventingen) verdi = 0 og et standardavvik = 1. Vi skal her ikke bry oss om det matematisk uttrykket for sannsynlighetstetthetsfunksjonen. Hvis vi derimot genererer et tenkt datasett etter standard normalfordelingsfunksjon vil det kunne se slik ut: Figure 4.3: Genererte standard normalfordelte data Her kan vi legge på en forventningskurve  en teoretisk kurve som viser en standard normalfordeling: Figure 4.4: Genererte standard normalfordelte data med normalfordelingskurve Vi kan ta bort det genererte datasettet og sitte igjen med bare normalfordelingskurven: Figure 4.5: Normalfordelingskurve Det den standardiserte normalfordelingskurven (også kjent som Gausskurven eller også Bellkurven  Klokkekurven fordi den har en klokkeform)  kan brukes til er å si noe om spredningen på forventede verdier  eller hvor langt fra gjennomsnittsverdien man kan forvente å finne de enkelte verdiene. Før vi ser nærmere på egenskaper ved normalfordelingskurven kan det være nødvendig å gå litt inn på begrepene varians og standardavvik som mål på spredningen i datasett. Disse begrepene, spesielt standardavvik, vil være helt sentrale i videre arbeid med temaet. 4.1.1 Varians og standardavvik Variansen i en variabel representerer det gjennomsnittlige avviket fra gjennomsnittsverdien (Field, Miles, and Field 2012) og er et mål på spredningen i dataene (som navnet antyder: hvor mye dataene variere ut fra den sentrale tendensen). Under vises et eksempel basert på Field (2009). La oss anta at vi har spurt 5 studenter på høgskolen hvor mange kjæledyr de har. Svarene kan settes opp i en enkel tabell. I gjennomsnitt har de 2,6 kjæledyr. Vi ønsker imidlertid å se hvor mye avviket er for den enkelte fra snittet (siden vi har regnet ut snittet kan vi se på gjennomsnittsverdien som en modell på forholdet mellom studenter og antall kjæledyr). Vi registrerer svarene vi fikk i et skjema: .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-2133aa38{table-layout:auto;width:100%;}.cl-212b0518{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-212b4c4e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-212b99ec{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-212b99ed{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-212b99ee{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} StudentnrAntallAvvikAvvik_kvadrert11-1.62.5622-0.60.36330.40.16430.40.16541.41.96Snitt2.6Sum05.20 Når vi regner ut avviket (sum of deviances) summerer vi avvikene. Siden denne er 0 skulle det innebære at det totalt sett i modellen ikke er avvik mellom modellen og våre virkelige observasjoner. Problemet her er at det er både positive og negative avvik som nuller hverandre ut. Man må derfor kvadrere avvikene for å omgå problemet med fortegn. Imidlertid får vi et nytt problem. La oss anta at vi i stedet for 5 studenter har spurt 500. Da får vi et svært høyt kvadrert avvik fra snitt. Altså  vi må ta høyde for for antallet observasjoner. Vi deler derfor sum kvadrert avvik fra snitt på antall observasjoner (5,20/5). MEN: vi må foreta et litt teknisk og komplisert tillegg i utregningen. Vi må dele på antall observasjoner MINUS 1 (som er antallet frihetsgrader  degrees of freedom). Dette vil ikke bli nærmere forklart her, men for de som ønsker å lese mer om frihetsgrader kan prøve noen andre kilder, f.eks. Walker (1940), Good (1973) eller Pandey and Bright (2008). Vi ender altså opp med regnestykket 5,20/(5-1) = 1,3. Dette er variansen. Variansen er altså det gjennomsnittlige avviket mellom gjennomsnittsverdien av de observerte dataene og verdiene til de enkelte observasjonene. Som regel snakker vi imidlertid om standardavviket. Dette finner vi ved å ta kvadratroten av variansen (som vi jo har funnet ved å kvadrere avvikene for å unngå fortegnsproblemer). Vi får da i vårt tilfelle et standardavvik på 1,14. Variansen og standardavviket forteller oss altså noe om spredningen i dataene. Liten varians betyr at spredningen er liten (om vi har gjennomført en spørreundersøkelse betyr det at respondentene har svart ganske likt). Stor varians betyr stor spredning (respondentene har svart ganske ulikt). 4.1.2 Normalfordeling, standardavvik og forventninger Vi kan nå se nærmere på normalfordelingen. Figure 4.6: Normalfordeling med 1 standardavvik Ett standardavvik over og under 0 (= det skraverte området i grafen over) innebærer at det er 68 % sannsynlighet for at en tilfeldig valgt x-verdi befinner seg i dette intervallet. Vi kan vise det samme for 2 og 3 standardavvik: Figure 4.7: Normalfordeling med 2 standardavvik To standardavvik over og under 0 (= det skraverte området i grafen over) innebærer at det er 95 % sannsynlighet for at en tilfeldig valgt x-verdi befinner seg i dette intervallet. Vi kan finne arealet mellom x=-2 og x=2, som er 0.954499713. Figure 4.8: Normalfordeling med 3 standardavvik Tre standardavvik over og under 0 (= det skraverte området i grafen over) innebærer at det er 99.7 % sannsynlighet for at en tilfeldig valgt x-verdi befinner seg i dette intervallet. Vi kan finne arealet mellom x=-3 og x=3, som er 0.997300214. Dette utgjør et kjernepunkt i statistisk prosesskontroll som vi vil komme mye tilbake til. Oppsummert kan vi framstille normalfodeling og standardavvik slik (Hartmann, Krois, and Waske 2018b): Figure 4.9: Normalfordeling med standardavvik Som nevnt er mange fenomener i hverdagen normalfordelte, eller nærme nok normalfordeling til at vi kan bruke normalfordeling som teoretisk modell for observerte data 15. Det finnes imidlertid mange tilfeller der vi ikke kan bruke normalfordelingen. Hvis dataene er sterkt asymmetriske vil ikke reglene for normalfordeling som vi har skissert ovenfor gjelde 16. Noen av de er viktige for statistisk prosesskontroll, og de vil vi se på i de følgende avsnittene. 4.2 Binomialfordeling En distribusjon hvor det kun er to mulige utfall av en hendelse kalles en binomial fordeling. Et myntkast er en slik hendelse (gitt at vi ser bort fra den fysiske muligheten at mynten kan lande stående på høykant). Levende eller død kan også være et eksempel på dette. Det ene utfallet utelukker det andre, men de er uavhengige fordi resultatet i ett myntkast ikke påvirker resultatet i neste myntkast. Alle myntkastene må derimot være identiske, det vil si sannsynligheten for det ene eller det andre resultatet er lik hver gang forsøket eller myntkastet gjennomføres. Hvis vi har lik sannsynlighet, kan en tilfeldig generert binomial distribusjon se slik ut: Figure 4.10: Binomialfordeling med lik sannsynlighet I diagrammet over vises en sannsynlighetsfordeling for en binomial fordeling der utfallene suksess/fiasko har lik sannsynlighet. Hvis vi gjennomfører en aktivitet med disse karakteristika 20 ganger kan vi bruke sannsynlighetsfordelingen til å skape en forventning om sannsynligheten for antall suksesser/fiaskoer. Hver gang vi gjennomfører aktiviteten blir det enten suksess eller fiasko. Hvis vi har 50% sjanse for suksess eller feil hver gang vi gjennomfører aktiviteten er sannsynligheten for suksess lik som sannsynligheten for fiasko. Vi kan da forvente at det er størst sannsynlighet at vi i 10 av 20 tilfeller får suksess. Det er liten sannsynlighet for at vi enten får suksess i 0 eller 20 av 20 ganger vi gjør aktiviteten. Det er imidlertid verdt å merke seg at de to utfallene ikke trenger å ha lik sannsynlighet. Da vil den binomiale distribusjonen se annerledes ut: Figure 4.11: Binomialfordeling med ulik sannsynlighet Her har vi bare 20% sannsynlighet for suksess, og fordelingen av sannsynligheter vil se annerledes ut. Med 20% sannsynlighet for suksess er det veldig liten sannsynlighet for at vi vil få 10 eller flere suksesser hvis vi gjør forsøket 20 ganger. Det er størst sannsynlighet for å få 4 suksesser. Et terningkast (med en vanlig terning med 6 sider)  som ikke er tuklet med  har lik sannsynlighet for å lande på hhv 1,2,3,4,5 og 6. Det vil si det er 1/6 sannsynlighet for 1, 1/6 sannsynlighet for 2 osv. Hvis vi kaster denne terningen 10 ganger kan resultatet se slik ut: Figure 4.12: 10 terningkast Vi ser at vi ikke fikk noen 2ere og 5ere. Dette kan vi forvente når vi bare har 10 terningkast. Hvis vi imidlertid kaster terningen 100 ganger vil det være svært liten sannsynlighet for å ikke få «treff» på alle 6 verdiene på terningen, og vi burde kunne forvente at vi får en ganske jevn fordeling på alle 6 verdiene. Nedenfor vises resultatet av 100 terningkast. Figure 4.13: 100 terningkast Vi ser at vi har en relativt jevn fordeling. Noe ulikhet er det selvsagt, noe vi vil forvente fra en tilfeldig prosess. Hvis vi gjennomførte 1000 eller 10000 terningkast vil fordelingen bli nærmere og nærmere den teoretisk forventede fordelingen. Vi kan burde, teoretisk, forvente 100 treff på hver mulighet hvis vi kaster terningen 600 ganger, men vi vil sjelden se akkurat 100 treff på hver slik vi ser hvis vi kjører tre runder med 600 terningkast: Runde 1: ## terning_runde1 ## 1 2 3 4 5 6 ## 93 102 102 102 108 93 Runde 2: ## terning_runde2 ## 1 2 3 4 5 6 ## 101 102 94 91 105 107 Runde 3: ## terning_runde3 ## 1 2 3 4 5 6 ## 104 113 92 98 95 98 Selv om vi kjører 6 000 000 terningkast og vil forvente 1 000 000 treff på hver av terningens sider vil vi ikke få en perfekt fordeling iht teoretisk forventning, men resultatet vil være svært nærme og er nærme nok til at vi kan bruke sannsynlighetsfordelingen til å lage forventninger om utfall: 6 000 000 terningkast: ## minterning ## 1 2 3 4 5 6 ## 1000492 998250 1000216 1000832 1001422 998788 Hvis vi setter resultatet fra 6 000 000 terningkast inn i et histogram ser vi at resultatet er svært nærme hva vi teoretisk vil forvente: Figure 4.14: 6 000 000 terningkast 4.3 Poissonfordeling Poissonfordelinger finnes i situasjoner der hendelser skjer vilkårlig i tid (og rom) hvor vi er interessert i kun antallet hendelser i et gitt tidsintervall. Vi kan f.eks. være interessert i hvor mange supporthenvendelser vi får i løpet av en time, antallet feilmedisineringer per uke, hvor mange besøk avdelingen får per dag o.l. Andre eksempler kan være antall trafikkulykker langs en angitt veistrekning, antall elgpåkjørlser på en togstrekning, eller antall av en gitt art fugler i et definert område i et definert tidsrom. En hendelse må være uavhengig tidsmessig av andre hendelser (det er altså ikke økt sannsynlighet for at en hendelse vil skje fordi en tilsvarende hendelse akkurat har skjedd), sannsynligheten for en hendelse i et kort perspektiv er lik sannsynligheten over et lengre perspektiv, og ettersom et tidsintervall blir kortere og kortere vil sannsynligheten for hendelsen gå mot null. Poissonfordeling uttrykker sannsynligheten for at et gitt antall hendelser inntreffer i et gitt tidsintervall (eller et gitt geografisk domene) og at vi kjenner gjennomsnittlig hvor ofte hendelsen inntreffer. Denne sannsynligheten uttrykkes som en lambdaverdi (\\(\\lambda\\)). Eksempelet under er hentet fra Soage (2020): Figure 4.15: Poissonfordelinger Ut fra hvilken \\(\\lambda\\)-verdi vi setter kan vi si noe om sannsynligheten for at et antall hendelser inntreffer. Ugarte et al. (2016) eksemplifiserer Poissonfordeling ved å vise til at det i gjennomsnitt skåres 2,5 mål i en VM-kamp i fotball. Denne situasjonen tilfredsstiller forutsetningene for å bruke Possionfordeling.Vi kan grafisk framstille sannsynlighetsfordeingen slik: Figure 4.16: Poissonfordeling mål i VM-kamp fotball I R kan vi også enkelt regne ut den nøyaktige sannsynligheten for x antall mål gitt forutsetningen om at det i snitt skåres 2.5 mål pr kamp til å være 0. Vi kan bruke sannsynlighetsfordelingen til å regne ut sannsynligheten for et gitt antall mål, f.eks.: Sannsynligheten for 0 mål = 0.082085 Sannsynligheten for 1 mål = 0.2052125 Sannsynligheten for 2 mål = 0.2565156 Sannsynligheten for 3 mål = 0.213763 Sannsynligheten for 4 mål = 0.1336019 eller f.eks. sannsynligheten for at det skåres mellom 1 og 3 mål (= 0.6754911). 4.4 Geometrisk fordeling En geometrisk fordeling er en diskret fordeling der man teller antall hendelser/forsøk inntil et gitt resultat forekommer. Resultatet er suksess eller feil, altså hvor mange ganger man har en hendelse før man får en suksess eller feil (avhengig av hva man måler). Et eksempel er hvor mange ganger man må kaste to terninger for å få 11 i sum. Man kaster da to terninger til første gang man får 11 (= suksess). En geometrisk distribusjon kan se slik ut (p = 0,4): Figure 4.17: Geometrisk fordeling I statistisk prosesskontroll er denne typen fordeling til stede når man f.eks. teller antall dager mellom sjeldne hendelser. Man teller antall dager før man f.eks. får et alvorlig avvik på en medisinering, en operasjon e.l. I geometrisk fordeling er sannsynligheten for et gitt utfall uavhengig av om det har skjedd før. Man kan bruke geometrisk fordeling f.eks. til å estimere hvor mange dager man normalt vil forvente det går mellom en sjelden hendelse. Hvis man gjennom erfaringstall vet at sannsynligheten for en sjelden hendelse er p = 0.035 vil man forvente at det går 1/0.035 \\(\\approx\\) 29 dager mellom hver hendelse. Geometrisk distribusjon kan hjelpe oss i en statistisk prosesskontroll for å finne normal/unormal variasjon ved sjeldne hendelser. Det kan være verdt å merke seg at binomial og geometrisk fordeling skiller seg fra hverandre ved at geometrisk fordeling har et ukjent antall hendelser (man fortsetter til man får første suksess/feil), mens binomial fordeling har et gitt antall hendelser. Som vi skal se i senere eksempler derfor geometrisk fordeling viktig når vi håndterer sjeldne hendelser, fordi vi ikke kjenner hvor mange dager det f.eks. går før vi får første suksess/feil. 4.5 Eksponensiell fordeling En tilfeldig kontinuerlig variabel kan sies å være analog til den geometriske distribusjonen, men for kontinuerlige data. Den eksponensielle distribusjonen brukes ofte for å modellere tid mellom to hendelser. I statistisk prosesskontroll vil vi typisk bruke denne distribusjonen hvis vi måler tid mellom to sjeldne hendelser. Hvis vi f.eks. måler tiden mellom uventet dødsfall som følge av en type rutineoperasjon på et sykehus vil den ha en eksponensiell distribusjon hvis sannsynligheten for at hendelsen inntreffer innenfor t gitt tidsintervall er omtrentlig proporsjonal med lengde på tidsintervallet (Taboga 2017). Eksponensielle fordelinger har samme grunnform, men kan ha ulik bratthet avhengig av den såkalte lamdaverdien (= en parameter for raten av hendelser). Lambdaverdi er en parameter for hvor ofte hendelsene forventes å skje. Figure 4.18: Eksponensiell fordeling "],["er-dataene-dine-normalfordelte.html", "5 Er dataene dine normalfordelte? 5.1 Q-Q plott 5.2 Anderson-Darling test for normalitet", " 5 Er dataene dine normalfordelte? I forrige kapittel viste vi til at data har ulike fordelinger, og at ulike analyser vi gjør i statistisk prosesskontroll har forutsetninger/bygger på antalkelser om hvordan dataene er fordelt (det gjelder forsåvidt alle statistiske analyser vi gjør). Så i dette kapittelet skal vi se nærmere på hvordan vi kan avgjøre om dataene våre er normalfordelte - i mange tilfeller vil det være hensiktsmessig å først sjekke for normalitet siden veldig mange statistiske analyser forutsetter det 17. Vi skal også være klar over at utregning av såkalte testverdier (som Shapiro-Wilk eller Anderson-Darling) også bygger på visse forutsetninger. Vi har imidlertid en metode som vi kan kalle forutsetningsfri som vi anbefaler å begynne med: Q-Q plott. 5.1 Q-Q plott Både histogrammet og Q-Q plottet er visuelle måter å undersøke om en distribusjon er normalfordelt eller ikke. Selv om de ikke alltid gir et entydig svar er de egnet til å gi oss et inntrykk av om en datadistribusjon er normalfordelt eller ikke. Setter man en normalfordelingskurve på et histogram gir det en indikasjon. Som hjelpemiddel er imidlertid Q-Q plott langt bedre. Q-Q plottet (quantile-quantile plot) kan tolkes ved å se om dataverdiene ligger langs en rett linje med ca 45 graders vinkel. Q-Q plottet (se video for forklaring på utregning) innebærer å se to distribusjoner mot hverandre  empirisk fordeling (dataene) og teoretisk forventning ut fra en fordelingsmodell (som normalfordeling om vi snakker om normal Q-Q plott - dvs vi ser om vår empiriske datafordeling og normalfordelingen er lik). Om de samsvarer perfekt ligger de på en helt rett linje (x = y). I eksempelet under vil da alle punktene ligge perfekt oppå den rette linjen. Siden vi vet den teoretiske distribusjonen til normalfordelingen, kan vi bruke denne teoretiske fordelingen til å plotte den mot datasettet vi sitter med. Vi har laget en video som viser hvordan du kan lage et Q-Q plott fra scratch i Excel. Statistikkprogrammer (som R og evt statistikk/SPC plug-ins i Excel) lager naturligvis dette (og regner ut testverdier) svært raskt og enkelt for oss. La oss først se på et Q-Q plott som viser en normalfordeling (du kan laste ned Excelfila hvis du ønsker dataene): Download QQ_norm.xlsx Figure 5.1: Q-Q plott normalfordeling Vi ser at dette Q-Q plottet viser oss at vi kan være ganske sikre på at dette datasettet er normalfordelt (noe som gir meninig siden vi har brukt R til å lage et normalfordelt datasett). Tolkning av Q-Q plott er imidlertid ikke alltid så enkelt som i eksempelet ovenfor - det er en viss grad av subjektivitet involvert. Underhar vi gjengitt noen typiske mønstre vi kan se og hva de skyldes. Som et supplement til Q-Q plott kan vi bruke ulike testverdier (fra f.eks. Shapiro-Wilk og Anderson-Darling). Disse kommer vi tilbake til senere i kapittelet. I det første eksempelet på avvik fra den helt klare normalfordelingen lager vi et datasett som har en skjevhet mot høyre (right skewness) - også kalt positiv skjevhet (uten at det legges noe positivt i positivt). Datasettet kan lastes ned i Excelformat her: Download QQ_norm_rs.xlsx Figure 5.2: Q-Q plott - fordeling skjevhet høyre I et datasett med høyreskjevhet vil ofte Q-Q plottet vise en bananform med bunnen/midten av bananen ned mot høyre hjørne og endene pekende oppover/utover fra den rette linjen. I det neste datasettet har vi generert en kraftig skjevhet til venstre. Q-Q plottet får da en omvendt bananform i forhold til høyre skjevhet, altså en topp på midten og to ender som svinger nedover ift den rette linja. Datasettet finner du her: Download QQ_norm_ls.xlsx Figure 5.3: Q-Q plott - fordeling skjevhet venstre De neste to tilfellene av avvik vi skal ta for oss er såkalte light-tailed (lette haler med liten sannsynlighet for ekstreme verdier og utvalg tendeerer til å ikke fravike gjennomsnittet med mye) og heavy-tailed (fete/tunge haler med større sannsynlighet for at ekstreme verdier vil forekomme) fordelinger. Datasett for fete haler er her: Download QQ_ht.xlsx Figure 5.4: Q-Q plott - heavy-tail Fordelinger med tunge haler vil ofte følge en slags S-form, men den er ofte mer liggende enn S-formen til fordeling med lette haler. Den starter med å vokse raskere enn normalfordelingen og ender med å vokse saktere. Datasettet for lette haler finner du her: Download QQ_lt.xlsx Figure 5.5: Q-Q plott - light-tail Q-Q plottet for en fordeling med lette haler har ofte en S-form. Dataene vokser saktere enn normalfordelingen i starten før den følger vekstraten til normalfordelingen. Mot slutten vokser den raskere enn normalfordelingen. Derfor bøyer den av fra normalfordelingen. Til slutt kan vi se på en typisk bimodial fordeling, med datasett her: Download QQ_bimod.xlsx Figure 5.6: Q-Q plott - bimodial Den bimodiale fordelingen viser ofte et brudd eller et distinkt knekkpunkt rundt krysning av den rette linja, med en del av linja på hver side av den rette linja. Vi har nå sett på noen typiske eksempler på mønstre i Q-Q plott. Det kan imidlertid være vanskelig å bedømme fordelinger som ligger nære normalfordelingen, men likevel ikke perfekt oppå (du vil trolig aldri se en perfekt match med mindre du har generert et normalfordelt datasett med mange datapunkter). Vi kan supplere Q-Q plottene med visse statistiske tester - det er tema for de neste delkapitlene (men husk: disse statistiske testene har sine egne forutsetninger og er heller ikke uten utfordringer). 5.2 Anderson-Darling test for normalitet Anderson-Darlings test er en test for å se om et datasett kommer fra en gitt fordeling, f.eks. normalfordelingen (Anderson and Darling 1952, 1954). Testen setter opp to hypoteser: \\(H_0\\): Dataene følger normalfordelingen \\(H_1\\): Dataene følger ikke normalfordelingen Vi har laget en video (basert på Zaiontz 2020) som viser hvordan du kan gjennomføre en A-D test i Excel som ligger . Vi bruker det samme datasettet som i videoen og du kan laste ned datasettet. Download Anderson-Darling_raw.xlsx Som vi kan se av resultatet fra testen med pakken nortest i R får vi samme verdier som når vi gjør dette manuelt i Excel (jfr video). ## ## Anderson-Darling normality test ## ## data: addata$Values ## A = 0.74573, p-value = 0.04046 Siden vi vet at nullhypotesen er at datasettet har en normalfordeling vil vi forkaste nullhypotesen dersom vi har en signifikant p-verdi (grensen for hva som er signifikant bestemmer vi forsåvidt selv, men vanlige verdier er 0.01, 0.05 og 0.1). Altså - i dette tilfellet har vi en p-verdi=0.04. Vi forkaster derfor nullhypotesen og aksepterer \\(H_1\\) som sier at dataene er trolig ikke er normalfordelte (med andre ord: p-verdien må være større enn signifikansverdien for at vi skal si at dataene trolig er normalfordelte). I vårt tilfelle ser dette slik ut (Hartmann, Krois, and Waske 2018a): Det er verdt å merke seg at Anderson-Darling testen egentlig ikke forteller deg at dataene dine er normalfordelte, men at det er usannsynlig at de ikke er det om testen viser det. Dette synes kanskje som samme sak, men er i realiteten en viktig erkjennelse  en tørr gressplen er et bevis for at det ikke har regnet, men en våt gressplen er ikke bevis for at det har regnet. En våt gressplen kan skyldes andre ting enn regn. Altså  en signifikant p-verdi på testen gjør at vi forkaster \\(H_0\\) og antar at fordelingen er ikke-normal. En ikke-signifikant p-verdi på gjør at vi med f.eks. 95% konfidens kan si at vi ikke har funnet avvik fra normalfordelingen. Tabellarisk kan vi oppsummere vurderingene slik: Betingelse Vurdering p-verdi \\(\\le\\) valgt signifikansnivå Forkast \\(H_0\\) - datene er trolig ikke normalfordelte p-verdi &gt; valgt signifikansnivå Behold \\(H_0\\) - dataene er trolig normalfordelte Testverdi (\\(A^2\\) verdi) &gt; kritisk verdi Forkast \\(H_0\\) - datene er trolig ikke normalfordelte Testverdi (\\(A^2\\) verdi) \\(\\le\\) kritisk verdi Behold \\(H_0\\) - dataene er trolig normalfordelte For at vi skal anta at dataene er normalfordelte må altså p-verdien være større enn valgt signifikansnivå og testverdien være mindre eller lik kritisk verdi. Kritisk verdi leses av i tabell i vedlegg 7. Kritisk verdi referer til det punktet i en teoretisk distribusjon man sammenlikner med en testverdi. Som det framgår av tabellen for kritisk verdi i vedlegget er kritisk verdi låst til valgt signifikansnivå. Kritisk verdi er dermed en terskelverdi for statistisk signifikans  kritisk verdi svarer på spørsmålet «hvor langt fra gjennomsnittsverdien må du bevege deg for å dekke en gitt andel av variansen i datasettet» (f.eks. 90%, 95%, 99%). Generelt vil man forkaste nullhypotesen dersom testverdien overstiger den kritiske verdien. I vårt eksempel ovenfor fikk vi en A-verdi på 0,74573. Kritisk verdi for 0,05 (95%) for normalfordeling (vedlegg 7) er 0,752. Her kan man legge merke til at normtest pakken i R regner ut A-verdien som er identisk med den A-verdien vi viser i Excelvideoen. Imidlertid gjøres det ofte en korreksjon for sammenlikning med normalfordeling (korreksjoner for ulike fordelinger, jfr vedlegg 7) slik at man får en A^2 verdi. Den har vi i Excel regnet ut til 0,7904. For vår vurdering blir dette viktig - bruker vi A-verdien får vi et forvirrende resultat, der p-verdien sier vi ikke har et normalfordelt datasett. A-verdien er mindre enn kritisk verdi så den indikerer at dataene er normalfordelte, mens A^2-verdien er større og indikerer at de ikke er normalfordelte. Vi må anta at A^2-verdien er mer korrekt, og til slutt konkludere med at vi tror dataene ikke er normalfordelte. Vi kan se på et Q-Q plott for dette datasettet også: Figure 5.7: Q-Q plott - A-D data Q-Q plottet støtter vår vurdering om at dette datasettet ikke er normalfordelt. Når det gjelder A-D testen skal vi altså være oppmerksom på om programmet vi bruker regner ut den generiske A-verdien eller den mer korrekt A^2-verdien (dersom vi tester for normalfordeling). Hvis vi bruker normtest på det vi vet er et normalfordelt datasett (jfr vårt første eksempel på et Q-Q plott i dette kapittelet) får vi: ## ## Anderson-Darling normality test ## ## data: addata4$value ## A = 0.15306, p-value = 0.9591 Her ser vi, ikke overraskende, at både p-verdi og kritisk verdi tilsier at datasettet er normalfordelt. Det finnes flere andre statistiske tester som kan kjøres for å teste for normalitet, f.eks. Kologorov-Smirnov, Shapiro-Wilks og Cramer Von-Mises test. Vi går ikke inn på manuell utregning av disse i Excel. Anderson-Darling er en modifisering/videreutvikling av Kolmogorov-Smirnov (Guthrie 2020) og anses ofte som en bedre test.For sammenlikningens skyld kjører vi disse i R: ## ## One-sample Kolmogorov-Smirnov test ## ## data: addata5 ## D = 0.88493, p-value = 0.0000000000000171 ## alternative hypothesis: two-sided ## ## Shapiro-Wilk normality test ## ## data: addata5$Values ## W = 0.87521, p-value = 0.04027 ## ## Cramer-von Mises normality test ## ## data: addata$Values ## W = 0.12634, p-value = 0.04326 Tolkning Kolmogorov-Smirnov: Hvis p-verdien er under valgte signifikansnivå (f.eks. 0.05) skal vi anta at datasettet ikke er normalfordelt. Her vil testen peke på at datasettet ikke er normalfordelt. Tolkning av Shapiro-Wilks og Cramer-von Mieses test er lik som for Kolmogorov-Smirnov. Som et siste eksempel på en statistisk test for normalitet kan vi bruke Jarque-Bera test. Denne skiller seg litt ut fra de andre ved at den spesifikt ser på skjevhet og kurtosis i datasettet opp mot hva en normalfordeling vil ha. For å gjøre lykken komplett finnes det versjoner av testen: ## ## Jarque Bera Test ## ## data: addata6$Values ## X-squared = 2.1953, df = 2, p-value = 0.3337 ## ## Adjusted Jarque-Bera test for normality ## ## data: addata6$Values ## AJB = 3.1014, p-value = 0.131 Tolkningen er lik som før - hvis p-verdien er mindre enn valgte signifikansnivå peker det mot at datasettet ikke er normalfordelt. Her, i motsetning til de øvrige testene, er p-verdien større enn signifikansnivået (0,05) så det peker mot at datasettet er normalfordelt. Dette er altså ikke så enkelt. Det finnes mange statistiske tester, som kan gi motsatte indikasjoner på om et datasett er normalfordelt eller ikke. Vårt råd blir: Start alltid med Q-Q plott. Velg evt en teststatistikk, men vær klar over at alle teststatistikker bygger på forutsetninger eller tester ulike sider av distribusjonen. Det vi også kan huske på er at i henhold til sentralgrenseteoremet (Central Limit Theorem) - se vedlegg 4 - vil populasjonens fordeling være av mindre interesse dersom utvalgsstørrelsen er stor nok. Hva er stor nok? De fleste kilder peker mot at over 30 er stort nok. En siste ting for å gjøre forvirringen komplett Vi kan ta det opprinnelige Q-Q plottet for dette datasettet og legge på konfidensintervaller: Figure 5.8: Q-Q plott - med konfidensgrenser Tolkningen er: Dersom Q-Q plottpunktene i all hovedsak ligger innenfor konfidensintervallene (på figuren over markert med grå farge) er dataene sånn ca. normalfordelte. Vi går ikke nærmere inn på begrepet konfidensintervaller her ut over å si at konfidensintervaller sier noe om gode estimater er. Datasettet vårt er et utvalg. Dette utvalget sammenlikner vi med datafordelingen til et normalfordelt datasett i et Q-Q plott. Q-Q plottet sier oss da, som vi nå vet, noe om vårt datasett og et normalfordelt datasett er like. Dersom vi hypotetisk sett tar uendelig mange utvalg slik vi har fått vårt datasett så kan vi med 95% sikkerhet 18 si at Q-Q plottdatapunktene vil falle innenfor grensene. Husk at et Q-Q plott ikke er en test for å se om dataene er normalfordelte, men en sjekk om dataene har synlige avvik fra normalfordelingen. "],["seriediagram.html", "6 Seriediagram", " 6 Seriediagram Den første analysen vi gir oss i kast med etter å ha fått en forståelse av dataene våre er et seriediagram. Et seriediagram (jfr. Anhøj and Bjørn 2009) (ofte referert til som run diagram siden dette er den engelske betegnelsen) 19 er en framstilling av en serie hendelser sekvensielt i tid. Et seriediagram er enkelt å konstruere og tolke. I dette diagrammet kan vi bruke både måledata og telledata, og det spiller ingen rolle om det er hendelser, prosenter eller andeler (i kontrolldiagrammer vil vi være nøye med å skille mellom hvilke typer data vi har slik at vi velger rett kontrolldiagram). Den eneste forutsetningen vi må ha med oss for seriediagrammer er at punktene er uavhengige, altså at verdien i et punkt ikke er påvirket av verdien på foregående punkt. I tillegg anbefales minst 10 punkter av Berardinelli and Yerian (n.d.), 15 punkter (Reynolds et al. 2021), mens Anhøj and Bjørn (2009) anbefaler mellom 20 og 30 datapunkter for å få et robust seriediagram. Anbefalingen på mellom 20 og 30 hviler på en balanse mellom å se unormal variasjon der prosessen egentlig er stabil (såkalt type-1 feil) og å ikke se unormal variasjon der den faktisk finnes (såkalt type-2 feil). Det er derfor verdt å merke seg at «mer ikke er bedre» - et stort antall datapunkter øker ikke den statistiske styrken, men øker sjansen for type-2 feil. Vi legger til grunn at anbefalingen fra Anhøj and Bjørn (2009) virker godt fundert. Et seriediagram vil kunne vise oss noe om variasjon, men vi kan også gå glipp av noen mer spesielle former for variasjon. Så fordelen i enkelheten må veies opp mot ulempen ved å være litt mindre sensitiv for spesiell variasjon. Plottingen av et seriediagram kan gjøres enkelt med penn og papir ved at man tiden på x-aksen og en verdi av en måling, en observasjon e.l. på y-aksen. Deretter forbinder man punktene med en linje, og legger til medianen (som er verdien av det datapunktet som deler et utvalg i to)20. Hvorfor serie (run)? En serie er i denne sammenhengen definert som et antall (ett eller flere) punkter i diagrammet på samme side av medianen. I diagrammet under ser vi et eksempel på et seriediagram. Vi plotter ganske enkelt inn hver enkelt observasjon fortløpende i tid utover x-aksen og verdien iht y-aksen. Sentraltendensen er medianen, hvilket innebærer at halvparten av målingene er over og halve under medianstreken. Under finner du et eksempel på seriediagram. Vi har laget en kort video som viser hvordan du kan lage et seriediagram i Excel. Den finner du her. Dataene som er brukt i Excelvideoen finner du her: Download seriediagram_eksempelvideo.xlsx Figure 6.1: Eksempel seriediagram Når vi skal tolke seriediagrammet finnes det flere sett av retningslinjer, f.eks. gitt av Carey (2002) og Perla, Provost, and Murray (2011). Vi velger å bruke «Anhøj-reglene» (Anhøj 2015; Anhøj and Wentzel-Larsen 2020) på seriediagrammene. For det første er det vist at disse reglene gir en god balanse mellom type-1 og type-2 feil. For det andre er det to enkle regler å forholde seg til som gjør tolkningen enklere og raskere. Anhøj-reglene ser på to forhold: Uvanlig lange serier. Her kan man matematisk regne ut hvor lang serien må være for å regnes som «uvanlig lang»: \\(log2(n)\\) der n = antall punkter/hendelser (Anhøj 2015). Så for eksempelet ovenfor må serien være \\(log2(30)+3=8\\). Det innebærer at dersom vi har flere enn 8 datapunkter etter hverandre på samme side av senterlinjen vil indikere et skift i prosessen. Uvanlig få krysninger av senterlinjen. Også her kan vi regne ut hvor mange krysningspunkter det bør være \\(b(n-1.05)\\)21. For eksempelet ovenfor blir derfor et minimum antall krysningspunkter 8. Færre enn 8 krysningspunkter vil indikere et skift i prosessen. Heldigvis kan det settes opp en tabell slik at vi enkelt kan lese ut de kritiske verdiene (Anhøj and Wentzel-Larsen 2020) (se vedlegg 2). I eksempelet under har vi igjen 24 observasjoner. Vi bør forvente minst 8 krysninger (regel 2) og siden vi har flere punkter enn 8 etter hverandre på samme side (regel 1) har vi brudd på begge reglene. Dette indikerer en prosess ute av kontroll med unormal variasjon. I et nytt eksempel kan vi provosere fram brudd på Anhøj-reglene: Figure 6.2: Eksempel seriediagram - modifiserte tall I det modifiserte seriediagrammet har vi like mange punkter som det forrige (24) så vi burde forvente minst 8 krysninger (regel 2) og siden vi har flere punkter enn 8 etter hverandre på samme side (regel 1) har vi brudd på begge reglene. Dette indikerer en prosess ute av kontroll med unormal variasjon. Man må imidlertid være observant på eventuelle endringer i prosesser. I eksempelet ovenfor kan man tenke seg en prosessendring etter hendelse 15. Hvis vi legger dette så vi får et brudd i dataserien etter hendelse 15 inn får vi et annet bilde: Figure 6.3: Eksempel seriediagram - modifiserte tall - brudd i prosess I første del av prosessen har vi 14 punkter. Iht vedlegg 2 bør vi da ha minst 4 krysninger og maks 7 punkter på samme side for å få en serie. I andre del har vi 10 punkter. Da skal vi ha minst 2 krysninger og maks 6 punkter på samme side. Ingen av de to delene bryter med Anhøjs regler. Gjennom sin enkelhet vil et seriediagram kunne spare oss for unødvendig arbeid med kontrolldiagrammer (se neste avsnitt). Hvis vi har tegn på unormal variasjon i et seriediagram vil det være liten grunn til å utvikle kontrolldiagram da vi allerede i seriediagrammet kan konstatere unormal variasjon. Tvert imot, som Anhøj (2009) påpeker, kan utviklingen av kontrolldiagrammer være påvirket av tilstedeværelsen av unormal variasjon ved at beregningen av kontrollparameterne gjennomsnitt og kontrollgrenser blir uforutsigbar. Det kan derfor være et godt tips å starte med et seriediagram, tolke det og deretter bestemme seg for hvordan man går videre. Som Anhøj (2021a) uttrykker det: It is a common misunderstanding that control charts are superior to run charts. The confusion may stem from the fact that different sets of rules for identifying non-random variation in run charts are available, and that these sets differ significantly in their diagnostic properties. Og videre: One big advantage of run charts is that they are oblivious to assumptions on the theoretical distribution of data. Also they are easier to construct (by pen and paper) and understand than are control charts. Finally, as mentioned, the diagnostic value of run charts is independent of the number of data points, which is not the case with control charts unless one adjusts the control limits in accordance with the number of data points.In practice I always do the run chart analysis first. If, and only if, the run chart shows random variation and I need to further investigate data for outliers or to know the limits of common cause variation, I would do a control chart analysis Anhøj (2021a) påpker imidlertid et viktig unntak fra tilnærmingen om å alltid se på et seriediagram først: Om man har sjeldne data bør man heller lage et g eller t kontrolldiagram (se neste kapittel) siden seriediagram er dårlig egnet til å detektere endringer i disse tilfellene. Vi vil derfor avslutte dette kapittelet med å sterkt anbefale at man begynner med et seriediagram. Balestracci (2014): Over the years, I have developed an increasing affection for the much-neglected run chart: a time plot of your process data with the median drawn in as a reference (yes, the mediannot the average). It isfilter No. 1 for any process data and answers the question: Did this process have at least one shift during this time period? (This is generally signaled by a clump of eight consecutive data points either all above or below the median.) If it did, then it makes no sense to do a control chart at this time because the overall average of all these data doesnt exist. (Sort of like: If I put my right foot in a bucket of boiling water and my left foot in a bucket of ice water, on average, Im pretty comfortable.) "],["kontrolldiagram.html", "7 Kontrolldiagram 7.1 Mønstre i kontrolldiagram 7.2 Tolkning av kontrolldiagram 7.3 Telledata (attributter) 7.4 Måledata (variabler) 7.5 Spesielle kontrolldiagram (CUSUM og EWMA) 7.6 Risikojustering av kontrolldiagram", " 7 Kontrolldiagram Et kontrolldiagram er mer sensitivt for å vise spesielle typer variasjon enn et run diagram. For å oppnå denne økte sensitiviteten er det imidlertid viktig at man velger riktig type kontrolldiagram ut fra hvilken type data man har. Her vil flytdiagrammet på s.xxxx kunne være til hjelp for å velge riktig type, men vi vil også gå gjennom hvert enkelt kontrolldiagram nedenfor. Man skal imidlertid ikke anta at et seriediagram er «mindre verdt» enn et kontrolldiagram. Selv om kontrolldiagram er mer sensitive ovenfor spesielle typer variasjon, er seriediagram mer sensitive ovenfor mindre skifter i dataene (under 2 SD) enn kontrolldiagrammene som typisk reagerer på større skifter i dataene (rundt 2 SD og mer) (Anhøj and Olesen 2014). Et seriediagram kan derfor ofte være et viktig første steg før man tar i bruk mer sofistikerte verktøy som kontrolldiagram (Perla et al. 2011). En spesiell egenskap ved kontrolldiagram er at den kan hjelpe oss til å se yteevnen til en stabil prosess. Med det mener vi hvilke grenser prosessen trolig vil holde seg innenfor. Dette kalles ofte for prosesskapabilitet. Dette vil vi komme nærmere tilbake til i et senere avsnitt. Så hva er et kontrolldiagram? Et kontrolldiagram er en statistisk tilnærming til å se på prosesser, variasjon i prosesser og om prosesser produserer resultater innenfor gitte akseptable grenser. Det likner på i stor grad på et seriediagram. Vi plotter inn en rekke hendelser eller observasjoner i et diagram der tiden for observasjonene plottes fortløpende i tid på x-aksen og verdien eller antall hendelser på y-aksen. Det et kontrolldiagram tilfører er at det inkluderer mer avanserte analyser gjennom å regne ut to kontrollgrenser som lar oss vurdere statistisk etter andre regler enn seriediagrammet om en prosess har normal eller unormal variasjon. I tillegg er kontrolldiagrammene basert på at sentraltendensen er gjennomsnittet, ikke median (som i seriediagrammet). Shewhart baserte sin tilnærming til kontrolldiagram på matematisk teori (se vedlegg 7 for forklaring på Chebyshevs teorem) og egne empiriske erfaringer når han satt verdiene for øvre og nedre kontrollgrenser til tre sigma (tre standardavvik). Flere tiårs erfaring fra en lang rekke områder viser at tre sigma som grenseverdier holder vann (Mohammed, Worthington, and Woodall 2008). Et kontrolldiagram kan se slik ut (R pakken qicharts2 (Anhøj 2020): Figure 7.1: Eksempel kontrolldiagram i qicharts Observasjonene/målingene plottes som punkter sekvensielt i tid. Snittet er -0,2, UCL 2,2 og LCL -2,7. Tilsvarende data ved bruk av R pakken qcc (Scrucca et al. 2017): Figure 7.2: Eksempel kontrolldiagram i qcc Figure 7.3: Eksempel kontrolldiagram i qcc Alle kontrolldiagram vil ha tre horisontale linjer: En gjennomsnittsverdi, en øvre kontrollgrense og en nedre kontrollgrense (øvre og nedre kontrollgrense kan ved enkelte typer kontrolldiagram avvike fra en ren horisontal linje, men ha et horisontalt mønster. Ulike programmer eller R-pakker gir ulik grafisk framstilling.Analyse-It i Excel gir dette for samme data: Før vi går inn på kontrolldiagram for hhv telledata og måldata skal vi ta en gjennomgang av typiske mønstre som trekkes fram som kan si oss noe om tolkning av kontrolldiagram (se f.eks. Lavangnananda and Tengsriprasert (2002) og Montgomery (2020)). 7.1 Mønstre i kontrolldiagram Når vi har laget et kontrolldiagram vil det være noen åpenbare tegn vi vil legge merke til, f.eks. vil vi ganske raskt se om vi har punkter utenfor kontrollgrensene. En annen ting vi raskt kan forsøke å se på er om kontrolldiagrammet viser et gjenkjennbart mønster som kan fortelle oss noe om prosessen og dataene vi har. Vi skal her vise åtte typiske mønstre som blir av flere blir trukket fram (Lavangnananda and Tengsriprasert (2002) snakker om ni mønster, der det siste omtales som Mixture - vi mener imidlertid den i praksis kan være så vanskelig å fange opp eller skille fra et normalt mønster at vi velger å se bort fra denne). Vi viser mønstrene uten mange kommentarer da de fleste er ganske åpenbare. Det eneste mønsteret vi ønsker å knytte noen korte kommentarer til er stratifisering som kanskje ikke er helt intuitiv. Stratifisering regnes som en unormal variasjon (a special cause) dersom 15 eller flere påfølengde punkter faller innenfor det som kalles sone C (= +/- 1 SD fra snittet). Man sier ofte at punktene klemmer senterlinjen, og det kan se ut som prosessen har unormalt liten variasjon. Montgomery (2020) peker på to mulige årsaker: Kontrollgrensene kan være feilkalkulert, eller målingene kan komme fra flere underliggende prosesser. Vi skal ikke gå dypere inn på dette her, men en god gjennomgang av dette er gitt av Rowe (2012) på denne lenken. 7.2 Tolkning av kontrolldiagram Vi skal være oppmerksom på at de kan opererer med ulike regler for når de flagger unormal variasjon. Ulike programmer kan imidlertid ha lagt inn noe ulike regler for hva som betraktes som unormal variasjon. Det er derfor lurt å sette seg inn i hvilke regler som benyttes i det programmet du bruker  alle programmene vil, på en eller annen måte, indikere unormal variasjon hvis vi ber programmet om å gjøre det. Og de fleste programmene vil også la oss velge mellom hvilke kontrollregler vi ønsker å bruke. Her må man altså sjekke opp ut fra hvilket program/R-pakke man ønsker å bruke. I det videre vil vi i hovedsak bruke qcc og qicharts2. Ulike sett regler har vokst fram fra det som regnes som de opprinnelige 4 reglene (1, 2, 5 og 6) (Western Electric Company 1956), til Nelson (1984) 8 regler som er modifisert av flere, blant annet Montgomery (2020) (som qicharts2 bruker).Pakken qcc bruker reglene 1, 2, 3 og 4 som Shewhart reglene. Eksempel på kontrolldiagram med indikasjon på et eller flere brudd på regler for normal variasjon: Figure 7.4: Oversikt regler kontrolldiagram Figure 7.5: Oversikt regler kontrolldiagram .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-28c4eb40{table-layout:auto;width:100%;}.cl-28bd4480{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-28bd4481{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-28bd92a0{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-28bd92a1{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-28bd92a2{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} TestRegelIndikasjon11 punkt utenfor kontrollgrenseneEn større endring22 av 3 påfølgende punkter er mer enn 2 sigma fra gjennomsnittsverdien og i samme retningEn mindre, men vedvarende endring34 av 5 påfølgende punkter er mer enn 1 sigma fra gjennomsnittsverdien og i samme retningEn mindre, men vedvarende endring48 påfølgende punkter er på samme side av gjennomsnittetIkke-tilfeldig systematisk variasjon56 påfølgende punkter er i stigende eller synkende trend (etter hverandre)En middels endring615 påfølgende punkter er innenfor +/- 1 sigma fra gjennomsnittetEn liten endring714 påfølgende punkter alternerer opp og ned (annenhver opp og ned i forhold til foregående verdi)Stratifisering (at vi egentlig har to eller flere prosesser  et histogram vil f.eks. kunne vise en bimodal distribusjon)88 påfølgende punkter på samme side av gjennomsnittet og ingen innenfor +/- 1 sigmaBlandet variasjon Vi skal i det følgende vise reglene grafisk. I diagrammene nedenfor viser vi eksempler på kontrolldiagram inndelt i tilsammen seks soner (A, B og C). Sone C er intervallet +/- 1 sigma fra sentraltendensen, sone B er intervallene +/- 1 til 2 sigma fra sentraltendensen og sone A er intervallene +/- 2 til 3 sigma fra sentraltendensen. 7.2.1 Punkter utenfor kontrollgrensene: 7.2.2 2 av 3 påfølgende punkter er mer enn 2 sigma fra gjennomsnittsverdien (i sone A) og i samme retning 7.2.3 4 av 5 påfølgende punkter er mer enn 1 sigma fra gjennomsnittsverdien (sone A og B) og i samme retning 7.2.4 8 påfølgende punkter er på samme side av gjennomsnittet 7.2.5 6 påfølgende punkter er i stigende eller synkende trend (etter hverandre) 7.2.6 15 påfølgende punkter er innenfor +/- 1 sigma fra gjennomsnittet 7.2.7 14 påfølgende punkter alternerer opp og ned (annenhver opp og ned i forhold til foregående verdi) 7.2.8 8 påfølgende punkter på samme side av gjennomsnittet og ingen innenfor +/- 1 sigma Bruk av regel 1 på en normalfordelte data vil kunne gi «falsk alarm» (vise unormal variasjon når det ikke finnes) i 1 av 370 tilfeller i gjennomsnitt. Hvis man imidlertid legger til testene 2, 5 og 6 stiger raten av feil alarmer til 1 av 91,75 tilfeller. Et godt råd som ofte gis er å velge tester før man lage kontrolldiagrammene basert på kjennskap til prosessen man holder på med. Som Anhøj (2021a) påpeker: It is a common misunderstanding that control charts are superior to run charts. The confusion may stem from the fact that different sets of rules for identifying non-random variation in run charts are available, and that these sets differ significantly in their diagnostic properties. Vi skal i videre i dette kapittelet ta for oss ulike typer kontrolldiagrammene (ref. flytskjema for valg av kontrolldiagram). Vi vil vise et eksempel på hvert av de vanlige kontrolldiagrammene. For hvert eksempel finnes det en Excelfil med dataene som er brukt for de ulike eksemplene og en video som viser framgangsmåten i Excel. Grunnen til dette er at for mange vil Excel være et mye mer kjent grensesnitt enn R. Samtidig, ved å se på videoen og stegene som gjøres, ser man hvordan det enkelte kontrolldiagram er bygd opp. Selvsagt er dette mye mer tidkrevende enn å bare kjøre analysen i R, men det kan gi en fin innsikt i hva som egentlig skjer. På sikt mener vi det er mye å hente på å bruke R og pakken qicharts2 eller pakken qcc. Alternativt kan man investere i et tillegg til Excel som nevnt i kapittel 1. 7.3 Telledata (attributter) Diagrammene i dette delkapittelet handler om data der vi kan telle og putte dataene inn i kategorier. Motsetningen er måledata som er kontinuerlige data som behandles i neste delkapittel. 7.3.1 p-diagram P-diagrammet er trolig det mest brukte diagrammet i helsesektoren (Anhøj 2021a). Her er dataene binomiale, dvs type ja/nei. Vi kan f.eks. registrere om det er eller ikke er et avvik fra en gitt rutine. P-diagrammet og NP-diagrammet skiller seg kun fra hverandre ved at NP-diagrammet forutsetter en lik størrelse på utvalget hver måling, mens P-diagrammet brukes når utvalgsstørrelsen varierer. Hvis vi f.eks. registrerer antall avvik i en rutine pr uke og antallet gjennomføringer av rutinen varierer fra uke til uke bør vi bruke et P-diagram. La oss tenke oss at vi har følgende data som viser antall keisersnitt og totalt antall fødsler på et sykehus (eksempeldata modifisert fra QIMacros 2021). .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-2acf5b46{table-layout:auto;width:100%;}.cl-2ac5a3bc{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2ac5a3bd{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2ac5e610{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2ac5e611{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2ac5e612{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} År 1År 2MånedKeisersnittFødslerMåned.Keisersnitt.Fødsler.Jan65370Jan62374Feb64383Feb48355Mar77446Mar57393Apr59454Apr64417Mai64463Mai66434Jun74431Jun55421Jul72443Jul51417Aug67451Aug82444Sep59433Sep65429Okt65407Okt69411Nov60381Nov62386Des68406Des66357 Datasettet i Excelformat finner du her: Download P_chart.xlsx Figure 7.6: p-diagram Figure 7.7: p-diagram I p-diagrammet vil UCL og LCL variere noe siden det tas hensyn til at n varierer fra registrering til registrering. Video med framgangsmåte i Excel ligger her. 7.3.2 Laneys p-diagram I noen tilfeller har vi data som gir svært smale kontrollgrenser (eksempeldata modifisert fra SPC for Excel 2021). La oss anta følgende datasett: .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-2b149f80{table-layout:auto;width:100%;}.cl-2b0d12ec{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2b0d39e8{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2b0d60da{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2b0d60db{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2b0d60dc{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} MånedMedlemmerPr_telefonMåned.Medlemmer.Pr_telefon.Jan0787553852Sep07216009250Feb0798004100Okt07205009950Mar07170007083Nov07187009846Apr07164007339Des07189009854Mai07195009406Jan08143008034Jun07198009310Feb08148008162Jul07212007250Mar08145008122Aug072230010400Apr08146008200 Datasett: Download Laneyp.xlsx Figure 7.8: p-diagram for Laney Figure 7.9: p-diagram for Laney Diagrammet gir liten mening når mer eller mindre alle punktene ligger utenfor kontrollgrensene. Laney (2002) peker på at p- og u-diagrammer har forutsetninger om distribusjonen som blant annet antar at gjennomsnittet er konstant over tid. Kombinert med veldig stor utvalgsstørrelse gir dette såkalt overdispersjon, hvilket betyr at den faktiske variansen er større enn det modellen benytter. Framgangsmåten Laney foreslår kan virke noe teknisk, men innebærer å regne ut z verdien for alle punktene (z verdien forteller antallet standardavvik mellom det målte punktet og gjennomsnittet). Z-verdiene brukes så for å regne ut Moving Range (MR), som igjen brukes til å regne ut gjennomsnittlige MR, som igjen brukes til å regne ut UCL og LCL. Vi har laget en video som kort forklarer begrepet Moving Range. Som dere vil se i videoen (se lenke litt lenger ned) er den eneste forskjellen i formlene som regner ut UCL og LCL et uttrykk for standardavviket for z-verdiene. Denne, sier Laney, korrigerer for den relative andelen av prosessvariasjon som ikke forklares av den binomiale fordelingen alene. Ved stor n minskes variasjonen fra utvalgene. Laneys p-diagram er i realiteten veldig likt et I-diagram, med den forskjellen at p-diagrammet tar høyde for varierende utvalgsstørrelser. Du finner en video som forklarer framgangsmåten i Excel her. 7.3.3 np-diagram Forskjellen på p-diagram og np-diagram ligger i om utvalgsstørrelsen er lik eller ulik gjennom registreringene. I dette eksempelet sjekker vi om en prosedyre er korrekt gjennomført eller ikke. For å registrere dette tar vi hver uke 50 stikkprøver og registrerer hvor mange som ikke er gjennomført iht prosedyren (eksempeldata modifisert fra QIMacros 2021). .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-2b5c51fe{table-layout:auto;width:100%;}.cl-2b523d68{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2b5264f0{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2b52b298{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2b52b299{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2b52b29a{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} UkenFeilUke.n.Feil.1501213501725015145012350815502245010165085504175010650718505750161950138509205011950142150201050102250181150523502412506245015 Datasett: Download np_diagram.xlsx Figure 7.10: np-diagram Figure 7.11: np-diagram I dette tilfellet ser vi at det ved to anledninger  uke 15 og 23  var brudd på regel 1 (utenfor 3 sigma). Som vanlig finnes det en Excelvideo som viser framgangsmåten steg-for-steg i Excel. 7.3.4 u-diagram p- og np-diagrammer teller antall defekter  en hendelse, et produkt, en tjeneste er enten defekt eller ikke. Men i mange tilfeller gir det ikke så mye mening å se på defekt/ikke-defekt. En bil kan f.eks. ha flere feil, men likevel være kjørbar. Bilen er ikke defekt selv om den har feil vi er interessert i. Det vi i stedet kan være mer interessert i er hvor mange feil har enheten vi ser på. Vi kan f.eks. være interessert i hvor mange kundeklager som har kommet inn i en periode. Vi er da interessert i antallet klager og antar ikke at hele prosessen er defekt selv om vi har klager. I eksempelet under ser vi på antall pasientfall opp mot totalt antall pasientdager (eksempeldata modifisert fra QIMacros 2021). .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-2ba5dfc2{table-layout:auto;width:100%;}.cl-2b9c97a0{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2b9cbe60{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2b9d1536{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2b9d1537{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2b9d1538{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} MånedPasientfallPasientdagerMåned.Pasientfall..Pasientdager.Jun174658Jun425609Jul224909Jul415722Aug234886Aug245261Sep304970Sep226071Okt284780Okt506072Nov184973Nov515335Des445762Des396483Jan425441Jan225752Feb335893Feb315731Mar335743Mar335017Apr334747Apr255158Mai275118Mai225040 Datasett: Download u_diagram.xlsx Figure 7.12: u-diagram Figure 7.13: u-diagram Video her for Excel 7.3.5 Laneys u-diagram Som for p-diagrammet finnes det et alternativ fra Laney (2002). Se punktet om Laneys p-diagram  samme forhold som ble diskutert for p vs p-diagram gjelder for u vs u-diagram. Datasett: Download ludiagram.xlsx Data (eksempeldata modifisert fra SPC for Excel 2021). .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-2bf232d2{table-layout:auto;width:100%;}.cl-2be89600{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2be8e3ee{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2be931d2{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2be931d3{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2be931d4{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} UkePasienterFeilUke.Pasienter.Feil.1656698146598107296713615100294338129104168192504775790179417102578805318713063691029319545558772011802059465287940512110222999848664228154431098581162351144611922691246256871210496692564668413942743 Uten Laneys korreksjon (standard u-diagram): Laneys u-diagram: Video som viser frangangsmåte i Excel ligger her 7.3.6 c-diagram c-diagrammet likner på u-diagrammet, men her er utvalgsstørrelsen lik. Man kan f.eks. registrere antall hendelser med personskader i en fabrikk. Fabrikken vil da utgjøre utvalget og den er lik fra periode til periode. Vi kan bruke antall feilmedisineringer i en enhet som et eksempel (eksempeldata modifisert fra QIMacros 2021). .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-2c0d4540{table-layout:auto;width:100%;}.cl-2c053454{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2c053455{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2c058242{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2c058243{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2c058244{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} MånedFeilmedisineringMåned.Feilmedisinering.Jan74Jan75Feb70Feb63Mar67Mar71Apr65Apr59Mai63Mai70Jun82Jun66Jul110Jul97Aug61Aug71Sep75Sep84Okt78Okt85Nov76Nov57Des78Des60 Datasett: Download cdiagram.xlsx Figure 7.14: c-diagram Figure 7.15: c-diagram Excelvideo her 7.3.7 g-diagram g-diagrammet brukes på sjeldne hendelser. Her bruker vi dager dager mellom infeksjoner etter en viss type operasjon som eksempel (eksempeldata modifisert fra SPC for Excel 2021). .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-2c5004fc{table-layout:auto;width:100%;}.cl-2c46c130{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2c46c131{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2c46e746{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2c46e747{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2c46e748{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Dager_mellom582211132616469352567582011494657 Datasett: Download gdiagram.xlsx Video for Excel I utregning av sentraltendensen oppgis noe ulike utregninger i forskjellige kilder. Noen bruker det aritmetiske gjennomsnittet (slik vi har gjort i de andre diagrammene hittil), mens flertallet ser ut til å bruke en beregnet medianverdi (se Benneyan 2001). Grunnen til dette er at distribusjonen antas å være geometrisk, noe som innebærer at den er betydelig skjevfordelt. Median er dermed en mer representativ verdi for sentraltendensen enn gjennomsnittet. Det legges derfor inn en konstant på 0.693 når man regner ut CL. Samtidig brukes snittet likevel når man regner ut UCL og LCL  framgangsmåten er forklart i videoen. 7.3.8 Utfordringer med telledata og distribusjon på dataene Alle telledata, om det er antall eller andeler, er individuelle verdier per en eller annen tidsenhet. Som vi kan se av formlene for utregning av UCL og LCL i så vel p som np, u og c utgjør gjennomsnittet grunnlaget for utregning av kontrollgrensene. Dette baserer seg på at dataene følger enten en binomial (for p og np) eller Poisson (for c og u) sannsynlighetsfordeling (jfr kapittelet om datadistribusjon). Som Wheeler (2021) beskriver innebærer det at gjennomsnittet spesifiserer modellen og snittet er grunnlaget for både sentraltendens og spredning/variasjon, men det er uansett en teoretisk tilnærming som baserer seg på at dataene har enten binomial eller Poissonfordeling. Er dataene ikke det viser Wheeler (2021) at kontrollgrensene blir gale, og mange typer telledata har ikke verken binomial eller Poisson fordeling. Man bør derfor kjenne til distribusjonen av telledataene før man benytter p, np, c eller u diagram. Wheeler (2021) viser at IMR (XMR) diagrammer (se neste delkapittel), som baserer utregningen av kontrollgrensene empirisk (i motsetning til teoretisk ut fra sannsynlighetsfordeling) på Moving Ranges (MR), alltid vil gi deg riktige kontrollgrenser. Kontrollgrensene med et IMR diagram vil således være empirisk utregnet fra den variasjonen du faktisk har i dataene og ikke være teoretisk beregnet ut fra en sannsynlighetsfordeling. Wheelers (2021) artikkel viser gjennom tre eksempler at kontrollgrensen i et IMR-diagram vil replikere de i p, np, c og u der disse er korrekte, og avvike (men vise de riktige) der p, np, c og u viser feil kontrollgrenser. viser at IMR (XMR) diagrammer (se neste delkapittel), som baserer utregningen av kontrollgrensene empirisk (i motsetning til teoretisk ut fra sannsynlighetsfordeling) på Moving Ranges (MR), alltid vil gi deg riktige kontrollgrenser. Kontrollgrensene med et IMR diagram vil således være empirisk utregnet fra den variasjonen du faktisk har i dataene og ikke være teoretisk beregnet ut fra en sannsynlighetsfordeling. Wheeler (2021) artikkel viser gjennom tre eksempler at kontrollgrensen i et IMR-diagram vil replikere de i p, np, c og u der disse er korrekte, og avvike (men vise de riktige) der p, np, c og u viser feil kontrollgrenser. Som Wheeler (2021) uttrykker det: In contrast to this use of theoretical models which may or may not be correct, the XmR chart provides us with empirical limits that are actually based upon the variation present in the data. This means that you can use an XmR chart with count-based data anytime you wish. Since the p-chart, the np-chart, the c-chart, and the u-chart are all special cases of the chart for individual values, the XmR chart will mimic these specialty charts when they are appropriate and will differ from them when they are wrong. Mohammed and Worthington (2012) understreker at så lenge det kun finnes normal variasjon vil kontrollgrensene for IMR(XMR) og p/np/c/u-diagrammer være samsvarende. De peker videre på at dersom det er klare forskjeller mellom IMR og p/np/c/u er det en indikasjon på unormal variasjon. De anbefaler derfor at man bruker begge typene. Vi foreslår derfor at dersom man ikke er helt sikker på distribusjonen i telledata kan man følge anbefalingen fra Wheeler (2021) anbefaling om å bruke IMR (XMR) diagram. Man kan eventuelt følge anbeflaingen fra Mohammed and Worthington (2012) om å bruke IMR i kombinasjon med p/np/c/u. Man bør trolig være forsiktig med å bruke bare p/np/c/u om man ikke er sikker på distribusjonen. Under kapittelet om distribusjoner finner du en beskrivelse av ulike aktuelle distribusjoner og hvordan man kan undersøke data med tanke på distribusjon. Et enkelt grep for å få et inntrykk av distribusjonen er et «vanlig» histogram. For dataene brukt i eksempelet over for np-diagram kan vi sammenlikne np-diagrammet med I-diagramdelen av IMR-diagram for samme data: Vi kan se det er avvik mellom diagrammene. Np-diagrammet har trangere kontrollgrenser og viser to punkter utenfor øvre kontrollgrense. Hvis vi plotter et Q-Q plott, finner vi: Sammen med statistiske tester for normalitet (Shapiro-Wilk og Anderson-Darling) får vi klare indikasjoner på at datasettet er nærme normalfordeling. Siden et np-diagram bygger på forutsetning om en binomial fordeling virker det mest korrekt å bruke IMR-diagrammet22. 7.4 Måledata (variabler) 7.4.1 IMR (XMR) Eksempel basert på Anhøj (2021a). .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-2c740000{table-layout:auto;width:100%;}.cl-2c69c996{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2c69e69c{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2c6a05dc{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2c6a05dd{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2c6a05de{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Baby_nrFødselsvektBaby_nr.Fødselsvekt.128981334783303614368232757153650434551633435317917300963402183812733941940098373720297593434213369102953222972113525233598123778243141 Datasett: Download imr_diagram.xlsx Figure 7.16: IMR-diagram Figure 7.17: IMR-diagram Figure 7.18: IMR-diagram Figure 7.19: IMR-diagram Framgangsmåte i Excel her 7.4.2 XbarR Eksempeldata modifisert fra (QIMacros 2021). .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-2cdc3742{table-layout:auto;width:100%;}.cl-2cd35118{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2cd378aa{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2cd3ecf4{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2cd3ecf5{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2cd3ecf6{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Prøve_nrObs_1Obs_2Obs_3Obs_4Obs_5174.03074.00274.01973.99274.008373.99573.99274.00174.01174.004373.98874.02474.02174.00574.002474.00273.99673.99374.01574.009573.99274.00774.01573.98974.014674.00973.99473.99773.98573.993773.99574.00673.99474.00074.005873.98574.00373.99374.01573.988974.00873.99574.00974.00574.0041073.99874.00073.99074.00773.9951173.99473.99873.99473.99573.9901274.00474.00074.00774.00073.9961373.98374.00273.99873.99774.0121474.00673.96773.99474.00073.9841574.01274.01473.99873.99974.0071674.00073.98474.00573.99873.9961773.99474.01273.98674.00574.0071874.00674.01074.01874.00374.0001973.98474.00274.00374.00573.9972074.00074.01074.01374.02074.0032173.98274.00174.01574.00573.9962274.00473.99973.99074.00674.0092374.01073.98973.99074.00974.0142474.01574.00873.99374.00074.010 Datasett: Download XbarR_diagram.xlsx NB NB NB - Lage og sette inn video her. 7.4.3 XbarS Eksempeldata modifisert fra (QIMacros 2021). Download XbarS_diagram.xlsx .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-2d0e9ef8{table-layout:auto;width:100%;}.cl-2d05f0f0{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2d0618fa{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2d068d76{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d068d77{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d068d78{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} MånedAvd1Avd2Avd3Avd4Avd5Avd6Avd7Avd8Avd9Jan252235232445363432Feb252235232445363432Mar453634324035675634Apr343240356754575945Mai252235232445363432Jun252235232445343240Jul453634324035675634Aug343240356754575945Sep252235232445363432Okt252235232445363432Nov453634324035675634Des343240356754575945 .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-2d2fb1a6{table-layout:auto;width:100%;}.cl-2d2432fe{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2d2432ff{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2d24ab44{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d24ab45{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2d24ab46{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} MånedAvd10Avd11Avd12Avd13Avd14Avd15Avd16Avd17Avd18Avd19Jan403567Feb40356725223523244536Mar556744684645Apr4467475355432267Mai403567Jun356725223523244536Jul556744684645Aug4467475355432267Sep403567Okt40356725223523244536Nov556744684645Des4467475355432267 Video kommer her 7.4.4 T-diagram I likhet med g-diagrammet er T-diagrammet er diagram vi kan bruke når det er lang tid mellom hendelser (sjeldne hendelser). I g-diagrammet så vi på antall tilfeller mellom hver uønskede hendelse. T-diagrammet brukes når vi vil se på tid mellom hendelser. Siden antall tilfeller mellom hendelser er en diskret variabel og tid er en kontinuerlig variabel plasseres de hhv. i telledata og måledata. Eksempelet under er modifisert fra Anhøj (2021a). Datasett: Download t_diagram_data.xlsx Figure 7.20: t-diagram Video kommer her 7.5 Spesielle kontrolldiagram (CUSUM og EWMA) 7.5.1 CUSUM 7.5.2 EWMA 7.6 Risikojustering av kontrolldiagram "],["prosesskapabilitet.html", "8 Prosesskapabilitet 8.1 Histogrammer 8.2 Boxplots 8.3 Kapabilitetsindekser 8.4 Loss function 8.5 Ikke-normale data", " 8 Prosesskapabilitet Gitt at en prosess er kontrollert, altså at vi kun har normal variasjon, kan vi være interessert i å se nærmere på hvordan prosessen leverer (resultatene sett opp mot forventninger). Som tidligere nevnt betyr ikke en kontrollert prosess at vi er fornøyde med resultatene, men det betyr at vi ikke ser unormal variasjon. Dermed kan vi jobbe for å forbedre prosessen gjennom å addressere de normale årsakene til variasjon i prosessen, som kan være en lang rekke forhold. La oss understreke dette poenget med et eksempel fra Leavengood and Reeb (2015b). Hvis en kunde stiller krav om et fuktighetsinnhold (i et gitt produkt) på 6% \\(\\pm\\) 1% og vi har en kontrollert prosess som gir produkter med 10% \\(\\pm\\) 5% så har vi en stabil prosess som ikke er kapabel. For en kunde kan det derfor være avgjørende at vi kan vise vår prosesskapabilitet - de vil sikre seg at vår prosess vil gi produkter (eller tjenester) som er ikke bare stabile, men kapable (møter deres forventninger og krav). La oss starte med et tenkt eksempel der vi har to prosesser som skal forholde seg til samme spesifikasjonsgrenser (basert på Leavengood and Reeb (2015b)). Det kan f.eks. være to like maskiner som produserer samme proodukt med samme krav til kvalitet (samme spesifikasjonsgrenser). I figuren under illustrerer vi to fiktive prosesser. Nedre spesifikasjonsgrense (LSL) og øvre spesifikasjonsgrense (USL) er tegnet inn. Spesifikasjonsgrensene er ikke det samme som kontrollgrenser. Kontrollgrenser er regnet ut fra dataene prosessen faktisk gir, mens spesifikasjonsgrensene er grenser for akseptabelt avvik i produksjon/spesifikasjoner vi (eller noen andre, f.eks. en kunde) har satt. Vi kunne også omtalt spesifikasjonsgrenser som toleransegrenser - hva tolererer vi av resultat fra prosessen før vi vil si at kvaliteten ikke er god nok. Differansen mellom de to spesifikasjonsgrensene (USL og LSL) er et uttrykk for hvilken toleranse vi har for resultatet av prosessen. Som Wheeler (2013) uttrykker det: The difference between the specification limits, USL  LSL, is the specified tolerance. It defines the total space available for the process. Med andre ord: Spesifikasjonsgrenser sier hva vi ønsker fra prosessen, kontrollgrensene hva vi fikk. Prosessen med blå kurve har snitt = 0 og standardavvik = 0.5, den røde prosessen har snitt = 0.5 og standardavvik = 1. Den røde prosessen er således noe usentrert. Spesifikasjonsgrensene er satt til hhv -2 og 2. Det vi kan se er at den røde prosessen er noe usentrert (snittet er 0.5 fra 0) og spredningen (standardavviket) er noe større enn den blå prosessen. Med andre ord - gitt den akseptable grensen for spesifikasjoner som er satt ser vi at den røde prosessen vil produsere flere defekter enn den blå prosesen. Figure 8.1: Eksempel på to ulike prosesser Vi skal nå se på ulike verktøy vi kan bruke for å jobbe med prosesskapabilitet. 8.1 Histogrammer Vi har tidligere i boka vært innom histogrammer, f.eks. i kapittel 4 der vi så på ulike datafordelingsmodeller (normalfordeling, binomialfordeling, geometrisk fordeling og eksponensiell fordeling). Deleryd (1999) påpeker at histogrammer er den enkleste måten å tilnærme seg prosesskapabilitet. Man plotter spesifikasjonsgrensene på x-aksen og lager forøvrig et vanlig histogram av dataene. Dette historgrammet vil da vise oss noe om sentrering, spredning og den generelle formen på dataene 8.2 Boxplots 8.3 Kapabilitetsindekser 8.3.1 Måledata 8.3.1.1 Cp 8.3.1.2 Cpk 8.3.1.3 Cpm 8.3.1.4 Cpmk 8.3.2 Telledata 8.4 Loss function 8.5 Ikke-normale data "],["spc-som-del-av-et-helhetlig-og-kontinuerlig-kvalitetsarbeid.html", "9 SPC som del av et helhetlig og kontinuerlig kvalitetsarbeid 9.1 DMAIC 9.2 Pareto 9.3 Flytdiagram 9.4 Eksperimenter", " 9 SPC som del av et helhetlig og kontinuerlig kvalitetsarbeid 9.1 DMAIC 9.2 Pareto 9.3 Flytdiagram 9.4 Eksperimenter "],["referanser.html", "Referanser", " Referanser "],["vedlegg-1---r-kode.html", "Vedlegg 1 - R kode", " Vedlegg 1 - R kode Kapittel 2 Sette opp nødvendige pakker: pacman::p_load(ggplot2, readxl, tidyverse, ggpubr, dplyr, hrbrthemes) Lage fig 2.1: prepost_eksempel_long &lt;- as_tibble(read_excel(&quot;prepost_eksempel_long.xlsx&quot;)) ggbarplot(prepost_eksempel_long, x = &quot;Periode&quot;, y = &quot;Verdi&quot;, add = c(&quot;mean&quot;), color = &quot;blue&quot;, fill = &quot;lightblue&quot;) Lage fig 2.2: ggline(prepost_eksempel_long, x = &quot;Periode&quot;, y = &quot;Verdi&quot;, add = c(&quot;mean_se&quot;, &quot;jitter&quot;)) Lage fig 2.3: t &lt;- 1:24 z &lt;- c(prepost_eksempel_long$Verdi) plot(t,z, type=&quot;l&quot;, col=&quot;blue&quot;, lwd=3, xlab=&quot;Periode&quot;, ylab=&quot;Antall&quot;, xaxt=&quot;n&quot;) axis(1, seq(0,24,2)) abline(v=12, col=&quot;red&quot;, lwd = 3) text(15.5, 40, &quot;Endring i prosedyre&quot;, col = &quot;red&quot;) Kapittel 3 Lage fig 3.1: # Genererer tilfeldig tall for regel 1: pacman::p_load(xlsx, ggplot2, tidyverse, ggpubr) set.seed(91) regel1_x &lt;- as_tibble(rnorm(100, mean = 0, sd = 1)) %&gt;% rename(x = value) %&gt;% add_column(nr = 1:100) %&gt;% relocate(nr) regel1_y &lt;- as_tibble(rnorm(100, mean = 0, sd = 1)) %&gt;% rename(y = value) %&gt;% add_column(nr = 1:100) %&gt;% relocate(nr) regel1 &lt;- merge(regel1_x,regel1_y,by=&quot;nr&quot;) regel1_plot &lt;- ggplot(regel1, aes(x = x, y = y)) + geom_point(size = 1) + labs(x = &quot;x&quot;, y = &quot;y&quot;, title = &quot;Regel 1&quot;) + xlim(-5,5) + ylim(-5,5)+ geom_vline(xintercept = 0, col = &quot;red&quot;) + geom_hline(yintercept = 0, col = &quot;red&quot;) # Genererer tilfeldig tall for regel 2: set.seed(92) regel2_x &lt;- as_tibble(rnorm(100, mean = 0, sd = 2)) %&gt;% rename(x = value) %&gt;% add_column(nr = 1:100) %&gt;% relocate(nr) ## Setter sd = 2 fordi variasjonen med regel 2 er dobbel av regel 1 (jfr SPC for Excel) regel2_y &lt;- as_tibble(rnorm(100, mean = 0, sd = 2)) %&gt;% rename(y = value) %&gt;% add_column(nr = 1:100) %&gt;% relocate(nr) regel2 &lt;- merge(regel2_x,regel2_y,by=&quot;nr&quot;) regel2_plot &lt;- ggplot(regel2, aes(x = x, y = y)) + geom_point(size = 1) + labs(x = &quot;x&quot;, y = &quot;y&quot;, title = &quot;Regel 2&quot;) + xlim(-5,5) + ylim(-5,5) + geom_vline(xintercept = 0, col = &quot;red&quot;) + geom_hline(yintercept = 0, col = &quot;red&quot;) # Henter tall fra Excel for regel 3: regel3 &lt;- read.xlsx(&quot;Funnel_blankedata_regel3.xlsx&quot;, 1) regel3_plot &lt;- ggplot(regel3, aes(x = Regel_3_x, y = Regel_3_y)) + geom_point(size = 1) + labs(x = &quot;x&quot;, y = &quot;y&quot;, title = &quot;Regel 3&quot;) + xlim(-5,5) + ylim(-5,5)+ geom_vline(xintercept = 0, col = &quot;red&quot;) + geom_hline(yintercept = 0, col = &quot;red&quot;) # Henter tall fra Excel for regel 4: regel4 &lt;- read.xlsx(&quot;Funnel_blankedata_regel4.xlsx&quot;, 1) regel4_plot &lt;- ggplot(regel4, aes(x = Regel_4_x, y = Regel_4_y)) + geom_point(size = 1) + labs(x = &quot;x&quot;, y = &quot;y&quot;, title = &quot;Regel 4&quot;) + xlim(-5,5) + ylim(-5,5)+ geom_vline(xintercept = 0, col = &quot;red&quot;) + geom_hline(yintercept = 0, col = &quot;red&quot;) # Setter plottene sammen: ggarrange(regel1_plot, regel2_plot, regel3_plot, regel4_plot + rremove(&quot;x.text&quot;), ncol = 2, nrow = 2) Lage fig 3.2: regel3_2 &lt;- read.xlsx(&quot;Funnel_blankedata_regel3_2.xlsx&quot;, 1) regel3_2_plot &lt;- ggplot(regel3_2, aes(x = x, y = y)) + geom_point(size = 1) + labs(x = &quot;x&quot;, y = &quot;y&quot;, title = &quot;Regel 3 - annet førstetreff&quot;) + xlim(-5,5) + ylim(-5,5)+ geom_vline(xintercept = 0, col = &quot;red&quot;) + geom_hline(yintercept = 0, col = &quot;red&quot;) regel3_2_plot Lage fig 3.3: regel4_2 &lt;- read.xlsx(&quot;Funnel_blankedata_regel4_2.xlsx&quot;, 1) regel4_2_plot &lt;- ggplot(regel4_2, aes(x = x, y = y)) + geom_point(size = 1) + labs(x = &quot;x&quot;, y = &quot;y&quot;, title = &quot;Regel 4 - annet førstetreff&quot;) + xlim(-2,10) + ylim(-10,2)+ geom_vline(xintercept = 0, col = &quot;red&quot;) + geom_hline(yintercept = 0, col = &quot;red&quot;) regel4_2_plot Lage fig 3.4: pacman::p_load(qicharts2) regel1x &lt;- regel1 %&gt;% pull(2) regel1y &lt;- regel1 %&gt;% pull(3) regel1xrun &lt;- qic(regel1x, title = &#39;x-verdi ved regel 1&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) regel1yrun &lt;- qic(regel1y, title = &#39;y-verdi ved regel 1&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) ggarrange(regel1xrun, regel1yrun + rremove(&quot;x.text&quot;), ncol = 2, nrow = 1, widths = c(1, 1)) Lage fig 3.5: pacman::p_load(qicharts2) regel2x &lt;- regel2 %&gt;% pull(2) regel2y &lt;- regel2 %&gt;% pull(3) regel2xrun &lt;- qic(regel2x, title = &#39;x-verdi ved regel 2&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) regel2yrun &lt;- qic(regel2y, title = &#39;y-verdi ved regel 2&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) ggarrange(regel2xrun, regel2yrun + rremove(&quot;x.text&quot;), ncol = 2, nrow = 1, widths = c(1, 1)) Lage fig 3.6: pacman::p_load(qicharts2) regel3x &lt;- regel3 %&gt;% pull(2) regel3y &lt;- regel3 %&gt;% pull(3) regel3xrun &lt;- qic(regel3x, title = &#39;x-verdi ved regel 3&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) regel3yrun &lt;- qic(regel3y, title = &#39;y-verdi ved regel 3&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) ggarrange(regel3xrun, regel3yrun + rremove(&quot;x.text&quot;), ncol = 2, nrow = 1, widths = c(1, 1)) Lage fig 3.7: pacman::p_load(qicharts2) regel4x &lt;- regel4 %&gt;% pull(2) regel4y &lt;- regel4 %&gt;% pull(3) regel4xrun &lt;- qic(regel4x, title = &#39;x-verdi ved regel 4&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) regel4yrun &lt;- qic(regel4y, title = &#39;y-verdi ved regel 4&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) ggarrange(regel4xrun, regel4yrun + rremove(&quot;x.text&quot;), ncol = 2, nrow = 1, widths = c(2, 2)) Lage fig 3.8: pacman::p_load(xlsx, qicharts2, tidyverse, ggplot2, ggpubr) toteam1 &lt;- read.xlsx(&quot;toteam.xlsx&quot;, 1) team1 &lt;- qic(Team.1, data = toteam1, chart = &#39;i&#39;, show.grid = TRUE, title = &quot;Team 1&quot;, ylab = &quot;Antall defekter pr uke&quot;, xlab = &quot;Uke #&quot;) team2 &lt;- qic(Team.2, data = toteam1, chart = &#39;i&#39;, show.grid = TRUE, title = &quot;Team 2&quot;, ylab = &quot;Antall defekter pr uke&quot;, xlab = &quot;Uke #&quot;) ggarrange(team1, team2 + rremove(&quot;x.text&quot;), ncol = 2, nrow = 1, widths = c(1, 1)) Lage fig 3.9: pacman::p_load(xlsx, qicharts2, tidyverse, ggplot2, ggpubr) toteam2 &lt;- readxl::read_excel(&quot;toteam.xlsx&quot;) %&gt;% pivot_longer(c(&quot;Team 1&quot;, &quot;Team 2&quot;)) qic(Nr, value, data = toteam2, facets = ~name, xlab = &quot;Uke #&quot;, ylab = &quot;Antall defekter pr uke&quot;, title = &quot;To team - like prosesser - ulik variasjon&quot;) Kapittel 4 Lage fig 4.1: pacman::p_load(tidyverse) set.seed(30) x = rnorm(100, 179, 16) hist(x, xlab = &quot;Høyde&quot;, ylab = &quot;Antall&quot;, main = &quot;Histogram for genererte høydedata&quot;) Lage fig 4.2: data1 &lt;- sample(165:175, 50, replace=TRUE) data2 &lt;- sample(170:180, 30, replace=TRUE) data3 &lt;- sample(180:185, 15, replace = TRUE) data4 &lt;- sample(185:190, 5, replace = TRUE) data &lt;- c(data1, data2, data3, data4) hist(data, xlab = &quot;Høyde&quot;, ylab = &quot;Antall&quot;, main = &quot;Histogram for genererte høydedata&quot;) Lage fig 4.3: pacman::p_load(ggplot2, readxl, tidyverse, ggfortify) set.seed(100) normalfordeling &lt;- rnorm(100, mean = 0, sd = 1) hist(normalfordeling, main = &quot;Genererte, normalfordelte data&quot;, xlab = &quot;x&quot;, ylab = &quot;f(x)&quot;, border = &quot;black&quot;, col = &quot;gray&quot;, xlim = c(-4,4), ylim = c(0,0.5), las = 1, probability = TRUE) Lage fig 4.4: set.seed(100) normalfordeling &lt;- rnorm(100, mean = 0, sd = 1) hist(normalfordeling, main = &quot;Genererte, normalfordelte data&quot;, xlab = &quot;x&quot;, ylab = &quot;f(x)&quot;, border = &quot;black&quot;, col = &quot;gray&quot;, xlim = c(-4,4), ylim = c(0,0.5), las = 1, probability = TRUE) m &lt;- mean(normalfordeling) std &lt;- sqrt(var(normalfordeling)) curve(dnorm(x, mean = m, sd = std), col=&quot;darkblue&quot;, lwd = 3, add = TRUE, yaxt = &quot;n&quot;) Lage fig 4.5: pacman::p_load(ggplot2, readxl, tidyverse, ggfortify) ggplot(data.frame(x = c(-4, 4)), aes(x)) + geom_function(fun = dnorm, colour = &quot;darkblue&quot;, size = 1.5) + theme_classic() + scale_y_continuous(limits = c(0, 0.5), breaks = seq(0, 0.5, by = 0.1)) Lage fig 4.6: x &lt;- seq(-4, 4, length=200) y &lt;- dnorm(x) plot(x, y, type=&quot;l&quot;, lty=1, lwd = 2, col = &quot;red&quot;, xlab=&quot;x&quot;, ylab=&quot;f(x)&quot;) x &lt;- seq(-1,1,length=100) y &lt;- dnorm(x) polygon(c(-1,x,1),c(0,y,0),col=&quot;lightblue&quot;) abline(v=-1, col=&quot;green&quot;, lwd = 2) text(1.3, 0.38, &quot;1 SD&quot;, col = &quot;black&quot;) text(-1.35, 0.38, &quot;-1 SD&quot;, col = &quot;black&quot;) abline(v=1, col=&quot;green&quot;, lwd = 2) text(0, 0.2, &quot;68 %&quot;, col = &quot;black&quot;) Lage fig 4.7: x &lt;- seq(-4,4,length=200) y &lt;- dnorm(x) plot(x, y, type=&quot;l&quot;, lty=1, lwd = 2, col = &quot;red&quot;, xlab=&quot;x&quot;, ylab=&quot;f(x)&quot;) x &lt;- seq(-2,2,length=200) y &lt;- dnorm(x) polygon(c(-2,x,2),c(0,y,0),col=&quot;lightblue&quot;) abline(v=-2, col=&quot;green&quot;, lwd = 2) text(2.3, 0.38, &quot;2 SD&quot;, col = &quot;black&quot;) text(-2.35, 0.38, &quot;-2 SD&quot;, col = &quot;black&quot;) abline(v=2, col=&quot;green&quot;, lwd = 2) text(0, 0.2, &quot;95 %&quot;, col = &quot;black&quot;) Utregning av areal mellom to x-verdier i normalfordeling: pnorm(2,mean=0,sd=1)-pnorm(-2,mean=0,sd=1) Lage fig 4.8: x &lt;- seq(-4,4,length=200) y &lt;- dnorm(x) plot(x,y,type=&quot;l&quot;,lwd=2,col=&quot;red&quot;, xlab=&quot;x&quot;, ylab=&quot;f(x)&quot;) x &lt;- seq(-3,3,length=200) y &lt;- dnorm(x) polygon(c(-3,x,3),c(0,y,0),col=&quot;lightblue&quot;) abline(v=-3, col=&quot;green&quot;, lwd = 2) text(3.3, 0.38, &quot;3 SD&quot;, col = &quot;black&quot;) text(-3.35, 0.38, &quot;-3 SD&quot;, col = &quot;black&quot;) abline(v=3, col=&quot;green&quot;, lwd = 2) text(0, 0.2, &quot;99.7 %&quot;, col = &quot;black&quot;) Lage fig 4.9: y.norm &lt;- rnorm(n= 100000, mean = 0, sd = 1) h &lt;- hist(y.norm, breaks = 100, plot = F) cuts &lt;- cut(h$breaks, c(-Inf,-3,-2,-1,1,2,3,Inf), right = F) # right=False; sets intervals to be open on the right closed on the left plot(h, col = rep(c(&quot;white&quot;, &quot;4&quot;,&quot;3&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;, &quot;white&quot;))[cuts], main = &#39;Normalfordeling&#39;, xlab = &#39;&#39;, freq = F, ylim = c(0,0.6)) lwd = 3 # horzintal lines lines(x = c(2,-2), y = c(0.48,0.48), type = &quot;l&quot;, col=3, lwd = lwd) lines(x = c(3,-3), y = c(0.55,0.55), type = &quot;l&quot;, col=4, lwd = lwd) lines(x = c(1,-1), y = c(0.41,0.41), type = &quot;l&quot;, col=2, lwd = lwd) # vertical lines lines(x = c(1,1), y = c(0,0.41), type = &quot;l&quot;, col=2, lwd = lwd) lines(x = c(-1,-1), y = c(0,0.41), type = &quot;l&quot;, col=2, lwd = lwd) lines(x = c(2,2), y = c(0,0.48), type = &quot;l&quot;, col=3, lwd = lwd) lines(x = c(-2,-2), y = c(0,0.48), type = &quot;l&quot;, col=3, lwd = lwd) lines(x = c(3,3), y = c(0,0.55), type = &quot;l&quot;, col=4, lwd = lwd) lines(x = c(-3,-3), y = c(0,0.55), type = &quot;l&quot;, col=4, lwd = lwd) # text text(0, 0.44, &quot;68%&quot;, cex = 1.5, col=2) text(0, 0.51, &quot;95%&quot;, cex = 1.5, col=3) text(0, 0.58, &quot;99.7%&quot;, cex = 1.5, col=4) Lage fig 4.10: success &lt;- 0:20 plot(success,dbinom(success,size=20,prob=.5), type=&#39;h&#39;, main=&quot;Binomial distribusjon (n=20, p=0.5)&quot;, ylab=&quot;Sannsynlighet&quot;, xlab = &quot;Suksess&quot;, lwd=10) Lage fig 4.11: success &lt;- 0:20 plot(success,dbinom(success,size=20,prob=.2), type=&#39;h&#39;, main=&quot;Binomial distribusjon (n=20, p=0.2)&quot;, ylab=&quot;Sannsynlighet&quot;, xlab = &quot;Suksess&quot;, lwd=10) Lage fig 4.12: set.seed(32) terning10 &lt;- sample(1:6, 10, replace = TRUE) stripchart(terning10, method = &quot;stack&quot;, offset = .5, at = 0, pch = 19, col = &quot;steelblue&quot;, main = &quot;10 terningkast&quot;, xlab = &quot;Verdi på terning&quot;, ylab = &quot;Antall&quot;)) Lage fig 4.13: set.seed(33) terning10 &lt;- sample(1:6, 100, replace = TRUE) stripchart(terning10, method = &quot;stack&quot;, offset = .5, at = 0, pch = 19, col = &quot;steelblue&quot;, main = &quot;100 terningkast&quot;, xlab = &quot;Verdi på terning&quot;, ylab = &quot;Antall&quot;) Lage simulering av terningkast: set.seed(43) terning_runde1 &lt;- sample(1:6, 600, replace = TRUE) table(terning_runde1) set.seed(44) terning_runde2 &lt;- sample(1:6, 600, replace = TRUE) table(terning_runde2) set.seed(45) terning_runde3 &lt;- sample(1:6, 600, replace = TRUE) table(terning_runde3) Lage fig 4.14: set.seed(46) minterning &lt;- sample(1:6, 6000000, replace = TRUE) options(scipen=999) hist(minterning, main=&quot;Histogram for 6 000 000 terningkast&quot;, ylab=&quot;Antall&quot;, xlab = &quot;Verdi på terning&quot;) Lage fig 4.15: # Grid of X-axis values x &lt;- 0:50 #----------- # lambda: 5 #----------- lambda &lt;- 5 plot(dpois(x, lambda), type = &quot;h&quot;, lwd = 2, main = &quot;Poisson sannsynlighetsfordeling&quot;, ylab = &quot;P(X = x)&quot;, xlab = &quot;Antall hendelser&quot;) #----------- # lambda: 10 #----------- lambda &lt;- 10 lines(dpois(x, lambda), type = &quot;h&quot;, lwd = 2, col = rgb(1,0,0, 0.7)) #----------- # lambda: 20 #----------- lambda &lt;- 20 lines(dpois(x, lambda), type = &quot;h&quot;, lwd = 2, col = rgb(0, 1, 0, 0.7)) # Legend legend(&quot;topright&quot;, legend = c(&quot;5&quot;, &quot;10&quot;, &quot;20&quot;), title = expression(lambda), title.adj = 0.75, lty = 1, col = 1:3, lwd = 2, box.lty = 0) Lage fig 4.16: maal &lt;- 0:10 plot(maal, dpois(maal, lambda=2.5), type=&#39;h&#39;, main=&#39;Poissonfordeling (lambda = 2.5)&#39;, ylab=&#39;Sannsynlighet&#39;, xlab =&#39;# Mål&#39;, lwd=3) Regne ut sannsynligheter: # Sannsynligheten for 0 mål dpois(x = 0, lambda = 2.5) # Sannsynligheten for 1 mål dpois(x = 1, lambda = 2.5) # Sannsynligheten for 2 mål dpois(x = 2, lambda = 2.5) # Sannsynligheten for 3 mål dpois(x = 3, lambda = 2.5) # Sannsynligheten for 4 mål dpois(x = 4, lambda = 2.5) # sannsynligheten for mellom 1 og 3 mål: dpois(x = 1, lambda = 2.5) + dpois(x=2, lambda = 2.5) + dpois(x=3, lambda = 2.5) Lage fig 4.17: x_dgeom &lt;- seq(1, 20, by = 1) y_dgeom &lt;- dgeom(x_dgeom, prob = 0.4) plot(y_dgeom, type=&quot;l&quot;, main=&quot;Geometrisk fordeling for p = 0.4&quot;, ylab=&quot;f(x)&quot;, xlab = &quot;x&quot;) Lage fig 4.18: pacman::p_load(ggpubr) eksford &lt;- seq(0, 20, length.out=1000) dat1 &lt;- data.frame(x=eksford, fx=dexp(eksford, rate=0.2)) %&gt;% add_column(ID = 1:1000) %&gt;% relocate(3) dat2 &lt;- data.frame(x=eksford, fx=dexp(eksford, rate=1)) %&gt;% add_column(ID = 1:1000) %&gt;% relocate(3) dat3 &lt;- data.frame(x=eksford, fx=dexp(eksford, rate=1.5)) %&gt;% add_column(ID = 1:1000) %&gt;% relocate(3) dat4 &lt;- data.frame(x=eksford, fx=dexp(eksford, rate=2)) %&gt;% add_column(ID = 1:1000) %&gt;% relocate(3) dat1plot &lt;- ggplot(dat1, aes(x=x, y=fx)) + geom_line() + ggtitle(expression( ~ lambda ~ &quot; = 0.2&quot;)) dat2plot &lt;- ggplot(dat2, aes(x=x, y=fx)) + geom_line() + ggtitle(expression( ~ lambda ~ &quot; = 1.0&quot;)) dat3plot &lt;- ggplot(dat3, aes(x=x, y=fx)) + geom_line() + ggtitle(expression( ~ lambda ~ &quot; = 1.5&quot;)) dat4plot &lt;- ggplot(dat4, aes(x=x, y=fx)) + geom_line() + ggtitle(expression( ~ lambda ~ &quot; = 2.0&quot;)) ggarrange(dat1plot, dat2plot, dat3plot, dat4plot + rremove(&quot;x.text&quot;), ncol = 2, nrow = 2, widths = c(1, 1)) Kapittel 5 Lage fig 5.1: pacman::p_load(tidyverse, ggplot2, writexl, ggpubr) # Lage normalfordelt datasett set.seed(89) qqnorm &lt;- rnorm(10000, mean=90, sd=5) qqnorm &lt;- as_tibble(qqnorm) # Plotte Q-Q plott ggqqplot(qqnorm$value) + ggtitle(&quot;Normal Q-Q plott&quot;) + labs(x = &quot;Teoretisk forventning&quot;, y = &quot;Data&quot;) Lage fig 5.2: pacman::p_load(gridExtra, writexl, ggplot2, tidyverse, ggpubr) # Lage datasett med right skew N &lt;- 5000 qqrightskew &lt;- rnbinom(N, 10, .1) qqrightskew &lt;- as_tibble(qqrightskew) # Plotte histogram og Q-Q plott qqrighthist &lt;- ggplot(qqrightskew, aes(x=value)) + geom_histogram(color=&quot;black&quot;, fill=&quot;lightblue&quot;) qqrightskew_plott &lt;- ggqqplot(qqrightskew$value) + ggtitle(&quot;Normal Q-Q plott - skjevhet høyre&quot;) + labs(x = &quot;Teoretisk forventning&quot;, y = &quot;Data&quot;) grid.arrange(qqrighthist, qqrightskew_plott, ncol=2) Lage fig 5.3: pacman::p_load(gridExtra, writexl, ggplot2, tidyverse, ggpubr) # Lage datasett med left skew set.seed(91) N=5000 qqleftskew &lt;- rbeta(N,2,0.5,ncp=2) qqleftskew &lt;- as_tibble(qqleftskew) # Plotte histogram og Q-Q plott&quot; qqlefthist &lt;- ggplot(qqleftskew, aes(x=value)) + geom_histogram(color=&quot;black&quot;, fill=&quot;lightblue&quot;) qqlefthist &lt;- ggplot(qqleftskew, aes(x=value)) + geom_histogram(color=&quot;black&quot;, fill=&quot;lightblue&quot;) qqleftskew_plott &lt;- ggqqplot(qqleftskew$value) + ggtitle(&quot;Normal Q-Q plott - skjevhet venstre&quot;) + labs(x = &quot;Teoretisk forventning&quot;, y = &quot;Data&quot;) grid.arrange(qqlefthist, qqleftskew_plott, ncol=2) Lage fig 5.4: pacman::p_load(gridExtra, writexl, ggplot2, tidyverse, ggpubr) # Lage datasett med fet hale set.seed(14) N=100 qqcauchy &lt;- as_tibble(rcauchy(N, scale = 5)) # Plotte histogram og Q-Q plott qqcauchyhist &lt;- ggplot(qqcauchy, aes(x=value)) + geom_histogram(color=&quot;black&quot;, fill=&quot;lightblue&quot;) qqcauchyhist &lt;- ggplot(qqcauchy, aes(x=value)) + geom_histogram(color=&quot;black&quot;, fill=&quot;lightblue&quot;) qqcauchy_plott &lt;- ggqqplot(qqcauchy$value) + ggtitle(&quot;Normal Q-Q plott - tung hale&quot;) + labs(x = &quot;Teoretisk forventning&quot;, y = &quot;Data&quot;) grid.arrange(qqcauchyhist, qqcauchy_plott, ncol=2) Lage fig 5.5: pacman::p_load(gridExtra, writexl, ggplot2, tidyverse, ggpubr) # Lage datasett med tynn hale set.seed(81) qqlt &lt;- runif(n = 1000, min = -1, max = 1) qqlt &lt;- as_tibble(qqlt) # Plotte histogram og Q-Q plott qqlthist &lt;- ggplot(qqlt, aes(x=value)) + geom_histogram(color=&quot;black&quot;, fill=&quot;lightblue&quot;) qqlt_plott &lt;- ggqqplot(qqlt$value) + ggtitle(&quot;Normal Q-Q plott - lett hale&quot;) + labs(x = &quot;Teoretisk forventning&quot;, y = &quot;Data&quot;) grid.arrange(qqlthist, qqlt_plott, ncol=2) Lage fig 5.6: pacman::p_load(gridExtra, writexl, ggplot2, tidyverse, ggpubr) # Lage bimodialt datasett set.seed(10) mode1 &lt;- rnorm(50,2,1) mode1 &lt;- mode1[mode1 &gt; 0] mode2 &lt;- rnorm(50,6,1) mode2 &lt;- mode2[mode2 &gt; 0] qqbimod &lt;- as_tibble(sort(c(mode1,mode2))) # Plotte histogram og Q-Q plott qqbimodhist &lt;- ggplot(qqbimod, aes(x=value)) + geom_histogram(color=&quot;black&quot;, fill=&quot;lightblue&quot;) qqbimod_plott &lt;- ggplot(qqbimod, aes(sample = value)) + stat_qq() + stat_qq_line() + ggtitle(&quot; Normal Q-Q plott - bimodial&quot;) + labs(x = &quot;Teoretisk forventning&quot;, y = &quot;Data&quot;) grid.arrange(qqbimodhist, qqbimod_plott, ncol=2) Kjøre Anderson-Darling test for normalitet: pacman::p_load(nortest, readxl, tidyverse) addata &lt;- as_tibble(read_excel(&quot;Anderson-Darling_raw.xlsx&quot;)) ad.test(addata$Values) Lage fig 5.7: pacman::p_load(gridExtra, writexl, ggplot2, tidyverse, readxl) addata2 &lt;- as_tibble(read_excel(&quot;Anderson-Darling_raw.xlsx&quot;)) ggplot(addata2, aes(sample = Values)) + stat_qq() + stat_qq_line() + ggtitle(&quot; Normal Q-Q plott - A-D data&quot;) + labs(x = &quot;Teoretisk forventning&quot;, y = &quot;Data&quot;) Kjøre Anderson-Darling test for normalitet på normalfordelte data: pacman::p_load(nortest, readxl, tidyverse) addata3 &lt;- as_tibble(read_excel(&quot;QQ_norm.xlsx&quot;)) ad.test(addata3$value) Kjøre statistiske tester: pacman::p_load(nortest, readxl, tidyverse, tseries) options(scipen=999) addata5 &lt;- as_tibble(read_excel(&quot;Anderson-Darling_raw.xlsx&quot;)) ks.test(addata5, &quot;pnorm&quot;) shapiro.test(addata5$Values) cvm.test(addata$Values) Jarque-Bera test: addata6 &lt;- as_tibble(read_excel(&quot;Anderson-Darling_raw.xlsx&quot;)) pacman::p_load(tseries, normtest) jarque.bera.test(addata6$Values) ajb.norm.test(addata6$Values, nrepl=2000) Lage fig 5.8: pacman::p_load(ggpubr, tidyverse) addata7 &lt;- as_tibble(read_excel(&quot;Anderson-Darling_raw.xlsx&quot;)) ggqqplot(addata7$Values) Kapittel 6 Lage fig 6.1: pacman::p_load(qicharts2, ggplot2) set.seed(21) eksempelrun &lt;- rnorm(24, 16) serie1 &lt;- qic(eksempelrun, title = &quot;Eksempel på seriediagram - normalfordelte genererte tall&quot;, ylab = &quot;Verdi&quot;, xlab = &quot;Hendelse&quot;, method = &quot;anhoej&quot;) serie1 + geom_point(size = 2) Lage fig 6.2: pacman::p_load(qicharts2, ggplot2) set.seed(43) eksempelrun[13:24] &lt;- rpois(12, 24) serie2 &lt;- qic(eksempelrun, title = &quot;Eksempel på seriediagram - modifiserte genererte tall&quot;, ylab = &quot;Verdi&quot;, xlab = &quot;Hendelse&quot;, method = &quot;anhoej&quot;) serie2 + geom_point(size = 2) Lage fig 6.3: pacman::p_load(qicharts2, ggplot2) serie3 &lt;- qic(eksempelrun, title = &quot;Eksempel på seriediagram - endring i prosess&quot;, ylab = &quot;Verdi&quot;, xlab = &quot;Hendelse&quot;, method = &quot;anhoej&quot;, part = 14) serie3 + geom_point(size = 2) Kapittel 7 Lage fig 7.1: pacman::p_load(qicharts2, tidyverse) set.seed(81) kontr_eks &lt;- (rnorm(24)) kontr1 &lt;- qic(kontr_eks, chart = &#39;i&#39;, title = &quot;Eksempel på kontrolldiagram&quot;, subtitle = &quot;Tilfeldig genererte tall&quot;, ylab = &quot;Verdi&quot;, xlab = &quot;Hendelse&quot;) kontr1 + geom_point(size = 2) Lage fig 7.2: pacman::p_load(qcc, tidyverse) set.seed(81) kontr_eks &lt;- (rnorm(24)) kontr_eks &lt;- as_tibble(kontr_eks) kontr2 &lt;- qcc(kontr_eks, type = &quot;xbar.one&quot;, nsigmas = 3) plot(kontr2, title = &quot;Eksempel på kontrolldiagram - Tilfeldig genererte tall&quot;, ylab = &quot;Verdi&quot;, xlab = &quot;Hendelse&quot;) Lage fig 7.3: pacman::p_load(qcc, tidyverse) set.seed(64) mode1x &lt;- rnorm(15,2,1) mode1x &lt;- mode1x[mode1x &gt; 0] mode2x &lt;- rnorm(15,3,2) mode2x &lt;- mode2x[mode2x &gt; 0] kontr_eks2 &lt;- (sort(c(mode1x,mode2x))) kontr_eks2 &lt;- as_tibble(kontr_eks2) qq &lt;- qcc(kontr_eks2, type = &quot;xbar.one&quot;, nsigmas = 3) plot(qq, title = &quot;Eksempel på kontrolldiagram - Tilfeldig genererte tall&quot;, ylab = &quot;Verdi&quot;, xlab = &quot;Hendelse&quot;) Lage fig 7.4: pacman::p_load(qcc, tidyverse, readxl) pdiagr &lt;- as_tibble(read_excel(&quot;P_chart.xlsx&quot;)) p_chart &lt;- with(pdiagr, qcc(pdiagr$Keisersnitt, pdiagr$Antall_fødsler, type = &quot;p&quot;)) plot(p_chart, title = &quot;p-diagram: Andel keisersnitt&quot;, xlab = &quot;Måned&quot;, ylab = &quot;Andel&quot;) Lage fig 7.5: pacman::p_load(qcc, tidyverse, readxl) Lpdiagr &lt;- as_tibble(read_excel(&quot;Laneyp.xlsx&quot;)) Lp_chart &lt;- with(Lpdiagr, qcc(Lpdiagr$Pr_telefon, Lpdiagr$Medlemmer, type = &quot;p&quot;)) plot(Lp_chart, title = &quot;p-diagram: Andel kommunisert pr telefon&quot;, xlab = &quot;Måned&quot;, ylab = &quot;Andel&quot;) Lage fig 7.6: pacman::p_load(qcc, tidyverse, readxl) npdiagr &lt;- as_tibble(read_excel(&quot;np_diagram.xlsx&quot;)) np_chart &lt;- with(npdiagr, qcc(npdiagr$Feil, npdiagr$n, type = &quot;np&quot;)) plot(np_chart, title = &quot;np-diagram: Andel feil&quot;, xlab = &quot;Uke&quot;, ylab = &quot;Andel&quot;) Lage fig 7.7: pacman::p_load(qcc, tidyverse, readxl) udiagr &lt;- as_tibble(read_excel(&quot;u_diagram.xlsx&quot;)) u_chart &lt;- with(udiagr, qcc(udiagr$Pasientfall, udiagr$Pasientdager, type = &quot;u&quot;)) plot(u_chart, title = &quot;u-diagram: Andel feil&quot;, xlab = &quot;Uke&quot;, ylab = &quot;Pasientfall&quot;) Lage fig 7.8: pacman::p_load(qcc, tidyverse, readxl) cdiagr &lt;- as_tibble(read_excel(&quot;cdiagram.xlsx&quot;)) c_chart &lt;- with(cdiagr, qcc(cdiagr$Feilmedisinering, type = &quot;c&quot;)) plot(c_chart, title = &quot;c-diagram&quot;, xlab = &quot;Måned&quot;, ylab = &quot;Feilmedisinering&quot;) Lage fig 7.9: pacman::p_load(qcc, tidyverse, readxl) imrdiagr &lt;- as_tibble(read_excel(&quot;imr_diagram.xlsx&quot;)) imr_chart &lt;- with(imrdiagr, qcc(imrdiagr$Fødselsvekt, type = &quot;xbar.one&quot;)) plot(imr_chart, title = &quot;IMR-diagram&quot;, xlab = &quot;Baby nr&quot;, ylab = &quot;Fødselsvekt&quot;) Lage fig 7.10: pacman::p_load(qicharts2, tidyverse) set.seed(43) datoer &lt;- seq(as.Date(&#39;2020-1-1&#39;), as.Date(&#39;2020-12-31&#39;), by = &#39;day&#39;) hendelser &lt;- sort(sample(datoer, 24)) t_diagram_data &lt;- c(NA, diff(hendelser)) t_diagram &lt;- qic(t_diagram_data, chart = &quot;t&quot;, title = &quot;T-diagram&quot;, xlab = &quot;Hendelse nr.&quot;, ylab = &quot;Dager&quot;) t_diagram + geom_point() Vedlegg 2 pacman::p_load(kableExtra) n &lt;- 10:100 hendelser &lt;- data.frame( &quot;Antall observasjoner&quot; = n, &quot;Øvre grense for serie&quot; = round(log2(n) + 3), &quot;Nedre grense for antall krysninger&quot; = qbinom(0.05, n - 1, 0.5), check.names = FALSE) kbl(hendelser, booktabs = T, longtable = T, caption = &quot;Kritiske verdier&quot;, align = &#39;c&#39;) %&gt;% kable_styling(latex_options = &quot;striped&quot;) %&gt;% kable_styling(latex_options = &quot;repeat_header&quot;) %&gt;% row_spec(0, bold = T) Vedlegg 3 Lage generisk grafisk framstilling av Chebyshevs teorem pacman::p_load(tidyverse) # For å lage eksempelet lager vi to normalfordelte datasett med ulik gjennomsnitt og standardavvik som vi slår sammen set.seed(10) mode1 &lt;- rnorm(1000,2,1) mode1 &lt;- mode1[mode1 &gt; 0] mode2 &lt;- rnorm(1000,6,2) mode2 &lt;- mode2[mode2 &gt; 0] modex2 &lt;- as_tibble(sort(c(mode1,mode2))) # Deretter setter vi dataene inn i et diagram ggplot(modex2, aes(x=value)) + geom_density() + ggtitle(&quot;Eksempel: Bimodal distribusjon&quot;, subtitle = &quot;Eksemplet er kun illustrativt, ikke nøyaktig eller basert på reelle data&quot;) + labs(x = &quot;&quot;, y = &quot;&quot;) + theme_classic() + theme(legend.position = &quot;none&quot;) + scale_x_discrete(labels = NULL, breaks = NULL) + labs(x = &quot;&quot;) + xlim(-0.02, 8) + ylim(-0.02,0.3) + annotate(&quot;segment&quot;, x = 4, y = 0, xend = 4, yend = 0.15, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + annotate(&#39;text&#39;, x = 4, y = -0.015, label = &quot;bar(x)&quot;, parse = TRUE, size = 5) + annotate(&quot;segment&quot;, x = 7.8, y = 0, xend = 7.8, yend = 0.275, color = &quot;darkgreen&quot;) + annotate(&#39;text&#39;, x = 7.8, y = -0.015, label = &quot;bar(x) ~ + ~ 3 ~ sd&quot;, parse = TRUE, size = 5) + annotate(&quot;segment&quot;, x = 0.2, y = 0, xend = 0.2, yend = 0.275, color = &quot;darkgreen&quot;) + annotate(&#39;text&#39;, x = 0.3, y = -0.015, label = &quot;bar(x)~-~3~sd&quot;, parse = TRUE, size = 5) + annotate(&quot;segment&quot;, x = 2.1, y = 0, xend = 2.1, yend = 0.235, color = &quot;blue&quot;) + annotate(&#39;text&#39;, x = 2.1, y = -0.015, label = &quot;bar(x)~-~2~sd&quot;, parse = TRUE, size = 5) + annotate(&quot;segment&quot;, x = 5.9, y = 0, xend = 5.9, yend = 0.235, color = &quot;blue&quot;) + annotate(&#39;text&#39;, x = 5.9, y = -0.015, label = &quot;bar(x)~+~2~sd&quot;, parse = TRUE, size = 5) + annotate(&quot;text&quot;, x=4, y=0.23, label=&quot;Minst 75 %&quot;, color = &quot;blue&quot;) + annotate(&quot;segment&quot;, x = 3.35, y = 0.23, xend = 2.25, yend = 0.23, color = &quot;blue&quot;) + annotate(&quot;segment&quot;, x = 4.6, y = 0.23, xend = 5.8, yend = 0.23, color = &quot;blue&quot;) + annotate(&quot;text&quot;, x=4, y=0.27, label=&quot;Minst 88.89 %&quot;, color = &quot;darkgreen&quot;) + annotate(&quot;segment&quot;,x = 0.3, y = 0.27, xend = 3.2, yend = 0.27, color = &quot;darkgreen&quot;) + annotate(&quot;segment&quot;, x = 4.8, y = 0.27, xend = 7.7, yend = 0.27, color = &quot;darkgreen&quot;) Lage tabell over k og prosent pacman::p_load(tidyverse, kableExtra, knitr) k &lt;- seq(1,4,by = 0.1) auc &lt;- 1-(1/k^2) auc.percent &lt;- round(auc*100) cheb_table &lt;- as_tibble(cbind(k,auc.percent)) kbl(cheb_table) %&gt;% kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F) %&gt;% kable_paper() %&gt;% scroll_box(height = &quot;200px&quot;) Lage graf over k og prosent plot(k, auc.percent, col = &#39;blue&#39;, pch = 10, xlab = &#39;k&#39;, ylab = &#39;Prosent&#39;, main = &#39;Chebyshevs teorem&#39; ) abline(v=2, col=&quot;red&quot;, lwd = 1) abline(h=75, col=&quot;red&quot;, lwd = 1) Vedlegg 4 Lage ikke-normalfordelte data og plotte Q-Q plott pacman::p_load(ggplot2, tidyverse, magrittr, dplyr, truncnorm) nn &lt;- 1e4 set.seed(1) sims &lt;- as_tibble(c(rtruncnorm(nn/2, a=1, b=5, mean=2, sd=.5), rtruncnorm(nn/2, a=1, b=5, mean=4, sd=.5))) ggplot(sims, aes(sample=value)) + stat_qq() + stat_qq_line(col = &quot;red&quot;) Lage første histogram (populasjonen) pacman::p_load(ggplot2, tidyverse, magrittr, dplyr, truncnorm) nn &lt;- 1e4 set.seed(1) sims &lt;- c(rtruncnorm(nn/2, a=1, b=5, mean=2, sd=.5), rtruncnorm(nn/2, a=1, b=5, mean=4, sd=.5)) mySD &lt;- as.character(abs(as.integer((sims - mean(sims)) / sd(sims)))) myDF &lt;- data.frame(sims, mySD) xAxis &lt;- as.integer(max(abs(sims))) mu &lt;- round(mean(sims),2) sd &lt;- round(sd(sims),2) myBin &lt;- sd/10 ggplot(myDF, aes(sims)) + geom_histogram(aes(fill = mySD), binwidth = myBin, col=&quot;black&quot;, size=.1) + # change binwidth labs(x=&quot;x&quot;, y=&quot;Frequency&quot;) + labs(title=&quot;Histogram av generert bimodal distribusjon&quot;,subtitle=paste0( &quot;Gj.snitt = &quot;, mu, &quot;, sd = &quot;, sd)) + scale_x_continuous(breaks = seq(mu-sd*5, mu+sd*5, sd)) + theme_bw() + theme(plot.title = element_text(hjust = 0.5)) + guides(fill=guide_legend(expression(sigma))) Lage histogram over 100 utvalg av 30 n &lt;- 100 sampSize &lt;- 30 xbar &lt;- rep(NA, n) for (i in 1:n) { mysamp &lt;- sample(sims, size = sampSize) xbar[i] &lt;- mean(mysamp) } mySD&lt;-as.character( abs(as.integer((xbar - mean(xbar)) / sd(xbar) ))) myDF&lt;-data.frame(xbar,mySD) xAxis&lt;-as.integer(max(abs(xbar))) mu&lt;-round(mean(xbar),2) sd&lt;-round(sd(xbar),2) myBin&lt;-sd/10 ggplot(myDF, aes(xbar)) + geom_histogram(aes(fill = mySD), binwidth = myBin, col=&quot;black&quot;, size=.1) + # change binwidth labs(x=&quot;x&quot;, y=&quot;Frequency&quot;) + labs(title=&quot;Histogram for genererte utvalg&quot;, subtitle=paste0( &quot;mean = &quot;, mu, &quot;, sd = &quot;, sd, &quot;, Utvalgsstørrelse = &quot;,sampSize,&quot;, Antall utvalg = &quot;,n))+ scale_x_continuous(breaks = seq(mu-sd*5, mu+sd*5, sd))+ theme_bw()+ theme(plot.title = element_text(hjust = 0.5))+ guides(fill=guide_legend(expression(sigma)))+ geom_density(aes(y=..count../90)) Lage histogram over 1000 utvalg av 30 n&lt;-1000 sampSize&lt;-30 xbar &lt;- rep(NA, n) for (i in 1:n) { mysamp &lt;- sample(sims, size = sampSize) xbar[i] &lt;- mean(mysamp) } mySD&lt;-as.character( abs(as.integer((xbar - mean(xbar)) / sd(xbar) ))) myDF&lt;-data.frame(xbar,mySD) xAxis&lt;-as.integer(max(abs(xbar))) mu&lt;-round(mean(xbar),2) sd&lt;-round(sd(xbar),2) myBin&lt;-sd/10 ggplot(myDF, aes(xbar)) + geom_histogram(aes(fill = mySD), binwidth = myBin, col=&quot;black&quot;, size=.1) + # change binwidth labs(x=&quot;x&quot;, y=&quot;Frequency&quot;) + labs(title=&quot;Histogram for genererte utvalg&quot;, subtitle=paste0( &quot;Gj.snitt = &quot;, mu, &quot;, sd = &quot;, sd, &quot;, Utvalgsstørrelse = &quot;,sampSize,&quot;, Antall utvalg = &quot;,n))+ scale_x_continuous(breaks = seq(mu-sd*5, mu+sd*5, sd))+ theme_bw()+ theme(plot.title = element_text(hjust = 0.5))+ guides(fill=guide_legend(expression(sigma)))+ geom_density(aes(y=..count../90)) Lage histogram over 1000 utvalg av 30 n&lt;-10000 sampSize&lt;-30 xbar &lt;- rep(NA, n) for (i in 1:n) { mysamp &lt;- sample(sims, size = sampSize) xbar[i] &lt;- mean(mysamp) } mySD&lt;-as.character( abs(as.integer((xbar - mean(xbar)) / sd(xbar) ))) myDF&lt;-data.frame(xbar,mySD) xAxis&lt;-as.integer(max(abs(xbar))) mu&lt;-round(mean(xbar),2) sd&lt;-round(sd(xbar),2) myBin&lt;-sd/10 ggplot(myDF, aes(xbar)) + geom_histogram(aes(fill = mySD), binwidth = myBin, col=&quot;black&quot;, size=.1) + # change binwidth labs(x=&quot;x&quot;, y=&quot;Frequency&quot;) + labs(title=&quot;Histogram for genererte utvalg&quot;, subtitle=paste0( &quot;Gj.snitt = &quot;, mu, &quot;, sd = &quot;, sd, &quot;, Utvalgsstørrelsee = &quot;,sampSize,&quot;, Antall utvalg = &quot;,n))+ scale_x_continuous(breaks = seq(mu-sd*5, mu+sd*5, sd))+ theme_bw()+ theme(plot.title = element_text(hjust = 0.5))+ guides(fill=guide_legend(expression(sigma)))+ geom_density(aes(y=..count../90)) Vedlegg 5 pacman::p_load(flextable, SixSigma, officer, magrittr) nmax &lt;- 25 n &lt;- 2:nmax d2 &lt;- sapply(2:nmax, ss.cc.getd2) d3 &lt;- sapply(2:nmax, ss.cc.getd3) c4 &lt;- sapply(2:nmax, ss.cc.getc4) A2 &lt;- 3/(d2*sqrt(n)) D3 &lt;- sapply(1:(nmax-1), function(x){ max(c(0, 1 - 3*(d3[x]/d2[x])))}) D4 &lt;- (1 + 3*(d3/d2)) B3 &lt;- sapply(1:(nmax-1), function(x){ max(0, 1 - 3*(sqrt(1-c4[x]^2)/c4[x]))}) B4 &lt;- 1 + 3*(sqrt(1-c4^2)/c4) constdf &lt;- data.frame(n, A2, d2, d3, c4, D3, D4, B3, B4) set_flextable_defaults(big.mark = &quot; &quot;, font.size = 10, theme_fun = theme_vanilla, padding.bottom = 6, padding.top = 6, padding.left = 6, padding.right = 6, background.color = &quot;#EFEFEF&quot;) constdf1 &lt;- flextable(constdf) constdf1 &lt;- align(constdf1, align = &quot;center&quot;, part = &quot;all&quot;) constdf1 &lt;- add_header_lines(constdf1, values = &quot;Tabell med konstanter for kontrolldiagram&quot;) constdf1 "],["vedlegg-2---kritiske-verdier-i-kontrolldiagram.html", "Vedlegg 2 - Kritiske verdier i kontrolldiagram", " Vedlegg 2 - Kritiske verdier i kontrolldiagram Basert på Anhøj (2021b): Table 9.1: Kritiske verdier Antall observasjoner Øvre grense for serie Nedre grense for antall krysninger 10 6 2 11 6 2 12 7 3 13 7 3 14 7 4 15 7 4 16 7 4 17 7 5 18 7 5 19 7 6 20 7 6 21 7 6 22 7 7 23 8 7 24 8 8 25 8 8 26 8 8 27 8 9 28 8 9 29 8 10 30 8 10 31 8 11 32 8 11 33 8 11 34 8 12 35 8 12 36 8 13 37 8 13 38 8 14 39 8 14 40 8 14 41 8 15 42 8 15 43 8 16 44 8 16 45 8 17 46 9 17 47 9 17 48 9 18 49 9 18 50 9 19 51 9 19 52 9 20 53 9 20 54 9 21 55 9 21 56 9 21 57 9 22 58 9 22 59 9 23 60 9 23 61 9 24 62 9 24 63 9 25 64 9 25 65 9 25 66 9 26 67 9 26 68 9 27 69 9 27 70 9 28 71 9 28 72 9 29 73 9 29 74 9 29 75 9 30 76 9 30 77 9 31 78 9 31 79 9 32 80 9 32 81 9 33 82 9 33 83 9 34 84 9 34 85 9 34 86 9 35 87 9 35 88 9 36 89 9 36 90 9 37 91 10 37 92 10 38 93 10 38 94 10 39 95 10 39 96 10 39 97 10 40 98 10 40 99 10 41 100 10 41 "],["vedlegg-3---chebyshevs-teorem.html", "Vedlegg 3 - Chebyshevs teorem", " Vedlegg 3 - Chebyshevs teorem Dette vedlegget er i stor grad bygget på Hartmann et al. (2018b). Vi diskuterte i noe detalj hvordan vi kan bruke normalfordelingen til å si noe om hvordan verdier i et datasett kan antas å falle innenfor en gitt avstand fra gjennomsnittet (Hartmann et al. 2018b): Figure 9.1: Normalfordeling med standardavvik Vi kan ut fra normalfordeingen si at 68 % av observajsonene vil ligge innenfor ett standardavvik fra gjennomsnittsverdien 95 % av observasjonene vil ligge innenfor to standradavvik fra gjennomsnittsverdien 99.7 % av observasjonene vil ligge innenfor tre standardaavik fra gjennomsnittsverdien Dette kalles ofte for den empiriske regelen (the empirical rule), og gjelder kun normalfordelte data. Chebyshevs teorem gjelder imidlertid alle fordelinger. Normalfordelingen gir oss at datapunkter med en viss sannsynlighet ligger innenfor en viss avstand fra gjennomsnittsverdien. Det samme sier Chebyshevs teorem om datafordelinger som ikke er normalfordelte: bare en gitt mengde datapunkter kan ligge mer enn en gitt avstand fra gjennomsnittsverdien. Teoremet uttrykkes slik (Hartmann et al. 2018b): For ethvert nummer k større enn 1 vil minst \\(1-1/\\)k\\(^2\\) av dataverdiene ligge innenfor k standardavvik fra gjennomsnittet. Teoremet kan generisk kan framstilles slik: Figure 9.2: Chebyshevs teorem For ethvert numerisk datasett gjelder: Minst ¾ av datapunktene ligger innenfor to standardavvik av gjennomsnittet  altså i intervallet mellom endepunktene \\(\\overline{x}\\pm2s\\) for et utvalg og \\(\\overline{x}\\pm2\\sigma\\) for populasjoner. Minst 8/9 av datapunktene ligger innenfor tre standardavvik av gjennomsnittet  altså i intervallet mellom endepunktene \\(\\overline{x}\\pm3s\\) for et utvalg og \\(\\overline{x}\\pm3\\sigma\\) for populasjoner. Minst \\(1-1/\\)k\\(^2\\) av datapunktene ligger mellom k standardavvik av gjennomsnittet  altså i intervallet mellom endepunktene \\(\\overline{x}\\pm\\)k\\(s\\) for et utvalg og \\(\\overline{x}\\pm\\)k\\(\\sigma\\) for populasjoner. Ut fra tabellen under ser vi at dersom vi velger scroller til k = 2 vil 75 % av verdiene ligge innenfor (altså 75 % innenfor 2 standardavvik). k auc.percent 1.0 0 1.1 17 1.2 31 1.3 41 1.4 49 1.5 56 1.6 61 1.7 65 1.8 69 1.9 72 2.0 75 2.1 77 2.2 79 2.3 81 2.4 83 2.5 84 2.6 85 2.7 86 2.8 87 2.9 88 3.0 89 3.1 90 3.2 90 3.3 91 3.4 91 3.5 92 3.6 92 3.7 93 3.8 93 3.9 93 4.0 94 Vi kan også vise en grafisk framstilling av Chebyshevs teorem med fokus på prosenter (y-aksen) mot k (x-aksen). Figure 9.3: Chebyshevs teorem - prosent Når vi vet at minst 75% av distribusjonen ligger innenfor \\(\\overline{x}\\pm2s\\) vet vi også at maksimalt 25% ligger utenfor. Likeledes for \\(\\overline{x}\\pm3s\\) vil maksimalt 11,11 % av distribusjonen ligge utenfor. Så mens reglene for normalfordeling kun gjelder for normalfordelte eller tilnærmet-normalfordelte datasett, er Chebyshevs teorem et faktum som gjelder alle datadistribusjoner og som beskriver minimumsandelen av observasjoner/datapunkter som ligger innenfor hhv +/- 1, 2 og 3 standardavvik fra gjennomsnittet. "],["vedlegg-4---sentralgrenseteoremet-central-limit-theorem.html", "Vedlegg 4 - Sentralgrenseteoremet (Central Limit Theorem)", " Vedlegg 4 - Sentralgrenseteoremet (Central Limit Theorem) Koden brukt i dette eksempelet er i stor grad hentet fra Fedit (2018) Dette er et noe komplisert begrep som vi ikke skal gå veldig i dybden på, men det har et par viktige konsekvenser for oss når vi skal tenke på distribusjon av populasjoner og utvalg. Her belyser vi to forhold som «gis» av Central Limit Theorem: Gjennomsnittsverdien (mean) av tilfeldige utvalg fra en populasjon vil være tilnærmet lik gjennomsnittsverdien for populasjonen hvis størrelsen på utvalgene er tilstrekkelig stort. Fordelingen til tilfeldige utvalg fra en populasjon vil være tilnærmet normalfordelt uavhengig av fordelingen på populasjonen. Dette innebærer at selv om populasjonen er langt fra normalfordelt vil et tilstrekkelig stort utvalg vise seg å være tilnærmet normalfordelt. La oss se på dette gjennom et eksempel der vi starter med en bimodal fordeling (altså langt fra normalfordeling). Vi generer et datasett og plotter et Q-Q diagram (mer om dette et annet sted i boka (se kap. 5), men per nå trenger vi bare vite at dette er en effektiv måte å sjekke om en variabel er normalfordelt eller ikke). ## package &#39;truncnorm&#39; successfully unpacked and MD5 sums checked ## ## The downloaded binary packages are in ## C:\\Users\\nilsk\\AppData\\Local\\Temp\\Rtmp6TFe05\\downloaded_packages Figure 9.4: Ikke-normal fordeling og Q-Q plott Som sagt har vi gjort rede for Q-Q plott et annet sted i boka, så her kan vi nøye oss med å slå fast at denne variabelen definitivt ikke er normalfordelt. Det framkommer også tydelig når vi plotter et histogram: Figure 9.5: Histogram for bimodal fordeling Ut fra denne populasjonen tar vi 100 utvalg med 30 i hvert utvalg. Fordelingen ser da slik ut: Figure 9.6: Histogram for 100 utvalg fra bimodal fordeling Vi kan allerede nå ane en tilnørming mot normalfordeling, og i hvert fall en endret form enn populasjonen viste. Vi tar nå 1000 utvalg med 30 i hvert utvalg. Figure 9.7: Histogram for 1000 utvalg fra bimodal fordeling Det er videre åpenbart at dette begynner å se mer og mer ut som en normalfordeling. Til slutt øker vi til 10000 utvalg av 30. Figure 9.8: Histogram for 10000 utvalg fra bimodal fordeling Det vi kan se bekrefter hva Central Limit Theorem sier vi bør forvente. Vi kan starte med en hvilken som helst fordeling (kontinuerlig eller diskret) som har et definert gjennomsnitt og definert varians (og dermed definert standardavvik) og ta tilfeldige utvalg fra denne fordelingen  og vi vil få en tilnærmet normalfordelt fordeling. I det virkelige liv har vi ofte populasjonsfordelinger som har alt annet enn normalfordeling. Likevel kan vi ta tilfeldige utvalg og få en tilnærmet normalfordelt frekvensplott (av f.eks. gjennomsnittsverdier). Størrelsen på utvalget og antallet ganger vi tar utvalg vil påvirke -&gt; jo større utvalg og jo flere utvalg, jo nærmere normalfordeling vil frekvensplottet være. En interessant illustrasjon av CLT ligger her. Vi har laget en kort video som viser hvordan denne demonstrasjonssiden fungerer. Video kommer her "],["vedlegg-5---tabell-med-konstanter-for-kontrolldiagram.html", "Vedlegg 5 - Tabell med konstanter for kontrolldiagram", " Vedlegg 5 - Tabell med konstanter for kontrolldiagram ## package &#39;diffobj&#39; successfully unpacked and MD5 sums checked ## package &#39;brio&#39; successfully unpacked and MD5 sums checked ## package &#39;desc&#39; successfully unpacked and MD5 sums checked ## package &#39;pkgload&#39; successfully unpacked and MD5 sums checked ## package &#39;praise&#39; successfully unpacked and MD5 sums checked ## package &#39;waldo&#39; successfully unpacked and MD5 sums checked ## package &#39;testthat&#39; successfully unpacked and MD5 sums checked ## package &#39;xtable&#39; successfully unpacked and MD5 sums checked ## package &#39;SixSigma&#39; successfully unpacked and MD5 sums checked ## ## The downloaded binary packages are in ## C:\\Users\\nilsk\\AppData\\Local\\Temp\\Rtmp6TFe05\\downloaded_packages .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-356a0704{}.cl-355ffca0{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-355ffca1{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-356023ce{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:6pt;padding-top:6pt;padding-left:6pt;padding-right:6pt;line-height: 1;background-color:transparent;}.cl-3561f6f4{width:54pt;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3561f6f5{width:54pt;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3561f6f6{width:54pt;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-3561f6f7{width:54pt;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Tabell med konstanter for kontrolldiagramnA2d2d3c4D3D4B3B421.87997121.1283790.85250250.79788460.000000003.2665320.000000003.26653231.02332671.6925690.88836800.88622690.000000002.5745910.000000002.56817040.72859722.0587510.87980820.92131770.000000002.2820520.000000002.26604750.57681932.3259290.86408190.93998560.000000002.1144990.000000002.08899860.48324602.5344130.84803970.95153290.000000002.0038300.030363211.96963770.41928402.7043570.83320530.95936880.075707741.9242920.117685031.88231580.37252742.8472010.81983110.96503050.136171411.8638290.185089601.81491090.33669742.9700260.80783430.96931070.184013021.8159870.239132801.760867100.30826373.0775050.79705070.97265930.223022661.7769770.283705561.716294110.28508363.1728730.78731460.97535010.255581901.7444180.321280151.678720120.26577793.2584550.77847830.97755940.283269271.7167310.353511831.646488130.24941703.3359800.77041620.97940560.307175601.6928240.381555701.618444140.23535063.4067630.76302310.98097140.328080881.6719190.406245381.593755150.22310923.4718270.75621140.98231620.346558931.6534410.428199541.571800160.21234533.5319830.74990810.98348350.363042131.6369580.447888161.552112170.20279553.5878840.74405180.98450640.377863021.6221370.465675541.534324180.19425673.6400640.73859080.98541000.391281961.6087180.481848961.518151190.18656933.6889630.73348150.98621410.403505971.5964940.496638441.503362200.17960633.7349490.72869080.98693430.414698241.5853020.510230591.489769210.17326513.7783360.72417330.98758290.425006121.5749940.522778621.477221220.16746213.8193850.71991480.98817030.434530791.5654690.534409631.465590230.16212833.8583230.71588680.98870450.443369561.5566300.545230091.454770240.15720613.8953480.71206820.98919270.451601101.5483990.555329931.444670250.15264733.9306290.70844080.98964040.459292041.5407080.564785711.435214 "],["vedlegg-6---utregning-av-kontrollgrenser.html", "Vedlegg 6 - Utregning av kontrollgrenser", " Vedlegg 6 - Utregning av kontrollgrenser Jfr. Laney (2002) og Montgomery (2020) Notasjon Notasjon Innhold CL Sentraltendens (Central Line) UCL Øvre kontrollgrense (Upper Control Limit) LCL Nedre kontrollgrense (Lower Control Limit) n Utvalgsstørrelse \\(\\hat{\\sigma}\\) Standardavvik i prosessen \\(\\overline{x}\\) Gjennomsnitt av målinger \\(\\overline{\\overline{x}}\\) Gjennomsnitt av gjennomsnitt R Spenn (Range) \\(\\hat{R}\\) Gjennomsnitt av spenn (Average of Range) USL Øvre spesifiseringsgrense (Upper Specification Limit) LSL Nedre spesifiseringsgrense (Lower Specification Limit) Måledata Grense X R CL \\[\\overline{\\overline{x}}\\] \\[\\hat{R}\\] UCL \\[\\overline{\\overline{x}} + A_2\\hat{R}\\] \\[\\hat{R}D_4\\] LCL \\[\\overline{\\overline{x}} - A_2\\hat{R}\\] \\[\\hat{R}D_3\\] For A2, D3 og D4: Se vedlegg 5 For IMR (XMR): Grense I MR CL \\[\\overline{x}\\] \\[\\overline{MR}\\] UCL \\[\\overline{x} + 3 \\times \\frac{\\overline{MR}}{d_2}\\] \\[\\overline{MR}D_4\\] LCL \\[\\overline{x} - 3 \\times \\frac{\\overline{MR}}{d_2}\\] Utregning av gjennomsnittlig x-verdi: \\(\\overline{x}\\) = \\(\\frac{\\sum_{i = 1}^{m}x_i}{m}\\) Utregning av Moving Range: \\(MR_i\\) = \\(|x_i-x_i-1|\\), der \\(x_i\\) er et datapunkt og \\(x_i-1\\) er datapunktets foregående datapunkt. Utregning av gjennomsnittlig Moving Range: \\(\\overline{MR}\\) = \\(\\frac{\\sum_{i = 2}^{m}MR_i}{m-1}\\) Attributtdata Grense p np c u CL \\[\\overline{p}\\] \\[n\\overline{p}\\] \\[\\overline{c}\\] \\[\\overline{u}\\] UCL \\[\\overline{p} + 3\\sqrt{\\frac{\\overline{p}(1-\\overline{p})}{n}}\\] \\[n\\overline{p} + 3\\sqrt{n\\overline{p}(1-\\overline{p})}\\] \\[\\overline{c} + 3\\sqrt{\\overline{c}}\\] \\[\\overline{u} + 3\\sqrt{\\frac{\\overline{u}}{n}}\\] LCL \\[\\overline{p} - 3\\sqrt{\\frac{\\overline{p}(1-\\overline{p})}{n}}\\] \\[n\\overline{p} - 3\\sqrt{n\\overline{p}(1-\\overline{p})}\\] \\[\\overline{c} - 3\\sqrt{\\overline{c}}\\] \\[\\overline{u} - 3\\sqrt{\\frac{\\overline{u}}{n}}\\] Grense Laney.p. Laney.u. g CL \\[\\overline{p}\\] \\[\\overline{u}\\] \\[\\overline{g}*0.693\\] UCL \\[\\overline{p} + 3\\sigma_z\\sqrt{\\frac{\\overline{p}(1-\\overline{p})}{n_i}}\\] \\[\\overline{u} + 3\\sigma_z\\sqrt{\\frac{\\overline{u}}{n_i}}\\] \\[\\overline{g} + 3\\sqrt{\\overline{g}(\\overline{g}+1)}\\] LCL \\[\\overline{p} - 3\\sigma_z\\sqrt{\\frac{\\overline{p}(1-\\overline{p})}{n_i}}\\] \\[\\overline{u} - 3\\sigma_z\\sqrt{\\frac{\\overline{u}}{n_i}}\\] \\[\\overline{g} - 3\\sqrt{\\overline{g}(\\overline{g}+1)}\\] z-konvertering for Laneys p: \\(z_i\\) = \\(\\frac{p_i-\\overline{p}}{\\sqrt{\\frac{\\overline{p}(1-\\overline{p})}{n_i}}}\\) z-konvertering for Laneys u: \\(z_i\\) = \\(\\frac{u_i-\\overline{u}}{\\sqrt{\\frac{\\overline{u}}{n_i}}}\\) standardavvik for z: \\(\\sigma_z\\) = \\(\\frac{\\overline{R}}{d_2}\\) MR snitt for Laneys u: \\(M\\overline{R}\\) = \\(\\frac{\\sum{MR}}{(k-1)}\\) "],["vedlegg-7---anderson-darling-test-for-normalitet.html", "Vedlegg 7 - Anderson-Darling test for normalitet", " Vedlegg 7 - Anderson-Darling test for normalitet Jfr. Anderson and Darling (1954), Stephens (1979), Jäntschi and Bolboac (2018) og Zaiontz (2020) Fordeling AD.verdi Generisk/uniform \\[A=-n-\\frac{1}{n}\\sum_{i=1}^{n}(2_i-1)[lnF(X_i)+ln(1-F(X_{n-i+1}))]\\] Normal/lognormal \\[A^2=A(1+\\frac{75}{n}+\\frac{2.25}{n^2})\\] Gamma \\(k=1\\) \\[A(1+\\frac{6}{n})\\] Gamma \\(k\\ge1\\) \\[A+(\\frac{0.2+\\frac{0.3}{k}}{n})\\] Eksponensiell \\[A(1+\\frac{6}{\\sqrt{n}})\\] Weilbull/Gumbel \\[A(1+\\frac{0.2}{\\sqrt{n}})\\] Logistisk \\[A(1+\\frac{0.25}{\\sqrt{n}})\\] For gammafordeling er k parameteret (shape parameter) definert som \\(\\alpha\\). Kritiske verdier for Anderson-Darling test. Merk: hvis man søker på nett finner man ulike framstillinger med noen avvikende verdier  vi har basert verdiene for normalfordeling på DAgostino and Stephens (1986:123, tabell 4.7). Øvrige verdier er basert på Marsaglia and Marsaglia (2004) og Stephens (1974, 1976, 1977, 1978, 1979). Du kan laste ned tabellen i en Excel-fil her: Download AD-alpha.xlsx Tabell over \\(\\alpha\\) verdier "],["vedlegg-8---nedlasting-installasjon-og-enkel-bruk-av-r-og-rstudio.html", "Vedlegg 8 - Nedlasting, installasjon og enkel bruk av R og RStudio Nedlasting og installasjon av R Nedlasting og installasjon av RStudio RStudio", " Vedlegg 8 - Nedlasting, installasjon og enkel bruk av R og RStudio Heniskten med dette vedlegget er å vise nedlasting og installasjon av R og RStudio, samt den helt grunnleggende bruken av R i RStudio. Målet er at dere skal kunne nok om R og RStudio til å kunne hente koder i vedlegg 1 og kjøre dette selv når dere jobber dere gjennom boka. Dere skal altså kunne replikere eksemplene i boka gjennom kode i vedlegg 1 ved å kjøre disse i RStudio på egen maskin. Det finnes en god del gode ressurser for introduksjon til R, både på nett og i bokform. Ofte trekkes R for Data Science av Garret Grolemund og Hadley Wickham fram som et veldig godt sted å lære R. Vi har hatt stor nytte av denne boka selv, ikke minst fordi den pivoterer rundt Hadleys tilnærming til R og data gjennom pakken tidyverse. En annen god introduksjon til R er An Introdcution to R av Venables, Smith og R Core Team. De to siste ressursene vi vil nevne her er Derek Sondereggers A Sufficient Introduction to R og YaRrr! The Pirates Guide to R. Det finnes som sagt mange andre nettressurser, ikke minst mange gode how-to videoer på YouTube og Vimeo. Dette fører oss til avslutningen på denne korte innledningen og et kjernebudskap når det gjelder R: Du finner alltid svar på noe du lurer på eller ikke får til i R på nett (delekulturen er enorm) Nedlasting og installasjon av R Vi har laget en kort video som viser nedlasting og installasjon av R og RStudio som ligger her Første steg er å laste ned selve R. Det gjør du ved å gå til denne nettsiden og velge lenke ut fra ditt operativsystem (Windows, MacOS eller Linux): I det følgende har jeg valgt Windows. Velg deretter install R for the first time (antar at du ikke allerede har R på din maskin): Og deretter: Deretter er det i grunnen bare å følge vanlige prosedyrer (= følg instruksjonene) for å installere R på din maskin. Når du har installert kan det være lurt å se at det kjører. PÅ en PC (Win 10) kan du trykke på Windowssymbolet nederst til venstre på skjermen og deretter scrolle nedover i listen over apper (hos meg ser det slik ut): Når du åpner R får du opp et tilsvarende skjermbilde som dette: Jeg kjører altså versjon 4.0.5. R oppdateres jevnlig, og i skrivende stund er nyeste versjon 4.1.2. Det er ingen krise om man ikke kjører helt nyeste versjon av R, man skal være obs på at ved oppgradering av R-versjon kan man risikere å miste pakker (ingen krise - kan reinstalleres i de fleste tilfeller så lenge pakkene støtter den nye versjonen av R). For de som er interesserte i dette kan How to Keep Your R Packages Up to Date gi nyttig informasjon. Når du nå har fått installert R er sjansene store for at du aldri åpner R igjen - jeg har siden installasjon i hvert fall aldri hatt behov for å kjøre R i sin egen form fordi jeg heldigvis har RStudio som legger seg utenpå R som et grafisk brukergrensesnitt (og gjør R-arbeid og livet langt enklere). Nedlasting og installasjon av RStudio RStudio er mye mer enn bare et grafisk brukergrensesnitt (vel, egentlig en IDE - Integrated development environment), men for oss i denne konteksten er RStudio programmet vi jobber med R i. I tillegg til å være utrolig nyttig er gratisversjonen alt vi trenger. Nedlasting skjer her På denne siden velger du RStudio Desktop: Også her finnes det versjoner for ulike operativsystemer (Windows, macOS og ulike Linuxdistribusjoner): Deretter er det som for R bare å følge installasjonsveiledningen undervegs. RStudio Når du åpner RStudio første gang vil du trolig se dette: Som for R vil du etter å ha tatt programmet i bruk sjeldent se akkurat dette oppsettet siden RStudio normalt vil åpne med siste økt i minnet (så lenge ting er lagret). Uansett - i vår kontekst ønsker vi å åpne en RMarkdown fil som vil vil bruke til å skrive inn/kopiere inn tekst og kode (hele denne boka er skrevet i RMarkdown i RStudio). Vi går da opp i menyen og velger å lage et nytt RMarkdown dokument: Du får da opp et nytt vindu: Her kan du bare la alt stå som foreslått, med mindre du ønsker å lage din egen tittel. RMarkdowndokumentet opprettes og ser slik ut (jeg har uthevet en del med blått - dette vil ikke være der hos dere): Det som er uthevet i blått er informerende tekst RStudio lager som en slags introduksjon til RMarkdown. Du kan kjøre de to eksemplene som gis og se resultatet. Etter første gang vil du trolig bare ønske å merke alt slik jeg har gjort og slette alt. Merk: Du må ikke slette det som står øverst mellom de tre horisontale strekene (title:, author:, date: og output:). Når du har blitt mer dreven i RMarkdown kan du fiffe med dette også, men inntil videre er det en fordel å bare la det være. Grunnleggende bruk av RStudio RStudio er organisert i fire vinduer for å forenkle arbeidet. I tekst og kodevinduet skrives - ikke overraskende - tekst og kode. Vanlig tekst skrives rett inn som i andre teksteditorer, men formatteringen er annerledes enn i f.eks. Word, men siden formålet her er å kunne kjøre kodeeksempler går vi ikke nærmere inn på dette her. Kode skrives inn i egne kodebolker. Det enkleste for å se framgangsmåten er å ta en titt på denne videolink her videoen som viser framgangsmåten steg for steg. I vedlegg 1 har vi gjengitt kode for ulike analyser, plott osv. En kodeblokk i RMarkdown ser slik ut: For å kjøre denne kodeblokken (alle kodelinjene i blokken) kan vi trykke på Den grønne trekantpila i øverste høyre hjørne av kodeblokken. Hvis vi kun vil kjøre enkelte linjer av kodeblokken kan vi markere den/de linjene vi vil kjøre og trykke på samme trekantpil. Noen ganger vil vi oppleve at vi får en feilmelding - R vil ikke kjøre hele koden fordi det er noe feil i den. Det kan se slik ut: RStudio vil markere med en rød strek til venstre for kodelinjene hvor den ikke forstår koden. I tillegg vil RStudio gi informajson om hva den ikke skjønner. Her kan vi umiddelbart legge til at det ikke er alltid det er så lett å forstå disse feilmeldingene. I eksempelet over vil vi imidlertid se at R ikke finner objektet eksempelrun som vi ber R gjøre noe med. Dette skyldes at vi lager dette objektet (datasettet) i kodeblokken over (i det virkelige tilfellet) og når vi ikke har kjørt denne tidligere kodeblokka er objektet ikke laget i vårt eksempel her. R kan naturligvis ikke behandle et objekt som ikke finnes. R er befriende logisk sånn sett Når vi først kjører den tidligere kodeblokka og deretter gjentar koden på bildet over får vi: Vi håper selvsagt dere ikke vil oppleve problemer med å kjøre eksempelkodene brukt i denne boka og som er gitt i vedlegg 1. Det kan likevel hende selvsagt, og i så fall ber vi om tilbakemelding på dette - men som sagt er hensikten i denne konteksten kun å kjøre eksemplene, alle andre spørsmål om R/RStudio/RMarkdown må vi nesten henvise til andre hjelpemidler (som tidligere nevnt er Google et godt sted å begynne siden det finnes et svar på de fleste R/RStudio/RMarkdown relaterte spørsmål ute på den store vebben). "],["vedlegg-9---dimensjoner-i-implementering-av-spc.html", "Vedlegg 9 - Dimensjoner i implementering av SPC", " Vedlegg 9 - Dimensjoner i implementering av SPC Basert på Rungtusanatham, Anderson, and Dooley (1997) Nr Dimensjon 1 Ledelsens beslutninger og retningslinjer for å støtte implementering og praktisering av SPC 2 Betydning og synlighet av kontrolldiagram som verktøy for monitorering og kontroll av prosessytelser 3 Identifikasjon av kritiske måleparametre for kritiske prosesser og/eller produktegenskaper som påvirker de kritiske prosessene 4 Måleverktøyenes teknologisk modenhet og robusthet brukt i datainnsamling 5 Operatøransvar for korrekt bruk av kontrolldiagram for prosesskontroll 6 Verifisering av at forutsetningene for bruk av kontrolldiagram er tilstrekkelig ivaretatt 7 Bruk av kontrlldiagram i kontinuerlig forbedringsarbeid 8 Utvalgsstrategier for datainnsamling til kontrolldiagram 9 Opplæring og trening i statistiske og kognitive metoder for prosesskontroll og -forbedringer 10 Teknisk støtte for implementering og bruk 11 Kvalitetsforbedringsgruppe som støtte til praksis 12 Fravær av sluttinspeksjon/sluttkontroll som kvalitetsstrategi 13 Dokumentasjon og oppdatering av prosesskompetanse 14 Evaluering og revisjon av SPC praksis og resultater "],["vedlegg-10---formler-prosesskapabilitet.html", "Vedlegg 10 - Formler prosesskapabilitet Måledata Telledata", " Vedlegg 10 - Formler prosesskapabilitet Basert på Kane (1986), Chan, Cheng, and Spiring (1988),Taguchi, Elsayed, and Hsiang (1989), Pearn, Kotz, and Johnson (1992), English and Taylor (1993), Luceño (1996), Deleryd (1999), Tang and Than (1999), Wu, Pearn, and Kotz (2009), Wheeler (2013), Montgomery (2020), McNeese (2020) Måledata Cp Cp = \\(\\frac{ønsket/tillatt spredning}{faktisk spredning}\\) Cp = \\(\\frac{USL - LSL}{6\\sigma}\\) der: USL = Øvre toleransegrense (Upper Specification Limit) LSL = Nedre toleransegrense (Lower Specification Limit) \\(\\sigma\\) = standardavvik for prosessen beregnet ut fra data kontrolldiagrammet Formelen over forutsetter at både USL og LSL er i bruk (tosidig). Dersom man skal ha en ensidig Cp brukes: Cpu = \\(\\frac{USL - \\mu}{3\\sigma}\\) = øvre toleransegrense Cpl = \\(\\frac{\\mu - LSL}{3\\sigma}\\) = nedre toleransegrense Og en hendig formel for prosent kapabilitet: P = \\((\\frac{1}{C~p~})100\\) der: P = prosenten av kapabiliteten (the specification band) prosessen bruker Pp Pp = \\(\\frac{USL - LSL}{6s}\\) der: s = standardavvik for prosessen beregnet ut fra all tidligere data for prosessen (som ikke er det samme som \\(\\sigma\\), jfr formel for Cp). Cpk Cpk = min(Cpu,Cpl) der: Cpu = \\(\\frac{USL - \\mu}{3\\sigma}\\) Cpl = \\(\\frac{\\mu - LSL}{3\\sigma}\\) \\(\\mu\\) = prosessgjennomsnitt Alternativ måte å uttrykke samme formel (Wheeler 2013): Cpk = \\(\\frac{2 DNS}{6\\sigma}\\) der: DNS = Distance to the nearer specification, altså avstanden fra gjennomsnitt til den spesifikasjonsgrensen som ligger nærmest snittet. Alternativ Cpk av Chan et al. (1988): Cpk=Cp(1-k) der: k=tilfeldig variabel Ppk Ppk = min(Ppu,Ppl) der: Ppu = \\(\\frac{USL - \\mu}{3s}\\) Ppl = \\(\\frac{\\mu - LSL}{3s}\\) \\(\\mu\\) = prosessgjennomsnitt s = standardavvik for prosessen beregnet ut fra all tidligere data for prosessen (som ikke er det samme som \\(\\sigma\\), jfr formel for Cpk) Alternativ måte å uttrykke samme formel (Wheeler 2013): Ppk = \\(\\frac{2 DNS}{6s}\\) der: DNS = Distance to the nearer specification, altså avstanden fra gjennomsnitt til den spesifikasjonsgrensen som ligger nærmest snittet. Cpm Cpm = \\(\\frac{USL - LSL}{6\\sqrt{\\sigma^{2} + (\\mu - T)^{2}}}\\) Cpmk Cpmk = \\(\\frac{d-|\\mu-m|}{3\\sqrt{\\sigma^{2}+(\\mu-T)^{2}}}\\) Telledata DPU DPU = \\(\\frac{T_{d}}{T_{e}}\\) der: DPU = Defects Per Unit Td = Totalt antall defekter Te = Totalt antall enheter DPMO DPMO = \\(\\frac{T_{d}}{{N_{u}*N_{o}}}\\) der: DPMO = Defects per millon opportunities Td = Totalt antall defekter Nu = Antall enheter (Number of units) No = Antall muligheter (Number of opportunities) Loss function L = \\(k(Y-T)^{2}\\) Ikke-normale data Surrogat Cp (Tang and Than 1999) Cp = \\(\\frac{USL - LSL}{U~p~-L~p~}\\) der: Up=øvre 0.135% punkt Lp=nedre 0.135% punkt Et annet forslag på kapabilitetsindeks for ikke-normale data (Luceño 1996): Cpc = \\(\\frac{USL - LSL}{6\\sqrt{\\frac{\\pi}{2}E|X-T|}}\\) "],["vedlegg-9---session-info.html", "Vedlegg 9 - Session Info", " Vedlegg 9 - Session Info ## R version 4.1.2 (2021-11-01) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 19043) ## ## Locale: ## LC_COLLATE=Norwegian Bokmål_Norway.1252 ## LC_CTYPE=Norwegian Bokmål_Norway.1252 ## LC_MONETARY=Norwegian Bokmål_Norway.1252 ## LC_NUMERIC=C ## LC_TIME=Norwegian Bokmål_Norway.1252 ## ## Package version: ## abind_1.4-5 askpass_1.1 assertthat_0.2.1 ## backports_1.4.1 base64enc_0.1-3 bit_4.0.4 ## bit64_4.0.5 blob_1.2.2 bmp_0.3 ## bookdown_0.24 boot_1.3.28 brio_1.1.3 ## broom_0.7.11 callr_3.7.0 car_3.0-12 ## carData_3.0-5 caret_6.0.90 cellranger_1.1.0 ## class_7.3.19 cli_3.1.1 clipr_0.7.1 ## codetools_0.2.18 colorspace_2.0-2 compiler_4.1.2 ## conquer_1.2.1 corrplot_0.92 cowplot_1.1.1 ## cpp11_0.4.2 crayon_1.4.2 curl_4.3.2 ## data.table_1.14.2 DBI_1.1.2 dbplyr_2.1.1 ## desc_1.4.0 diffobj_0.3.5 digest_0.6.29 ## downloader_0.4 dplyr_1.0.7 dtplyr_1.2.1 ## e1071_1.7.9 ellipsis_0.3.2 evaluate_0.14 ## extrafont_0.17 extrafontdb_1.0 fansi_1.0.2 ## farver_2.1.0 fastmap_1.1.0 flextable_0.6.10 ## forcats_0.5.1 foreach_1.5.1 foreign_0.8.81 ## fs_1.5.2 future_1.23.0 future.apply_1.8.1 ## gargle_1.2.0 gdtools_0.2.3 generics_0.1.1 ## ggforce_0.3.3 ggfortify_0.4.14 ggplot2_3.3.5 ## ggpubr_0.4.0 ggrepel_0.9.1 ggsci_2.9 ## ggsignif_0.6.3 globals_0.14.0 glue_1.6.0 ## googledrive_2.0.0 googlesheets4_1.0.0 gower_0.2.2 ## graphics_4.1.2 grDevices_4.1.2 grid_4.1.2 ## gridExtra_2.3 gtable_0.3.0 haven_2.4.3 ## highr_0.9 hms_1.1.1 hrbrthemes_0.8.0 ## htmltools_0.5.2 httr_1.4.2 ids_1.0.1 ## igraph_1.2.11 imager_0.42.11 ipred_0.9.12 ## isoband_0.2.5 iterators_1.0.13 jpeg_0.1-9 ## jquerylib_0.1.4 jsonlite_1.7.3 kableExtra_1.3.4 ## KernSmooth_2.23.20 knitr_1.37 labeling_0.4.2 ## lattice_0.20-45 lava_1.6.10 lifecycle_1.0.1 ## listenv_0.8.0 lme4_1.1.27.1 lubridate_1.8.0 ## magrittr_2.0.1 maptools_1.1.2 MASS_7.3-54 ## Matrix_1.3.4 MatrixModels_0.5.0 matrixStats_0.61.0 ## methods_4.1.2 mgcv_1.8.38 mime_0.12 ## minqa_1.2.4 ModelMetrics_1.2.2.2 modelr_0.1.8 ## munsell_0.5.0 nlme_3.1.153 nloptr_1.2.2.3 ## nnet_7.3.16 normtest_1.1 nortest_1.0-4 ## numDeriv_2016.8.1.1 officer_0.4.1 openssl_1.4.6 ## pacman_0.5.1 parallel_4.1.2 parallelly_1.30.0 ## pbkrtest_0.5.1 pillar_1.6.4 pkgconfig_2.0.3 ## pkgload_1.2.4 plotrix_3.8-2 plyr_1.8.6 ## png_0.1-7 polyclip_1.10-0 polynom_1.4.0 ## praise_1.0.0 prettyunits_1.1.1 pROC_1.18.0 ## processx_3.5.2 prodlim_2019.11.13 progress_1.2.2 ## progressr_0.10.0 proxy_0.4.26 ps_1.6.0 ## purrr_0.3.4 qcc_2.7 qicharts2_0.7.2 ## quadprog_1.5-8 quantmod_0.4.18 quantreg_5.86 ## R6_2.5.1 rappdirs_0.3.3 RColorBrewer_1.1.2 ## Rcpp_1.0.8 RcppArmadillo_0.10.7.5.0 RcppEigen_0.3.3.9.1 ## readbitmap_0.1.5 readr_2.1.1 readxl_1.3.1 ## recipes_0.1.17 rematch_1.0.1 rematch2_2.1.2 ## remotes_2.4.2 reprex_2.0.1 reshape2_1.4.4 ## rJava_1.0-6 rlang_0.4.12 rmarkdown_2.11 ## rpart_4.1.15 rprojroot_2.0.2 rstatix_0.7.0 ## rstudioapi_0.13 Rttf2pt1_1.3.9 rvest_1.0.2 ## scales_1.1.1 selectr_0.4.2 SixSigma_0.10.3 ## sp_1.4.6 SparseM_1.81 splines_4.1.2 ## SQUAREM_2021.1 stats_4.1.2 stats4_4.1.2 ## stringi_1.7.6 stringr_1.4.0 survival_3.2.13 ## svglite_2.0.0 sys_3.4 systemfonts_1.0.3 ## testthat_3.1.2 tibble_3.1.6 tidyr_1.1.4 ## tidyselect_1.1.1 tidyverse_1.3.1 tiff_0.1-10 ## timeDate_3043.102 tinytex_0.36 tools_4.1.2 ## truncnorm_1.0-8 tseries_0.10-49 TTR_0.24.3 ## tweenr_1.0.2 tzdb_0.2.0 utf8_1.2.2 ## utils_4.1.2 uuid_1.0-3 vctrs_0.3.8 ## viridisLite_0.4.0 vroom_1.5.7 waldo_0.3.1 ## webshot_0.5.2 withr_2.4.3 writexl_1.4.0 ## xfun_0.29 xlsx_0.6.5 xlsxjars_0.6.1 ## xml2_1.3.3 xtable_1.8-4 xts_0.12.1 ## yaml_2.2.1 zip_2.2.0 zoo_1.8-9 Strengt tatt bruker vi R og RStudio, men dette vil bli forklart i vedlegget som omhandler nedlasting og installasjon av disse. R er programvaren og motoren, RStudio er brukergrensesnittet vi legger utenpå R som gjør det langt enklere å bruke Vi viser til Excel, men man kan like gjerne bruke Apache Open Office, en gratis programvarepakke som inkluderer Calc. Videoene hvor vi viser framgangsmåte i Excel kan enkelt brukes med Calc (selv om mindre forskjeller kan eksistere). Vi er ikke kjent med tilsvarende tilleggsprogram for Open Office Calc. Et annet eksempel på tilsvarende tillegg til Excel er XLSTAT Analyse-It som inkluderer kvalitetsmodulen koster i skrivende stund $ 249 for en årlig lisens, eller $ 649 for en permanent lisens. Om man vil ha et gratis alternativ for statistiske analyser som legger seg i Excel kan også Real Statistics Resource Pack være et ok alternativ, men dette tillegget har ikke noen funksjonalitet for statistisk prosesskontroll Sosio-teknisk systemteori belyser nettopp samspillet mellom sosiale/menneskelige og tekniske faktorer i organisasjonsutvikling. Klassisk litteratur på dette omfatter f.eks. Burns and Stalker (1961), Trist and Bamforth (1951) og Woodward (1958) - se f.eks. Appelbaum (1997) for en god og oversiktlig introduksjon til temaet. I vedlegg 9 har vi oversatt og gjengitt 14 dimensjoner ved implementering av SPC fra (ConceptualizingOrganizationalImplementation1997?) Eksempelet er modifisert fra Carey (2003). Se også Anhøj (2009) og NHS (2009) Hvis du ønsker å bruke R og koden må du laste ned fila og lagre den i samme mappe som din R-fil/ditt R-prosjekt ligger - se forøvrig vedlegg om installasjon av R/RStudio for tips om organisering av filer Illustrasjonen er modifisert fra Montgomery (2020), jfr. Leavengood and Reeb (2015a) Matematisk sett vil standardavviket ved å legge til n uavhengige tilfeldige observasjoner øke med kvadratroten av n ganger standardavviket for den individuelle observasjonen. Samlet sett dobles variansen, hvilket gir 1,4 ganger høyere standardavvik (siden standardavvik er kvadratroten av variansen, og \\(\\sqrt{2}\\) \\(\\approx\\) 1.4 R-kode for utregning av areal mellom to x-verdier i en normalfordeing (=sannsynlighet for at en gitt x-verdi ligger i intervallet mellom de to x-verdiene): pnorm(2,mean=0,sd=1)-pnorm(-2,mean=0,sd=1) pnorm(3,mean=0,sd=1)-pnorm(-3,mean=0,sd=1) Normalfordelingen er dessuten en god tilnærming til binomialfordeling med høyt antall observasjoner (høy n), og også til poissonfordeling med høy frekvens. Dette forfølger vi imidlertid ikke videre i dette kompendiet. Chebyshevs teorem vil imidlertid gjelde for alle datasett. Teoremet belyses i eget vedlegg for de spesielt interesserte Det er tildels stor uenighet om hvor alvorlig avvik fra normalfordelingens teoretiske forventning man kan være for likevel å bruke ulike statistiske analyser. Mange analyser er ganske robuste for avvik. Det beste rådet tror vi er å være bevisst på dette og sjekke med statistikkbøker og artikler hvor robuste de enkelte analysene er for avvik Gitt at vi har valgt 5% signifikansnivå I norsk litteratur og nettsteder brukes ofte betegnelsen «run diagram» (se f.eks. Brudvik (2009)). Selv om vi ikke har noe religiøst forhold til å finne norske begreper på ethvert engelsk begrep mener vi likevel begrepet seriediagram er et mer intuitivt begrep enn «run diagram». Har man en serie med oddetall observasjoner vil medianverdien utgjøres av et punkt, mens om man har et partall observasjoner utgjør gjennomsnittet av de to nærmest midten medianverdien. I en prosess som er tilfeldig vil det være 50-50 sjanse for å krysse medianlinjen mellom to punkter som kommer etter hverandre. Det totale antallet krysninger har således en binomialfordeling (Anhøj 2015) Dette er nærmere drøftet i kapittel 4 og 5 "]]
